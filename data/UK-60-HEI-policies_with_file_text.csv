Rank,Name,Filename,PolicyURL,Policy Text
1,London School of Economics and Political Science,01_LSE.rtf,https://www.lse.ac.uk/anthropology/study/AI-Policy,"AI Policy

AI Policy
As a student in the Department of Anthropology – or taking an Anthropology course – it is important that you understand how you can use generative AI in your assessments, so that you can do your best in your studies.
As a pedagogically diverse School with different disciplines, there is no one approach to the use of generative AI across LSE. Instead, the School has developed central guidance that allows different approaches to be taken by different academic departments and course convenors. You should familiarise yourself with the School's guidance, which is available here(""https://info.lse.ac.uk/staff/divisions/Eden-Centre/Artificial-Intelligence-Education-and-Assessment/School-position-on-generative-AI""). Within the School's guidance, there are three positions to know about:
		Position 1: No authorised use of generative AI in assessment.
		Position 2: Limited authorised use of generative AI in assessment
		Position 3: Full authorised use of generative AI in assessment.
In Anthropology we follow
		Position 2: Limited authorised use of generative AI in assessment
Position 2
This means that generative AI tools can be used in specific ways for assessments in the Department of Anthropology.
The full Department of Anthropology Policy on Student Use of AI can be found below.  You should read it carefully to understand what uses of AI are and are not permitted in the Department. Failing to follow this policy may result in an allegation of academic misconduct.
This policy applies only to courses taken in the Department of Anthropology. If you are taking a course from outside the Department, you are responsible for checking and abiding by the relevant policy for that course. 
Department of Anthropology Policy on Student Use of AI
Artificial Intelligence tools, when guided by critical reflection and ethical engagement, can play a useful role in aspects of educational and scholarly practice. Yet, such tools can also be detrimental to learning outcomes and may degrade critical skills. The Department’s default position is that the use of AI by students is permitted for a limited range of specific purposes only, as detailed below. Exceptions to the default position may be made at the discretion of individual course convenors, in which case this will be clearly communicated via the course Moodle page. 
The writing process. Text produced by any Generative AI system (e.g. ChatGPT, Claude, Copilot, Gemini, etc.) cannot be used in the writing of any summative or formative assessment. This includes using the output of AI prompts or searches directly, in edited or modified form, or citing or otherwise relying upon such output as a source for the purpose of supporting statements or arguments made in summative or formative work. The only acceptable use of AI in the writing process is for general advice about the essay as a form of expository writing and how to craft one well. For such acceptable uses, AI prompts should pertain to how to develop any essay in general, not an essay on a specific topic. Students should be aware that outputs to such prompts are likely to be quite generic.   
Students must not upload samples of their own writing to be improved or rewritten by generative AI tools such as ChatGPT, Claude or Copilot. This includes using software to translate original essays from another language into English for submission. This restriction does not apply to tools whose functionality is restricted to making purely stylistic suggestions, such as Grammarly and the AI technology currently built into Microsoft Word.  For more specific guidance on which forms of editorial assistance are acceptable, please consult the LSE’s Statement on Editorial Help for Students’ Written Work(""https://www.lse.ac.uk/resources/calendar2014-2015/academicRegulations/statementOnEditorialHelp.htm"").  
Submitting text for assessment purposes that has been produced in part or in whole by AI will be considered academic misconduct. If suspected, students may be called for a viva to explain their writing and research process. We may also use automated systems and other techniques to identify possible inappropriate use of AI tools. In cases of suspected misconduct or plagiarism, School regulations and rules will be applied. More information can be found in the LSE’s guidance on Assessment Discipline and Academic Misconduct(""https://info.lse.ac.uk/current-students/services/assessment-and-results/exams/exam-discipline-and-academic-misconduct""). 
Images. The use of AI tools to generate images (e.g. photos or diagrams) for inclusion as illustrations in certain forms of coursework (e.g. position pieces) is permitted (where appropriate), but must be correctly cited. 
Learning support. The department permits the use of AI tools for certain tasks that support learning, much in the way that internet and database searches may be used. For example, AI tools may be used to explain terms, concepts or approaches; to help find research articles; to summarise trends in the literature; or to identify questions and avenues for further research. Students should also be aware that Generative AI tools are still highly unreliable, and frequently ‘hallucinate’ false or misleading information. This can include inventing sources that do not exist or attributing ideas to authors in incorrect ways. Students must therefore exercise caution when using any material generated in this way, and should be prepared to verify the accuracy of any outputs and apply good scholarly judgment. 
Students must not upload course materials (including readings, syllabi, lecture slides, lecture recordings, or video transcripts) to Generative AI tools. Doing so can violate copyright rules and intellectual property rights; such practices are also likely to undermine the development of students’ critical skills in reading and analysis.   
Classes and seminars. AI should not be used during classes or seminars, including for fact-checking or the auto-translation of spoken or written content, unless explicitly permitted by the instructor. Students are permitted to use AI tools to explore materials and test their understanding of ideas ahead of class discussions, but all contributions to discussions and presentations must be students’ own work, not AI-generated text that is read aloud. 
Research and Fieldwork. The use of AI in original anthropological research and primary data analysis is generally permitted, with the proviso that doing so can raise ethical and legal issues that should be considered carefully on a case-by-case basis. Examples of permitted use may include using generative AI to stimulate questions or possible lines of enquiry for ethnographic fieldwork; transcribing and analysing recorded interviews, including via text-to-speech or speech-to-text software; synthesising and summarising field notes; using AI-powered tools for literature mapping and discovery (e.g. Undermind or Elicit); or tools currently built into popular software packages such as NVivo or EndNote.  Researchers must take all necessary steps to protect the privacy and anonymity of research participants and must inform themselves of how any data they upload will be stored and/or used, e.g. for the purposes of training models. 
At present, we recommend the use of either Anthropic’s Claude for Education or Microsoft Copilot for all permitted purposes, as these tools do not retain submitted data to train models under the terms of LSE’s current licenses.  
A range of additional information and resources can be found on the LSE website. In particular, please refer to the Data Science Institute’s Guidance on the use of generative AI to support research; the Digital Skills Lab’s guidance on the use of Microsoft Copilot; the Eden Centre’s Artificial Intelligence, Education and Assessment page; and the Moodle self-study course Generative AI: Developing your AI Literacy(""https://moodle.lse.ac.uk/course/info.php?id=8649"")."
2,University of St Andrews,02_stAndrews.pdf,https://www.st-andrews.ac.uk/policy/academic-policies-assessment-examination-and-award-good-academic-practice/generative-ai-faqs-students-guidance.pdf,"The University of St Andrews is a charity registered in Scotland, No: SC013532 UNIVERSITY OF ST ANDREWS  GENERATIVE AI – FAQs FOR STUDENTS    1. What is generative AI?   o It is artificial intelligence (AI) technology that actively generates content based on patterns learned from existing data in response to prompts.     2. How can I access AI tools?   o AI tools are available in an open format online, such as ChatGPT, DALL-E, Claude  o They are provided by online platforms, such as Google Cloud AI   o They are accessible via software, such as Microsoft Co-Pilot.  o The University’s provided AI tool is Microsoft Copilot.  This is available to all staff and students, with ‘Commercial Data Protection’ services enabled.      3. What is St Andrews’ standpoint on the use of generative AI for assessment?   o The University is committed to upholding academic integrity, including the prevention of the misuse of Generative AI.   o Skills in selectively utilising Generative AI as a resource will be required by our graduates.  o The University recognises that there are academically justifiable applications of Generative AI in the process of educational research and enquiry.  o The University acknowledges that AI offers students exciting opportunities to develop their academic, employability and life skills, and we are committed to support them to use this technology ethically.   o The University prides itself on developing students with excellent skills in research techniques, project planning, design, and critical thinking. These skills are core to a graduate’s education and cannot be replaced by AI use. Students should be aware of the many risks associated with using Generative AI – see Question 9 below.   o While students may choose to use Generative AI to generate notes, study aids, or other materials that they consider helpful in their learning, this type of usage may not be allowed in specific modules, so students should always check the relevant School or module handbook. Even when this type of usage is allowed, students should be mindful that they are still expected to develop relevant study skills they can employ independently of AI tools.       4. Can Students use AI to produce assessed work?    o Students should not use Generative AI for the preparation and presentation of assessed work unless authorised explicitly by the module co-ordinator. If AI use is permitted, the extent to which it can be used in assessment will be clearly outlined in the module handbook.   o If AI has been used, this should be clearly declared by the student on an assessment coversheet.     5. How does the Good Academic Practice policy address the use of AI?   
 The University of St Andrews is a charity registered in Scotland, No: SC013532 o The Good Academic Practice Policy states that Unauthorised use of AI is a type of academic misconduct.   o Using AI is considered academic misconduct when a student presents the output of an AI technology, such as a large language model (LLM) or paraphrasing application, as their own work without acknowledgment in all situations.   o The University’s position regarding students who submit content produced by Generative AI as their own work is identical to that of any type of plagiarism.   ▪ If a module does not allow Generative AI at all, then any use would be considered a case of Unauthorised Use of AI and, therefore, academic misconduct.   ▪ If a module does not prohibit the use of Generative AI, and yet a student submits content produced by Generative AI as their own work without acknowledgement, this will also be considered academic misconduct.    6. How can I maintain academic integrity when using AI?   o You should only use AI for assessment when you are permitted to by the module co-ordinator.   o If AI use is authorised, it must be cited.   o If AI use is authorised, all prompts used should be retained for reference and should be available to the module co-ordinator on request.  o AI should not be used as a substitute for your own work.     7. How do I acknowledge use of generative AI?   o You should include a declaration statement along with your references stating the AI tool used, describing how you used it, and indicating the date you accessed it.   o Further requirements may be stipulated by a School, academic programme, or individual member of teaching staff, or for a particular assignment, and will be made clear when an assignment is set.     8. How may AI assist me in my studies?  o It can help automate routine tasks, e.g., scheduling, task prioritisation, note management  o It can help improve your time management skills, e.g. you could experiment with asking AI to design a study plan.  o It may help with notetaking and summarisation. Where summation is required as part of formative or summative assessment, AI should only be used with the express permission of the module co-ordinator.     o It can create practice learning exercises.  o It may help practice your evaluation skills by assessing the quality of arguments given, e.g. some people find it helpful to ask a Generative AI based chatbot to critique their own writing.  o It may be used to proof-read for grammatical errors, as directed by your module co-ordinator.  o It may be used to suggest improvements to your writing, as directed by your module co-ordinator.   o It may help explain terms or key concepts in different ways to suit your own individual learning style.  o It may help you to learn new skills.      9. What are the risks of using AI in my academic work?   
 The University of St Andrews is a charity registered in Scotland, No: SC013532 o AI produced content is plagiarised content, and is not your own work, if it is not cited.    o As AI generates content from existing data, it can re-produce content copied from other sources.    o There are risks of copyright infringements on pictures and other copyrighted material.   o AI can generate incorrect data, produce “hallucinations” and out of date data.   o AI summarisation is not always correct and should always be checked for accurateness.  o AI can reproduce biased data.    o The energy required for AI data processing and storage is damaging to the environment, as this uses excessive amounts of electricity and water, as well as rare minerals.   o AI use may hinder a student’s independent thought and problem-solving skills.    o AI may capture data from input prompts, so it is important not to submit personal or sensitive information to an AI tool. The University Data Protection Policy can be accessed here.   o A reliance on Generative AI could impact your ability to develop important skills, including those associated with research design and critical engagement. It may also hinder the development of skills important in situations where AI is not available, e.g. in an exam setting.     10. How do I know that I am using AI?    In most cases, you would deliberately log into AI software (e.g. Co-pilot) and type in your prompt. However, there is now software available (e.g. Grammarly) which uses AI, embedded into it, so you may not be immediately aware that AI is underlying the functions of the software.  Here are some tips to help you identify if software uses AI:  • Check the Software’s Website: Look for mentions of AI, machine learning, or natural language processing. These terms often indicate AI usage.  • Read Reviews and Articles: Reviews and tech articles can provide insights into whether a software uses AI.  • Look at Features: Features like predictive text, automated suggestions, and real-time feedback are often powered by AI.  • Contact Support: If in doubt, reach out to the software’s customer support for clarification.  • University Resources: Consult IT guidelines – See https://www.st-andrews.ac.uk/it-support/services/software/students/    11. How can I determine if AI is allowed in my assessments?   o Read your School and module handbook and ask your module co-ordinator if AI use is permitted prior to starting your assessment.       12. Can I use Grammarly in my assessments?    o Grammarly has optional Generative AI features that aid the production of new content based on a series of prompts. These features should be disabled when writing assessments unless expressly permitted by your module co-ordinator or permitted as a reasonable adjustment by the Disability Team in Student Services.     13. Is AI detection software used at St Andrews?    o No.  Whilst Turnitin has developed AI-detection, this has not currently been  switched on at the University of St Andrews due to concerns over accurate detection. The Quality Assurance Agency (QAA) advised that universities should ‘be cautious in your use 
 The University of St Andrews is a charity registered in Scotland, No: SC013532 of tools that claim to detect text generated by AI and advise staff of the institutional position. The outputs from these tools are unverified and there is evidence that some text generated by AI evades detection’.    14. How can AI support disabled students?   o AI tools can provide support for students with physical, visual and auditory impairments   o ‘Use of AI’ is not a standard adjustment included in Student Support Plan, but it can be included should a student request this. Disability Advisers ensure that a student’s support plan is needs-led. If a student has information to suggest AI is needed due to their disability this can be discussed with their Disability Adviser.  o Examples of where AI may be permitted includes for students with Specific Learning Difficulties (SpLD) who may use AI to proofread their work. In such instances, the student should keep the original copies of their own work and drafts, where they haven’t used AI. Students with SpLDs may use generative AI to re-draft and improve sentence structure and phrasing and then combine the two in a finished piece of writing.  o The Scholarcy AI summarisation tool can help with condensing articles/reports/chapters into short summaries, this is helpful for students with SpLDs/ Autism spectrum disorder and underlying medical conditions like chronic fatigue or chronic migraines, where students may need to work in short bursts and take frequent breaks from screens.   o For visual or hearing impairments, one common problem is taking notes.  Glean, a note-taking piece of software, has in-built AI that can record, caption & transcribe lecture content. It can also provide ‘Question cards’ after a lecture, generated from this content.   o Software recommended through Disabled Student Allowance may have AI embedded in it, without you realising (Glean, Grammarly, Scholarcy). If you have been recommended this software as a reasonable adjustment, you may use it to adjust your work. You should not use Grammarly to generate content unless explicitly allowed to do so in your assignment guidance.     15. What should PGR students consider before using AI?   o PGR students considering the use of Generative AI should discuss and agree appropriate scope, boundaries, and applications with their supervisor at the start of the project or before commencing usage.   o Any Generative AI usage should also be highlighted during the annual review process and discussed with the review committee.  o Any use of Generative AI should be acknowledged.  ▪ a) AI use should be cited, and any prompts used, and responses received should be reported in an appendix. It is expected that Generative AI, even when used, will be applied only to specific sentences or paragraphs, and not used more broadly to contribute to the thesis. Extensive usage will still be considered poor academic practice or academic misconduct and investigated accordingly.   ▪ b) Use of AI specifically for language correction should be acknowledged in the same way as any other assistance with writing is acknowledged as per the Language Correction policy. If Generative AI forms an integral part of the research conducted or thesis production (e.g., a Computer Science thesis), a methodological statement must be included in the thesis.    16. How can I learn more about AI?   o IELLI Workshop - Understanding and using AI at University is available through PDMS"
3,Durham University,03_Durham.rtf,https://www.durham.ac.uk/global-durham/global-opportunities/ai-guidance/,"Al in Global Opportunity applications
It is unadvisable to use generative Al in GO applications - this page provides guidance about its use.
Return to the Global Opportunities homepage 

Summary
It is unadvisable to use generative AI and it may negatively affect your application.
The long read
AI / writing aids are now commonplace and cross a broad spectrum: from simple spell checkers in MS Word to generative AI. While the exact line between what may (such as spell checkers) and may not be appropriate (generative AI) may be moot, the overriding principle is your application (and thus any personal statements contained in them) should be indeed yours. While we do not have an outright ban on the use of generative AI, we do not recommend its use to write your personal statements. There are two key reasons:
First, to quote comedian Tom Lehrer: ‘Life is like a sewer. What you get out of it, depends on what you put into it.’ AI does not know you; it does not know your ambitions; it does not know your motivations to undertake a Global Opportunity; and does not know all that you have done in the past. Asking generative AI to produce a personal statement without feeding it in-depth information about you and your planned opportunity, will only produce extremely generalised statements. Such (im)personal and generalised statements always score badly.
Second, when reading multiple applications, scorers can often spot common themes and phrases. Likewise, a scorer can easily cut-and-paste a personal statement into and online AI detector, which will give a percentage score on the likelihood a statement is AI generated. A scorer may award lower marks if they find that your personal statement is written largely or entirely by something other than you.
Reading applications - a case study
A scorer can ask AI to generate a sample answer to the application questions set. The AI generated answer may then give an indication of words, phrases or themes that could indicate an AI generated submission. Since most applications are submitted through an online form, the spreadsheet populated by the form can then be filtered by these phrases to identify applications that may warrant further investigation. For example:

In the above example, a 'sprinkling' of a few additional words, such as 'research' or 'diverse' fails to hide that at least four separate applications have the same structure, tone and form.
Another step a scorer may take is to enter text (suspected of being AI) into an AI and/or plagiarism checker.  An AI checker looks at the characteristics of sentences (such as length, word choice and predictability), whereas a plagiarism checker will find text copied from other sources. These are available freely online and often produce a percentage score about how confident the checker is that a text was AI generated. We do not outright ban AI in Global Opportunity applications (see below), however, we respect the prerogative of scorers to give low marks to applications that they suspect to have heavily drawn on AI.
When may use of AI be appropriate?
Global Opportunities are open to students from all backgrounds and nationalities. Almost everyone has used an MS Word spell checker at some point. Asking an AI tool to 'proof read in British English' would be appropriate use (just as asking a friend or relative to proof read would be) as the original 'generation' of the text was by the human applicant.
Concluding thoughts
Reading AI generated applications is incredibly boring. They tend to be samey, predictable and frustrating even if there is a smattering of personal lines between the AI sentences. Trust your talents! Make the effort and take the time to write applications yourself, as this way you will stand out for the right reasons."
4,University of Cambridge,04_cambridge.rtf,https://www.cambridgeinternational.org/exam-administration/cambridge-exams-officers-guide/phase-3-coursework-and-moderation/generative-ai-in-coursework/,"The use of generative AI in coursework

This policy statement sets out Cambridge International’s position on the use of generative artificial intelligence (AI) in student work submitted for assessment as coursework. It applies to all Cambridge International qualifications.
1. Principles
We recognise that generative AI programs of various kinds have the potential to provide a valuable resource for students and can support the learning process as students research, design and plan coursework projects.
However, the inappropriate use of generative AI to create or enhance student work without acknowledgement risks being classed as plagiarism and, like other forms of malpractice, may be subject to penalty. (See the Cambridge Handbook (PDF, 6MB)(""https://www.cambridgeinternational.org/Images/700835-cambridge-handbook-2024.pdf"") section 5.6.)
As with our existing guidance relating to the submission and authentication of coursework, the primary responsibility for identifying any inappropriate use of generative AI by students remains with centres and teachers who know the students best. Teachers must keep student work submitted for assessment as coursework under supervision and must be able to authenticate it as the candidate’s own original unaided work. (See the Cambridge Handbook (PDF, 6MB)(""https://www.cambridgeinternational.org/Images/700835-cambridge-handbook-2024.pdf"") section 3 on 'Coursework and moderation)
 All use of generative AI programs to conduct initial research, create text, images, sound or video or plan a project must be acknowledged in the work and AI-generated material must be clearly referenced. Mark schemes and assessment criteria will not award credit specifically for the use of generative AI and there is no expectation that candidates will use AI (unless the ability to demonstrate the use of AI is one of the constructs being assessed) to support their learning or production of work (unless the use of AI is identified as an assessment objective within the syllabus). The only credit will be for the way the candidate has made use of the material produced in this way, in the same way that merely citing sources in a bibliography does not of itself deserve credit.
Using AI appropriately to support their work will not give the candidate an advantage over any other way of initiating research or planning a project.
2. Acceptable use of generative AI in student work
The following uses of generative AI programs by students in the preparation of material for submission as coursework are acceptable if clearly acknowledged in the work:
To carry out initial research into a topic in preparation for a written study. This is no different from consulting published articles or books or browsing in a search engine and citing websites visited in the bibliography. Candidates should clearly state the prompt or series of prompts they used, the name and version of the generative AI program used and when it was accessed. Candidates should check any websites cited by AI and include discussion of the reliability of any material identified, for example explaining how they have accounted for potential bias in a response or how they have checked for accuracy. Candidates should be made aware that AI programs can sometimes ‘hallucinate’ non-existent sources.
To quote briefly from AI-generated text within an essay and engage in critical discussion of the quotation. (We suggest a limit of two or three sentences or about 50 words in a single quotation. The use of longer AI-generated material is likely to be self-penalising if candidates do not fully engage in critical discussion of it.) Quotations must be clearly acknowledged and identified within the candidate’s writing, and like any other source of evidence should be contextualised and reviewed. Students might do this to help them identify core aspects of a question or outline the issues involved, but credit will only be awarded for their own work and judgements in response to the AI-generated material and other appropriate sources of evidence.
3. Guidance for teachers
This guidance should be read in conjunction with existing guidance on Preventing Plagiarism – guidance for teachers. Teachers are also advised to consult new guidance: Artificial intelligence and teaching, learning and assessment(""https://www.cambridgeinternational.org/support-and-training-for-schools/artificial-intelligence/index.aspx"").
Teachers must authenticate coursework as the candidate’s own unaided work. Where teachers suspect plagiarism or inappropriate use of AI they should not authenticate the work and should be prepared to investigate further.
We will take appropriate action if we suspect work submitted for coursework is plagiarised or has been produced using AI inappropriately. This will include treating the work, and in some cases its authentication, as malpractice and opening an investigation.
Advice on how to guard against inappropriate use of AI by students.
Keep drafts and plans of coursework under supervision. A sudden significant development of earlier work, for example a handwritten draft being presented in typed format with markedly improved content, should be questioned by the teacher. Material which is written in a different style in terms of vocabulary and syntax from work that the student characteristically produces may also invite investigation. Students can be asked to explain unusual vocabulary or concepts or comment on what they read in any academic references cited.
Work produced partly or completely by AI is likely to be strong on evidence and information and weak on analysis and evaluation or the expression of a distinctive point of view. There may be unexplained or illogical sequences of material, or a series of false endings/starts indicating the AI program has been prompted to provide more material.
Other potential identifiers include:
an uncharacteristically high level of accuracy of spelling, punctuation and grammar
a lack of any references after 2021
a consistent use of Americanised spelling conventions in a candidate not normally spelling in this way
discourse markers followed by a comma used to start paragraphs (However, / In conclusion,)
journalistic collocations (phrases uncharacteristic of student writers such as ‘disaster relief efforts’)
Latinate vocabulary
pleonasm (use of more words than is necessary) or tautology (saying the same thing twice)
repetition of content or ideas or whole phrases.
Sources
This guidance has been developed in the light of the JCQ document AI Use in Assessment: Protecting the Integrity of Qualifications(""https://www.jcq.org.uk/exams-office/malpractice/artificial-intelligence/"").
See preventing plagiarism(""https://www.cambridgeinternational.org/support-and-training-for-schools/support-for-teachers/teaching-and-assessment/plagiarism/index.aspx"") for more information and support."
5,University of Oxford,05_oxford.rtf,https://www.ox.ac.uk/research/support-researchers/research-practice/policy-generative-ai-research,"Policy for using Generative AI in Research: guidelines for researchers and professional staff
Why a policy?
Generative Artificial Intelligence (GenAI) is a fast-evolving technology that offers tremendous opportunities and, as with all new technologies, comes with risks. The University of Oxford wishes to enable and support the safe and productive use of GenAI by the Oxford research community.
The aims of this policy are to ensure the responsible use of GenAI in research and to provide clear guidelines for its integration into the research process. The policy is supported by, and should be read alongside, a list of FAQs for the policy on generative AI in research(""https://www.ox.ac.uk/research/support-researchers/research-practice/faqs-policy-generative-ai-research"") that provides good practice advice covering different parts of the research process.
The University promotes adherence to relevant funder and publisher policies and supports the Concordat to Support Research Integrity. In preparing this policy, we have drawn on existing funder policies, and guidelines from funders, publishers, and scholars (list of sources(""https://www.ox.ac.uk/research/support-researchers/research-practice/policy-generative-ai-research#sources"")), and where funder policies exist, we have referenced these.
The policy and FAQs were shaped, through roundtable meetings, by researchers who use GenAI in research and domain experts, working with the academic divisions and the AI Competency Centre; the Research Practice Sub Committee (RPSC) reviewed the policy and FAQs(""https://www.ox.ac.uk/research/support-researchers/research-practice/faqs-policy-generative-ai-research"").
Users are advised to interpret the use of GenAI in the context of research practice standards on transparency, rigour and respect; data protection, intellectual property and export control legislation; and information security and compliance guidance. Use of GenAI is also dependent on the fitness for purpose of the relevant tool in terms of functionality and performance. Users are advised to choose the tool that is most relevant for their discipline and application, and to be aware that both technology and practice will evolve over time.
Use of GenAI in research is within the scope of research conduct, and actions that are found to be in potential breach will be reviewed in line with the University's Code of practice and procedure on academic integrity in research(""https://hr.admin.ox.ac.uk/academic-integrity-in-research""). 
The University has guidelines in place on using GenAI in communication, and a policy on the use of AI in summative assessment(""https://academic.admin.ox.ac.uk/ai-use-in-summative-assessment""), setting out the expectations for those setting summative assessment and for students undertaking summative assessment.
This policy is archived in ORA (Oxford University Research Archive) at https://dx.doi.org/10.5287/ora-e9a8pkoeo(""https://dx.doi.org/10.5287/ora-e9a8pkoeo""), and the text is free for others to use and adapt. 
Scope of the policy
The policy encompasses the substantive use of GenAI in the research lifecycle, particularly, in applying for funding, conducting research, disseminating and sharing research outputs, and review and assessment, but also its use in research management to enhance service provision and support strategic insight. Researching GenAI, and training (configuring) and fine-tuning GenAI models, are out of scope of this policy.
Substantive use is defined as using GenAI in research to:
		interpret and analyse data (including audio and image files) and texts,
		undertake a literature review or translation,
		identify research gaps,
		formulate research aims,
		develop hypotheses,
		assist with generating ideas or to develop one’s own thinking,
		generate code and synthetic data,
		undertake transcription of interviews, meetings etc. to save time and effort rather than overcoming barriers (see exclusions below)
		produce documents using other people’s work or from transcripts or recordings.
Substantive use excludes using GenAI for tasks such as assisting non-native speakers with translation, transforming transcribed spoken language to written language by users who face barriers to writing, formatting documents, or improving one’s own standard of English or a foreign language.
See glossary(""https://www.ox.ac.uk/research/support-researchers/research-practice/policy-generative-ai-research#glossary"") for definitions of other terms used in this policy.
This policy applies to all researchers, i.e. members of the University, including staff and students, who are conducting research, and those who are not members of the University but who are conducting research on University premises (including in overseas research units), or using University facilities or funding for their research, such as visiting staff, fellows, students and contractors. It also applies to Professional staff, University staff who in some capacity support research, e.g. research facilitators, technicians, IT support staff, library staff, and administrative support staff.
The policy also applies to all internal research funding schemes managed by Research Services, Divisional Offices, and departments.
Expectations from users of generative AI in Research
All researchers and professional staff supporting researchers are expected to meet the expectations below, and to comply with relevant funder and publisher policies, and professional guidelines. In addition, researchers are expected to follow the guidance in the GenAI FAQs(""https://www.ox.ac.uk/research/support-researchers/research-practice/faqs-policy-generative-ai-research"") document that sets out good practice in the research process.
Professional staff supporting researchers might be interested to use GenAI in order to simplify and improve the operational efficiency of processes, and the speed and quality of analysis; to accelerate the production of documents for different audiences, including summaries; to provide more accurate and targeted guidance to funding applicants.
Professional staff should consult the GenAI FAQs(""https://www.ox.ac.uk/research/support-researchers/research-practice/faqs-policy-generative-ai-research"") document and when supporting researchers, ensure they are aware of any restrictions to the use of GenAI in research.
All users should:
1   Remain ultimately responsible for GenAI content used in research
Users of GenAI tools are accountable for the integrity of the content generated by, or with the support, of these tools, maintaining a critical approach to using the output produced by GenAI and an awareness of the tools’ limitations, such as hallucinations, or social biases that may be embedded in training data, which could perpetuate misrepresentation of social categories, protected groups, or historical inaccuracies.
2   Understand the implications of uploading material subject to Intellectual Property Rights
Users might be considering whether to upload published or unpublished work, i.e. work protected by copyright and related rights, to a GenAI tool for analysis, or a submitted manuscript or grant application, when acting as a reviewer. Uploading published or unpublished work may constitute a breach of copyright, if it cannot be covered by a copyright exception, e.g. non-commercial research and private study, or criticism and review. Users are advised to ensure the tool being used will not use the uploaded content for training purposes or finetuning the model, and are recommended to use ChatGPT Edu, which is governed by an agreement between the University and OpenAI; experienced users may prefer a locally deployed model. Further guidance is available in the University’s guide to copyright or through emailing copyright@bodleian.ox.ac.uk(""mailto:copyright@bodleian.ox.ac.uk"").
3   Follow information security advice on using generative AI safely
While many popular generative AI tools are cloud-hosted services, locally deployed models may also be available for use. Cloud-hosted services present specific confidentiality and disclosure risks since data is accessible to the service provider and potentially other third parties. Information that is commercially sensitive and where the Intellectual Property is unprotected, or is subject to a confidentiality agreement or export control, or personal data, should only be uploaded to a generative AI tool when confidentiality can be guaranteed. Users should consult Information Security and Information Compliance advice, use a locally deployed model or ChatGPT Edu, governed by an agreement between the University and OpenAI, or contact the AI Competency Centre(""https://staff.web.ox.ac.uk/ai-and-machine-learning-competency-centre"") for guidance. Uploading personal data is considered processing, needs to comply with data protection legislation and, when done as part of undertaking research, requires ethics approval. 
4   Declare use of GenAI in research and communicate openly
When employing a discrete GenAI tool, rather than where GenAI is a functionality in existing software, users should declare the substantive use of GenAI tools in their work. Declarations could include the name, version, date, and how it was used and affected the research process. If relevant, users must make the input (prompts) and output available, in line with open research principles.
5   Aim for reproducibility/transparency and robustness in results and conclusions
Users should consider the probabilistic nature of GenAI tools, which includes the tendency to produce a different output from the same input. Cloud-hosted third-party models inherently present a reproducibility and transparency issue, as they are continuously updated with new versions, cannot be archived and do not make their training data available. Locally run models and fully open models offer a better alternative, where feasible and appropriate, to improve reproducibility and transparency. Users should disclose or discuss in methods or acknowledgements, or an additional section determined by the guidelines or policies of the funder or publisher, the limitations of, and interactions with, the GenAI tools used and mitigation measures, e.g. validating outputs, iterative prompting by systematically refining and adjusting the prompts to improve the quality of outputs.
6   Learn how to use GenAI tools responsibly to maximise their benefits, including by undertaking training
GenAI tools are evolving quickly, and new ways to use them are regularly discovered. Users should make use of the training, guidance and advice offered by the University and other reputable sources to stay up to date on good practice. Users might be interested in the University’s Generative AI Special Interest Group (SIG) on Teams run by the AI Competency Centre(""https://staff.web.ox.ac.uk/ai-and-machine-learning-competency-centre"") as a source for finding out about emerging practice and new releases, and to ask specific questions.
7   Be mindful of the environmental impact of using GenAI tools
Building GenAI models is extremely energy-intensive, while the energy consumed through the use of the resultant tools depends on the task’s complexity and whether it involves image generation or reasoning. Where feasible and appropriate, users are encouraged to favour smaller, locally run GenAI models for routine or low-complexity tasks; this can reduce the environmental and data privacy impacts of remote, cloud-based AI use. Users should consider whether a local AI model, a non-GenAI tool or intelligent automation, is fit for purpose before opting for large, cloud-hosted models.
Support provided by the University
The University will support users in meeting the expectations set out above, by providing:
		Through the AI Competency Centre(""https://staff.web.ox.ac.uk/ai-and-machine-learning-competency-centre"") and Generative AI at Oxford, up-to-date and informed support, advice and information to users on all aspects of using GenAI in research, with more in-depth support for tools selected for their suitability in research, education and administration
		Through Research Data Oxford(""https://researchdata.ox.ac.uk/""), advice and guidance on use of research data with GenAI
		Through the Advanced Research Computing service and the Biomedical Research Computing(""https://www.medsci.ox.ac.uk/for-staff/resources/bmrc"") facility, advice on running locally deployed models
		Through the Compliance team(""https://compliance.admin.ox.ac.uk/"") in the Assurance Directorate, guidance and support to ensure compliance with data protection legislation
		Through the Information Security (InfoSec) team(""https://www.infosec.ox.ac.uk/"") in the Assurance Directorate, guidance and support to ensure the use of GenAI does not pose a cyber-security threat
		Free ChatGPT Edu(""https://openai.com/index/introducing-chatgpt-edu/"") access for all staff and students, offering the ability to use GenAI for research and to collaborate with other users across the University, while protecting data used and generated
		Training to enable all staff and students to use the capability of GenAI tools in research and to promote best practice; training provided by the AI Competency Centre and the Bodleian Libraries(""https://www.bodleian.ox.ac.uk/ask/workshops#/"")
Sources of related guidance and policy are listed at the end of this policy.
Policy implementation and reviewing mechanisms
This policy and supporting FAQs are published on the Research Practice pages, with links to the policy and FAQs on the Research Support webpages and the AI at Oxford website(""https://www.ox.ac.uk/ai-oxford"").
A policy advisory group will, on a termly basis, undertake a review of the policy, as the use of GenAI will change over time with certain uses becoming universal and new uses emerging; it will also review the FAQs(""https://www.ox.ac.uk/research/support-researchers/research-practice/faqs-policy-generative-ai-research""), including commissioning the development of new FAQs and the removal of redundant FAQs. 
Recommendations by the policy advisory group that do not materially alter the policy, e.g. additional clarification to scope and expectations, new levels of support and minor changes to existing levels of support, updates to glossary, list of existing University policies and guidance, and sources may be approved by the Co-Chairs for RPSC and submitted for noting to RPSC. Substantial changes will be reviewed by RPSC, which may refer the matter to Research and Innovation Committee for approval, or approve the change itself, in accordance with RPSC’s Terms of Reference.
Policy advisory group membership: Dominik Lukes, Lead Business Technologist for AI Competency Centre, Oxford e-Research Centre; Chris Morrison, Head of Copyright and Licensing, Bodleian Libraries; Rowan Wilson, Head of Research Computing and Support Services, IT Services; Dr Sara Ratner, PI of the AI in Education at Oxford University (AIEOU) Interdisciplinary Hub and post-doctoral researcher on the Learning in Families through Technology (LiFT) project, Education; Professor Eleanor Stride, Professor of Biomaterials, Engineering Science and the Nuffield Department of Orthopaedics, Rheumatology and Musculoskeletal Sciences; Dr Hazem Zohny, Senior Research Fellow in Practical Ethics, Neuroscience, and Society, the Oxford Uehiro Centre for Practical Ethics.
Glossary of terms
Fully open models|Class 1 models within the three-tier Model Openness Framework (MOF) are the gold standard in reproducible research practice; MOF has 17 components to fulfil completeness of model artefacts, covering code, data, and documentation that are part of the model development lifecycle as well as sharing that enables reproducibility, auditing, and downstream use. https://arxiv.org/pdf/2403.13784(""https://arxiv.org/pdf/2403.13784"")|
Generative AI (GenAI)
 |Novel and rapidly developing AI models and tools that identify patterns and structures in data and generate novel content such as text, images and other media in response to instructions (‘prompts’).|
GenAI model
 |A computational system trained on existing data that can generate new content or novel variations of existing content when provided with additional input. A model is created through training on existing data and documents. The learned patterns and relationships in a model are stored as model 'weights'. If these weights are available publicly then it is an open-weight model, such as Meta’s LLaMa or OpenAI’s CLIP models. If the weights are not available publicly then it is a closed-weight model, such as OpenAI’s GPT-4 or Google’s Gemini-2.5.|
GenAI tool|The interface through which a user can interact with a GenAI model, sending instructions to the model and receiving generated outputs. Common examples include ChatGPT (powered by GPT models), which began as a text-to-text interface but now supports image-to-text and text-to-image capabilities. Similar tools include Claude and Meta AI's chatbots.
		Tools can be hosted by a third party or by the maintainers of a model; ChatGPT is an example of a model hosted by the maintainers
		HuggingFace is a popular website that hosts research, open-weight, and industry models; many models can then either be run locally or run in interfaces on HuggingFace or other third-party websites
		It is possible in many cases to download and run models on one’s computer or on University servers, i.e. a locally run model, and thereby creating a GenAI tool, but this depends on the size of the model, the specifications of the computer/server, and context-specific resources like technical know-how and internet hosting capacity.|
Hallucinations|GenAI outputs that might initially appear to be believable but are in fact highly inaccurate or untrue, e.g. references that sound plausible but do not exist; a common characteristic of AI language models when producing responses based on limited or incomplete knowledge. Sometimes also termed confabulation.|
Information Compliance|Means compliance with data protection legislation, i.e. any personal data needs to be processed in an open, accurate way and in accordance with the UK’s data protection legislation.
When using GenAI involves processing of personal data, you will be required to consult the data protection by design framework; if this processing is part of undertaking research, you should obtain research ethics approval(""https://researchsupport.admin.ox.ac.uk/governance/ethics/"").
The data protection by design framework often includes the completion of a Data Protection Impact Assessment (DPIA): the processing of personal data is of a type identified by the Information Commissioner’s Office (the ICO) as likely to result in a high risk to individuals.|
Information Security|Means safeguarding the integrity, availability, and confidentiality of information assets within the University. 
In the context of information security, information is classified as either: public, internal or confidential.  Where a GenAI tool is an application connected to a third-party system or a website, information security considerations come into play when data that is internal or confidential is transmitted.
		The supplier of the GenAI tool should be on the University’s third-party security register(""https://www.infosec.ox.ac.uk/working-third-parties""), which assesses the regulatory and data compliance of external services. New suppliers may require the completion of a TPSA (Third Party Security Assessment)
		The University periodically engages in licensing agreements with third parties that will facilitate the secure sharing of documents and has agreements with OpenAI for ChatGPT Edu and with Microsoft for CoPilot for Microsoft 365
		Users who have a personal account on ChatGPT should not transmit any internal or confidential information to ChatGPT (such as research data), but obtain a ChatGPT-Edu account via the University and read the InfoSec guidance on using GenAI services safely(""https://www.infosec.ox.ac.uk/use-generative-ai-services-such-as-chatgpt-safely"")|
Large Language Models (LLM)
 |A type of machine-learning model designed for natural language processing tasks such as language generation; LLMs are language models with many parameters, and are trained with self-supervised learning on a vast amount of text, from a variety of sources, including public sources; feeding data or text into an LLM is likely to become part of its training data and may show up for other users of the model; LLMs are also used in symbolic systems studies that might not seem to be languages, e.g. LLMs trained on genomic datasets for genome analysis|
Substantive use
 |Using GenAI in research to:
		interpret and analyse data (including audio and image files) and texts,
		undertake a literature review or translation,
		identify research gaps,
		formulate research aims,
		develop hypotheses,
		assist with generating ideas or to develop one’s own thinking,
		generate code and synthetic data,
		undertake transcription of interviews, meetings etc. to save time and effort rather than overcoming barriers etc.
		produce documents using other people’s work or from transcripts or recordings.
 
Substantive use excludes using GenAI for tasks such as assisting non-native speakers with translation, transforming transcribed spoken language to written language by users who face barriers to writing, formatting documents, or improving one’s own standard of English or a foreign language.|
Users|Collective term for researchers and professional staff.|
 
 
Relationship with existing University policies and guidance
		Academic Integrity in Research(""https://hr.admin.ox.ac.uk/academic-integrity-in-research"") 
		Research Ethics Policy(""https://researchsupport.admin.ox.ac.uk/governance/ethics/committees/policy"") 
		Open Access Publications Policy(""https://openaccess.ox.ac.uk/oapp"") 
		Research Data Management Policy(""https://researchdata.ox.ac.uk/research-data-management-policy-full-text"")
		Intellectual Property Policy(""https://governance.admin.ox.ac.uk/legislation/statute-xvi-property-contracts-and-trusts)%20and%20Regulations%20(https://governance.admin.ox.ac.uk/legislation/council-regulations-7-of-2002"")
		Environmental Sustainability Strategy(""https://sustainability.admin.ox.ac.uk/environmental-sustainability-strategy"") 
		Data Protection Policy(""https://compliance.admin.ox.ac.uk/data-protection-policy/"") 
		Information Security Policy(""https://www.infosec.ox.ac.uk/guidance-policy"") 
		Publication and Authorship Guidance(""https://researchsupport.admin.ox.ac.uk/governance/integrity/publication"")
		Export Control Guidance(""https://researchsupport.admin.ox.ac.uk/policy/export"") 
		Open Research Statement(""https://www.ox.ac.uk/research/support-researchers/open-research"")
 
List of sources
Funder statement and policies
		Funders joint statement: use of generative AI tools in funding applications and assessment(""https://wellcome.org/who-we-are/positions-and-statements/joint-statement-generative-ai"") 
		UK Research and Innovation (UKRI) policy on use of generative artificial intelligence in application preparation and assessment(""https://www.ukri.org/publications/generative-artificial-intelligence-in-application-and-assessment-policy/use-of-generative-artificial-intelligence-in-application-preparation-and-assessment/"") 
		Wellcome policy on use of generative artificial intelligence when applying for Wellcome grant funding(""https://wellcome.org/grant-funding/guidance/policies-grant-conditions/use-of-generative-ai"")
		Cancer Research UK (CRUK) policy on the use of generative artificial intelligence tools in Cancer Research UK funding applications(""https://www.cancerresearchuk.org/funding-for-researchers/applying-for-funding/policies-that-affect-your-grant/policy-on-the-use-of-generative-ai-tools-in-cancer-research-uk-funding-applications"") 
Guidelines and guidance
		International Association of Scientific, Technical & Medical Publishers (STM) Ethical and practical guidelines for the use of generative AI in scholarly communications(""https://www.stm-assoc.org/wp-content/uploads/STM-GENERATIVE-AI-PAPER-2023.pdf"")
		Guidelines for ethical use and acknowledgement of large language models in writing(""https://doi.org/10.1038/s42256-024-00922-7"")  
		CRUK guidance for researchers on the use of generative AI (""https://www.cancerresearchuk.org/sites/default/files/cancer_research_uk_guidance_for_researchers_on_the_use_of_generative_ai.pdf"")
		European Commission’s Living guidelines on the responsible use of generative AI in research(""https://research-and-innovation.ec.europa.eu/document/2b6cf7e5-36ac-41cb-aab5-0d32050143dc_en"")"
6,Imperial College London,06_imperial.rtf,https://www.imperial.ac.uk/admin-services/library/learning-support/generative-ai-guidance/,"Generative AI guidance

About Generative AI
Generative AI tools automatically create content, including text, code, images, and more, based on user prompts. Examples include ChatGPT, Google Gemini, and Microsoft Copilot(""https://www.imperial.ac.uk/admin-services/ict/self-service/connect-communicate/office-365/microsoft-copilot/""). Text-focused tools are known as Large Language Models (LLMs) and use collections of existing data to predict outputs. They offer rapid content generation but can produce unreliable outputs, making them unsuitable for unverified academic use.
Appropriate academic use of generative AI
Consider use of AI outputs as a starting point for research only and rely on academic sources such as databases and peer-reviewed sources. Developing critical thinking and evaluation skills is a key aspect of your education at Imperial. 
If you use generative AI as a search tool, be sure to verify all information and cite any material you use for academic purposes.  
Guard against AI “hallucinations” by fact-checking every statement before use. 
Preserve your own voice in written work - uncritical AI use often yields generic, superficial text lacking true insight and will not demonstrate learning or substantial communication. 
For support in developing your academic and scientific writing, consult Imperial’s Centre for Academic English guidance on GenAI(""https://www.imperial.ac.uk/academic-english/cfae-guidance-on-genai/"") and access the support they provide. 
Imperial guidance and support 
Review your department’s current policy on using and disclosing generative AI in academic work. 
Consult your Subject Librarian(""https://www.imperial.ac.uk/admin-services/library/subject-support/"") and library resources for advice on evaluating and selecting scholarly sources. 
Refer to the guidance below as well as the library’s reference management pages(""https://www.imperial.ac.uk/admin-services/library/learning-support/reference-management/"") for acknowledgement and referencing guidance. 
Unless explicitly authorised, using AI to create assessed work may be treated as an offence such as contract cheating under Imperial’s Plagiarism, Academic Integrity & Exam Offences(""https://www.imperial.ac.uk/student-records-and-data/for-current-students/undergraduate-and-taught-postgraduate/exams-assessments-and-regulations/plagiarism-academic-integrity--exam-offences/"") regulations. 
Familiarise yourself with Imperial’s Academic Misconduct Policy(""https://www.imperial.ac.uk/media/imperial-college/administration-and-support-services/registry/academic-governance/public/academic-policy/academic-integrity/Academic-Misconduct-Policy-and-Procedure-v1.3-15.03.23.pdf"") for rules on appropriate AI usage. 
Acknowledging and referencing  use of generative AI tools
Acknowledging
A statement of acknowledgment shows the reader which AI tool you used and for what specific purpose. You should include a statement to acknowledge your use of generative AI tools for all assessed work, in accordance with guidelines from your department or course team.  
This statement should be written in complete sentences and include the following information: 
Name and version of the generative AI tool e.g. Copilot, ChatGPT-5 
Publisher (name of company that provides the AI system) e.g. Microsoft, OpenAI 
URL of the AI tool 
Brief description (single sentence) of the way in which the tool was used (e.g. summarising notes, generating outlines)
Confirmation that the work is your own 
Example: 
I acknowledge the use of ChatGPT-5 (OpenAI,  https://chatgpt.com(""https://chatgpt.com/"")) to generate an outline for background study. I confirm that no content generated by AI has been presented as my own work. 
Further requirements may be stipulated for a particular piece of assessed work where AI tools are allowed or required. This must be made clear to students when it is set. If unclear, please clarify with your module leader. Additional requirements may include expanded description in the ‘Acknowledgements’ or ‘Methods’ section, such as:
If relevant, the prompt(s) used to generate a response in the AI system.
The date the output was generated.
The output obtained (e.g. a ‘link to chat’ if ChatGPT, or a compilation of all output generated as an appendix).
How the output was changed for use or incorporation into a piece of work (e.g. a tracked-changes document or a descriptive paragraph).
Referencing
Referencing guidance is provided for Harvard and Vancouver referencing styles on the following pages: 
Your reference list and bibliography – Harvard(""https://www.imperial.ac.uk/admin-services/library/learning-support/reference-management/harvard-style/your-reference-list/"") 
Your reference list and bibliography – Vancouver(""https://www.imperial.ac.uk/admin-services/library/learning-support/reference-management/vancouver-style/your-reference-list/"")"
7,University of Bath,07_Bath.rtf,https://www.bath.ac.uk/announcements/new-principles-agreed-for-using-generative-artificial-intelligence-in-education/,"New Principles Agreed for Using Generative Artificial Intelligence in Education
Senate has recently agreed to align the University to a set of high-level Generative AI (GenAI) Principles in Education developed by the Russell Group
News story
Published on Wednesday 8 November 2023
Last updated on Wednesday 8 November 2023
View more announcements in Centre for Learning & Teaching(""https://www.bath.ac.uk/announcements/?f.Department+or+group%7CX=Centre+for+Learning+%26+Teaching"")
Following a meeting of Senate on the 8th November 2023, the University has adopted a permissive approach to GenAI in Education in order to minimise the risks and maximise the future benefits. It agreed to align the University to a set of high-level principles adopted by the Russell Group(""https://russellgroup.ac.uk/news/new-principles-on-use-of-ai-in-education/"") of universities, and to work collectively as a community to:
Support students and staff to become AI-literate.
Equip staff to support students to use generative AI tools effectively and appropriately in their studies.
Adapt teaching and assessment to incorporate the ethical use of generative AI and support equal access.
Ensure academic rigour and integrity is upheld.
Work collaboratively across the sector to share best practice as the technologies and their application in education.
Work is already underway – led by two groups with representation from across the institution (one academic and one professional services). More information can be found on the Teaching hub(""https://teachinghub.bath.ac.uk/ai-and-education/""), but a summary is presented below, and more specific communications are planned in the next few weeks.
Key Developments
We have updated our academic integrity statement, related Quality Assurance documents, and generic guidance for referencing and acknowledging(""https://teachinghub.bath.ac.uk/guide/genai-and-referencing/"") the use of AI tools in assessments.
Course teams retain full academic freedom to decide if, and to what degree, students are permitted (or not) to use GenAI in assessments.
Where students are allowed to use GenAI tools, they are NOT permitted to pass off any content created by GenAI tools as if it were their own work.
The Skills Centre(""https://unihub.bath.ac.uk/students/login?ReturnUrl=%2fstudents%2fworkflows%2fDetail%2f185"") has produced a self-paced module on AI Literacy for students, and a similar resource will be developed for staff.
In response to potential uncertainty around students’ permitted use of GenAI in assessments, and in recognition that this may be different depending on the requirements of specific subject disciplines’ learning outcomes, EQSC has recently approved a simple tool and light-touch approach(""https://teachinghub.bath.ac.uk/guide/genai-and-assessment/"") to enable staff to review their coursework.
The tool can be used to help colleagues to classify and communicate their current course assessment portfolio according to 3 types of GenAI usage. This will help to ensure greater clarity and transparency for students. The tool can also be used to help us better future-proof our assessments by identifying any quick wins to minimize risk and/or longer-term opportunities to develop, or change, assessments in light of GenAI. This approach aligns with existing work on CT (notably Assessment for Learning) and is intended to complement existing assessment plans.
We are currently working with the Associate Deans (Education) and Education Managers to ensure a joined-up approach to the review, to plan development sessions for staff and further communications. This will be announced in the new few weeks; in the interim, the CLT have organised a series of talks from external experts(""https://teachinghub.bath.ac.uk/events/clt-edutalks-ai-and-the-future-of-student-learning-nigel-francis/"").
We have discussed our approach with the Students’ Union via the Student Representatives, and they have helped to inform our plans and guidance.
Finally, we are working closely with DDAT to review a range of GenAI tools, potential licensing requirements and costs, data privacy concerns and to keep a watching brief on Microsoft’s Co-Pilot tools(""https://blogs.microsoft.com/blog/2023/09/21/announcing-microsoft-copilot-your-everyday-ai-companion/"") (if/when announced for Higher Education).
Please note: at present we have ruled out using so-called AI Detector Tools. The evidence so far indicates these are fundamentally flawed in concept, do not work effectively, and are prone to bias against certain groups(""https://arxiv.org/abs/2304.02819"") or individual characteristics. Staff must not upload student work into such tools as this may compromise students’ intellectual property and personal data.
Enquiries
The Centre for Learning & Teaching
clt@bath.ac.uk(""mailto:clt@bath.ac.uk"")
Find out more on Generative AI(""https://teachinghub.bath.ac.uk/guide-category/generative-ai/"")"
8,University of Warwick,08_Warwick_history.rtf,https://warwick.ac.uk/fac/arts/history/students/undergraduate/ai/,"This page explains the History Department's approach to Artificial Intelligence (AI). This guidance will help you to understand when it is appropriate (or not) to use AI in your History assignments.
Non-generative AI tools, such as spelling-checkers or basic grammar-checkers, have been widely used for many years. For instance, Microsoft Word telling you that you have misspelled a word is not going to lead to accusations that you have used AI tools inappropriately.
AI-based generative language tools (e.g., ChatGPT), are different from non-generative tools. Generative AI tools are trained to produce a human-like response from pre-existing large data sets (e.g., websites, journals, textbooks, etc.). Responses are not necessarily correct, despite often sounding authoritative.
A good simple rule to follow is that you MUST NOT use generative AI tools (e.g., ChatGPT) to create content (text or concepts) that is presented as your own work. You MAY use non-generative tools, such as a spelling-checker or basic grammar-checker. The most important thing to remember is that you must be able to demonstrate intellectual ownership of your work. If you have further questions, you can speak with your Personal Tutor or Year Director.
AI and the Study of History
Historians take a deliberative approach to studying the past, critically assessing their sources as well as scholarship in the discipline. Many of the skills you are learning(""https://warwick.ac.uk/fac/arts/history/students/undergraduate/specification/"") in history, including critical thinking, analysis, synthesis, a sensitivity to the strangeness and unknowable nature of the past, attentiveness to complexity and contingency, the deployment of evidence, and the development of your individual voice, cannot be replaced by artificial intelligence. As you develop these skills over the course of your degree, it is vital that you maintain, and can demonstrate, intellectual ownership of your work.
Generative AI tools undoubtedly possess great potential, but they must be treated with caution as there are various issues and dangers with using them, especially for history, where the processes of reading, thinking, and writing are so intertwined. Generative AI, when unable to provide an accurate answer, can have a tendency to simply invent things – whether footnotes, quotations, or “facts.” Google admits that Gemini, its AI technology, ""may display inaccurate info, including about people, so double-check its responses."" In terms of history research, there are also illuminating examples of the possible pitfalls of relying on AI rather that seeking out sources yourself. See for example: Ned Benton, ‘Artificial Intelligence and Slavery Research’(""https://nesri.commons.gc.cuny.edu/artificial-intelligence-and-slavery-research/"").
The use of Generative AI for writing can also have the effect of flattening creativity and individuality. This piece by Curtis Sittenfeld(""https://www.nytimes.com/2024/08/20/opinion/beach-read-ai.html"") (£) demonstrates how AI-created writing can be “proficient on a sentence level but… shallow in sentiment.” Much of history learning is about learning to write, so it is crucial that you demonstrate your own individual voice in your assignments.
Appropriate and Inappropriate use of AI
The most important thing to remember is that you must always be able to demonstrate intellectual ownership of your work. The History department’s current position is that the generative AI must always be used in a responsible and open manner, and use of AI must be acknowledged in a statement at the start of your essay.
Individual assignments may have specific instructions regarding the use of AI that differ from those in this handbook. You should ensure that you follow these closely, and if you have any questions, contact your seminar tutor.
Appropriate use of AI:
You MAY use non-generative tools, such as a spelling-checker or basic grammar-checker.
You may find it useful to use AI to help you organise your thoughts, test out ideas, or explain concepts to you in simpler terms, in the same way that you might speak to your seminar tutor for guidance on these issues. If you use an AI tool to help you generate ideas, make sure that you critically reflect on what it is telling you: generative AI does not have the same level of expertise in history as your seminar tutor, and may not give the best advice.
It may sometimes be appropriate to use generative AI to translate source material from one language to another. However, such translations should be handled with great care as they are sometimes inaccurate and misleading.
Inappropriate use of AI:
AI can be a useful took when preparing your assessments, but you should ensure that you do not use AI in place of your own learning or thought processes. Intellectual ownership of your work includes critical reflection and analysis, for example in the development of your argument or structure. Your essays should always be written in your individual voice, rather than the voice of a machine.
A good rule of thumb is that you should not use AI for any part of your assessments that you would not ask another human to do. You wouldn’t ask your friend to plan your essay for you, or to come up with an argument for you, or to rewrite a paragraph for you, so don’t use AI for these tasks either.
Acknowledging use of AI
You should acknowledge any use of AI in the same way as you acknowledge any other sources that you use for your assessments. You will have to confirm in your declaration of originality at the point of submission that the work remains yours and you have intellectual ownership of it.
If a generative AI has been used in the process of completing an assessment, you should clearly state in your submission:
WHY you used a generative AI;
WHAT it was used for;
WHICH AI and what prompts were used;
Appropriate use of AI will not result in any penalty, but your marker may comment on your use of it.
AI should NEVER be used to gain an unfair advantage or to create content which is presented as your own work. This is Academic Misconduct(""https://warwick.ac.uk/fac/arts/history/students/undergraduate/assess-plagiarism/"")."
9,University College London,09_UCL.rtf,https://www.ucl.ac.uk/students/exams-and-assessments/assessment-success-guide/engaging-generative-ai-your-education-and-assessment,"Engaging with Generative AI in your education and assessment
Guidance on how you might engage with Generative AI (GenAI) in your assessments effectively and ethically.
 Contents: 
GenAI and academic integrity(""https://www.ucl.ac.uk/students/exams-and-assessments/assessment-success-guide/engaging-generative-ai-your-education-and-assessment#GenAI%20and%20academic%20integrity"") 
How to acknowledge GenAI use in your work(""https://www.ucl.ac.uk/students/exams-and-assessments/assessment-success-guide/engaging-generative-ai-your-education-and-assessment#How%20to%20acknowledge%20GenAI%20use%20in%20your%20work"")
More resources(""https://www.ucl.ac.uk/students/exams-and-assessments/assessment-success-guide/engaging-generative-ai-your-education-and-assessment#More%20resources"")
GenAI is a technique in artificial intelligence in which outputs such as text, images, code, music, and video are generated by software. GenAI is potentially transformative as well as disruptive, and GenAI tools will feature in many academic and professional workplaces. Rather than seek to prohibit your use of them, we will support you in using them effectively, ethically and transparently.  
However, it may not always be appropriate to use GenAI. Whilst they are attractively powerful and easy to use, GenAI tools can provide misleading or incorrect information.  They can also negatively impact your learning by reducing the need for critical engagement that is key to deep and meaningful learning. Additionally, you need to be aware of the difference between reasonable use of such tools, and at what point their use might be regarded as giving you an unfair advantage.  
Visit the Generative AI Hub For more details on how GenAI works, the ethical implications and limitations of the tools and the ways in which you can use them, please visit the Generative AI Hub. The Generative AI and Academic Skills Moodle(""https://moodle.ucl.ac.uk/course/view.php?id=34355"") course provides a more in-depth look at GenAI in an academic context.
GenAI and academic integrity
Academic misconduct is strictly prohibited, including the use of essay mills, homework help sites, plagiarism, collusion, falsification, impersonation or any other action which might give me an unfair advantage.  
An unfair advantage is:  •    when you hide something and aren't transparent about your approach.  •    when you take something directly from someone (or something) else and don't reference or acknowledge it.  •    when you don't follow the assessment guidance. 
It is not acceptable to use GenAI tools to write your entire assessment and present this as your own work. Words and ideas from GenAI tools are making use of other human authors' ideas without referencing them, which is considered by many to be a form of plagiarism.
Using GenAI tools to check your grammar or spelling is usually appropriate if the tool is not rewriting a large proportion of your work. Similarly, tasks such as ideas generation or planning may be an appropriate use. For all assessments, your context and the nature of the assessment must be considered.
Your teachers will give guidance on: •    what ways (if at all) you are permitted to use GenAI. •    which aspects of your work it is appropriate (or even expected) that you use GenAI for.
If you are unsure about what constitutes acceptable use of GenAI in an assessment, ask for clarification from the module leader. If no explicit instructions are given, the default for assessments should be that you use GenAI in an assistive role while making sure that the final submission is still substantially your own work.
Staff resources on how to guide students on the use of GenAI in assessments can be found on the Generative AI Hub(""https://www.ucl.ac.uk/teaching-learning/generative-ai-hub""). Category 2 describes in more detail how GenAI might be used in an assistive role.
UCL does not use GenAI detectors when marking. Instead, if a marker has any concerns about your work, they may speak to you to get more information. You should not automatically assume this means that they suspect you of academic misconduct.
Inappropriate use of GenAI is viewed as plagiarism. This is defined as the representation of other people’s work or ideas as your own without appropriate referencing or acknowledgement. This includes the use of GenAI tools that exceeds that permitted in the assessment brief.
If teaching staff suspect that you are trying to pass off GenAI output as your own work then the regulations in the Academic Manual (""https://www.ucl.ac.uk/academic-manual/chapters/chapter-6-student-casework-framework/section-9-student-academic-misconduct-procedure"")(9.2.5 a), 9.2.5 e) iii, and 9.2.6 c) may  apply. You may be invited to an investigatory viva to probe the authorship of your work.
How to acknowledge GenAI use in your work
You should acknowledge GenAI use where it has been used to assist in the process of creating your work.
The Library Skills pages(""https://library-guides.ucl.ac.uk/referencing-plagiarism/acknowledging-genAI"") share guidance on how and when to acknowledge GenAI in your work."
10,University of Bristol,10_Bristol.rtf,https://www.bristol.ac.uk/bilt/sharing-practice/guides/guidance-on-ai/,"University guidance on Generative AI in Education
This guidance sets out the University of Bristol’s approach to using generative AI on taught degree programmes. The responsible use of generative AI is foundational to our educational vision to inspire students, and to equip well-rounded graduates with skills for the future. Here we set out an approach for the responsible use of generative AI, identifying how best to make use of its potential to support learning, and how to guard against learning losses. Generative AI should not replace activities that develop intellectual rigour, student agency, and students’ capacity to work through complex problems themselves. As an institution that prides itself on pursuing sustainability and contributing to the public good, we need to embrace a principled approach to generative AI, being aware of the environmental impacts(""https://www.bristol.ac.uk/bilt/sharing-practice/guides/guidance-on-ai/using-ai-in-assessment/other-considerations-when-using-ai/""), risks of bias and stereotyping, and ethical concerns about data privacy and security.   

The responsible use of generative AI means being prepared to set the agenda for how we see its value in teaching, learning, and assessment, and being transparent with students about when and why using generative AI is appropriate and supports their learning. We need to define its use, rather than letting it define how we and our students use it. Generative AI should not replace activities that are central to learning key concepts in a discipline. Research shows that using generative AI tools in a beneficial way for learning is contingent on students’ understanding the questions and concepts they are studying. Generative AI cannot replace the hard work of getting to grips with threshold concepts in a discipline. At the same time, it can offer support to students, co-piloting with them in novel ways, sense-checking, summarising, and guiding students with structuring ideas. It can simplify concepts to be more digestible for students, helping them to find their way with more complex theories, readings, and tasks.  It can also save time on more menial tasks, if prompted correctly.   
Large Language Models (LLMs) which make up common generative AI tools like ChatGPT, Google Gemini, or Microsoft Copilot can synthesise huge quantities of content from the internet, at pace. This can mislead users into believing in generative AI’s innate intelligence, and its capacity to synthesise and understand the meaning of the content it generates. From an educational perspective, its focus on knowledge and content is unhelpful. It detracts from the intellectual practices and skills that students need to display in their learning: original thinking, creativity, problem-solving, and higher order thinking. Moreover, generative AI reproduces bias and stereotyping, hallucinates, and makes mistakes. It requires discernment and the critical faculties of a human being to evaluate outputs generated by artificial intelligence. This is why we need a principled and responsible stance for its use, or we risk selling students short of the skills and knowledge that they need to graduate with a worthwhile degree from the University of Bristol.  
Our Guidance
This guidance is for all staff who teach and support learning. Across the university, staff are using generative AI to different extents in their teaching and assessment. Many of the recommended actions set out in the guidance may already be in use by academics on programmes and units of study.  Our guidance sets out the University’s position on generative AI as part of ongoing conversations in schools and faculties, and at University Education Committee. It seeks to establish a common framework for a more consistent and systematic approach for using generative AI which allows for creativity and experimentation. The guidance directs you to sources of support, BILT’s educational development projects on AI in teaching and Assessment, and the work of BILT Associates on the same; the Study Skills resource on using AI for students(""https://alt.content.bris.ac.uk/bbcswebdav/courses/Study_Skills/using-ai-at-university/index.html?source_domain=www.ole.bris.ac.uk&_gl=1*18vbg50*_ga*MTkzNjgxMDExNS4xNjc0NDc0NTgy*_ga_6R8SPL3HLT*MTcyNjQyNzc5OC4yOC4xLjE3MjY0Mjc4NzQuNTMuMC4w""), and further reading.   
		Our Key Messages (""https://www.bristol.ac.uk/bilt/sharing-practice/guides/guidance-on-ai/our-key-messages/"")
		Our Commitment to the Russell Group Principles (""https://www.bristol.ac.uk/bilt/sharing-practice/guides/guidance-on-ai/our-commitment-to-the-russell-group-principles/"")
		How might students be using AI to support their learning? (""https://www.bristol.ac.uk/bilt/sharing-practice/guides/guidance-on-ai/how-might-students-be-using-ai-to-support-their-learning/"")
		Using AI in Assessment (""https://www.bristol.ac.uk/bilt/sharing-practice/guides/guidance-on-ai/using-ai-in-assessment/"")

Contact
For more information or guidance, please contact ai-education@bristol.ac.uk(""mailto:ai-education@bristol.ac.uk"").

Our Key Messages

Our Commitment to the Russell Group Principles

How might students be using AI to support their learning?

Using AI in Assessment


Our Key Messages
School and Faculty Education Directors are encouraged to: 
Talk to staff and students about categories(""https://www.bristol.ac.uk/bilt/sharing-practice/guides/guidance-on-ai/using-ai-in-assessment/"") of AI use in assessment and discuss the default category of AI use (minimal) for the types of assessments commonly used in their disciplines. 
Review the use of Turnitin AI writing detection within their area of responsibility and decide whether to persist with its use until the next university checkpoint at the end of 24/25. 
Programme and unit teams are encouraged to:  
Provide students with clear guidance on the category(""https://www.bristol.ac.uk/bilt/sharing-practice/guides/guidance-on-ai/using-ai-in-assessment/"") of AI use permitted for each assessment, working within any school- or faculty-level positions 
Review your assessments(""https://www.bristol.ac.uk/bilt/sharing-practice/guides/guidance-on-ai/using-ai-in-assessment/review-your-assessments/"") for susceptibility to student AI use and refine accordingly. 
Talk to students about the learning objectives(""https://www.bristol.ac.uk/bilt/sharing-practice/guides/guidance-on-ai/using-ai-in-assessment/encouraging-students-to-be-ethical-and-transparent/"") of their unit/year of study, and the ways in which various uses of AI within their learning and study may or may not support the achievement of those objectives 
Recommend that students use Microsoft Co-pilot through the Edge browser as the default, universally available generative AI tool, where one is needed. 
Engage in playful and experimental use of generative AI with students, where this fits the purpose of your teaching and will support student learning.  
All staff are asked not to: 
Upload student work to externally-hosted AI tools, unless this tool has been authorised for use by IT Services. Please contact your IT Business Partner if you are unsure whether this is the case. 
Input any data rated as confidential or above – through the University data classification schema - which includes any sensitive or personal information to any AI tools, unless these have been provided by IT Services having gone through appropriate processes to protect University IP and to meet our legal, contractual and framework obligations. 
Use AI to mark or generate staff feedback on student work, unless this has been discussed in advance with your SED/FED and the AI in education team at ai-education@bristol.ac.uk(""mailto:ai-education@bristol.ac.uk"") who may enable you to undertake an authorised pilot.  
We've created four categories to consider where you assessment lies in regard to integration of AI. Read more about them here(""https://www.bristol.ac.uk/bilt/sharing-practice/guides/guidance-on-ai/using-ai-in-assessment/"").
Our Commitment to the Russell Group Principles
The University contributed to and is committed to the principles about generative AI that the Russell Group set out in 2023/24. These principles are useful in guiding us to continue to advance human knowledge and creativity and to seek to benefit from generative AI in educating students.   

The Russell Group Principles(""https://russellgroup.ac.uk/media/6137/rg_ai_principles-final.pdf"") are:  
Universities will support students and staff to become AI-literate.   
Staff should be equipped to support students to use generative AI tools effectively and appropriately in their learning experience.   
Universities will adapt teaching and assessment to incorporate the ethical use of generative AI and support equal access.   
Universities will ensure academic rigour and integrity is upheld.    
Universities will work collaboratively to share best practice as the technology and its application in education evolves.
The implications of these principles are that the University needs to support staff and students to have a basic familiarity with generative AI and to be discerning about when it enhances learning, and in contrast, when it holds students back from being agents of their own learning. The principles require us to set a level playing field for students in their access to AI tools, and to uphold academic integrity by designing assessments that minimise the risk of its unauthorised use. Implicit in the principles is our responsibility to create a learning environment characterised by trust, dialogue, and transparency about using generative AI. We also need to be mindful of the environmental impacts of the technology in deciding when to permit or recommend it. 
How might students be using AI to support their learning?
Generative Artificial Intelligence (genAI) is a type of AI that creates new outputs from existing data on the internet using pattern recognition. It generates text, data, code, images, graphs and data visualisations, videos, podcasts and other artefacts at speed in response to prompts. Teachers in higher education are both excited and cautious about the implications for student learning. Used well, it could support students with aspects of their learning, introduce more excitement, and speed up the pace of certain types of work; used poorly, it could homogenise and take away students’ confidence, agency, and the development of their authorial voice and expertise. It could deskill students by offering shortcuts. It is therefore important for us to ensure that we prepare to students to harness the benefits and see the downsides of using generative AI to support their learning. Using generative AI is contentious, with some being more in favour of its use than others. A good starting point for considering how it can impact education is to review the Study Skills tutorial(""https://studyskills.blogs.bristol.ac.uk/2023/10/25/741/"") that has been developed for our students. This explains in more detail what generative AI is, how students can use it in a positive way, but also outlines the limits we are setting to ensure that it does not by-pass the learning outcomes of an assessment, for example. 

Here are some typical examples of how students use AI, some of which you may want to encourage, and others you may want to discourage depending on the nature of the tasks they are undertaking:  
Generating informal podcasts based on challenging curriculum content in order to engage in the content in more accessible ways  
Summarising academic papers 
Rewording challenging concepts into accessible language 
Generating feedback on drafts of essays, sometimes with reference to rubrics 
Generating question prompts based on content so that students can test their knowledge 
Creating study plan schedules to maximise efficiency 
Please talk to your students about the skills and knowledge that they should be building through your units and programme, and the ways in which these uses of AI may help or hinder them from achieving that. It is important that students are clear about when they can and cannot use generative AI in their learning and assessment.  
Using AI in Assessment
Assessment requires students to demonstrate knowledge and skills outlined in the intended learning outcomes of a unit, measuring the extent to which they have demonstrated their learning. As generative AI becomes more embedded in our software, and students become more familiar with its capabilities, they may use it to complete aspects of their assessment. Students can use generative AI without detection, to the detriment of their learning, and in breach of our academic integrity policy.  
We may also see the potential for using generative AI in certain assessments and want to integrate it fully or allow some limited use of it in students’ preparing for an assessment or undertaking it.  
Here we set out our agreed categories of generative AI use in assessment which you should discuss with your students, clearly signposting how you expect them to use (or not use) generative AI and explaining why.    

Categories of generative AI use in assessment
In this section, we set out four categories for generative AI use in summative assessment, to be determined in line with the type of assessment, and as part of our assessment strategy. The categories are:  
Category 1: Prohibited – no use at all, not even spell- and grammar-checkers, e.g. in person invigilated exams.  
Category 2: Minimal – for example, using spell and grammar checkers to help identify mistakes but not rewrite chunks of text. This is the default permitted level of use and is consistent with the position outlined in the student-facing academic integrity pages.  
Category 3: Selective - AI tools can be used in limited and clearly defined ways (per assessment), e.g. exploring concepts, suggesting structure, summarising key ideas etc – depending on the purpose of the assessment, and using AI as a tutor in the process of developing an assessment. (Further examples are provided in the AI allowable usage briefs.) 
Category 4: Integral – the use of AI tools is an integral part of the assessment, for example prompting outputs that students critique and improve on using human intelligence. 
In line with our current academic integrity policy, the default category is Category 2: Minimal and only if a unit director has stipulated another category will a different category apply. Despite the existence of this default position, we strongly suggest that you tell students which category each assessment is, as part of the assessment brief (see templates below). You should also explain to students the pedagogical rationale for choosing a particular AI use category. 
Examples of assessment brief descriptions using the above categories are available here: AI Allowable usage briefs (PDF, 252kB)(""https://www.bristol.ac.uk/media-library/sites/bilt/documents/AI%20Allowable%20Usage%20Briefs.pdf"").  Please ensure that you review the marking criteria and rubric to check that these fit with your chosen position on the use of AI."
11,University of Strathclyde,11_Strathclyde.rtf,https://www.strath.ac.uk/professionalservices/educationenhancement/qualityassurance/useofgen-aiinlearningassessment/,"Education Enhancement
Use of Gen-AI in learning & assessment

Student FAQs
What is Generative AI and how does it work?

Generative AI or Gen-AI are tools or services that create content for users in response to prompts they've been given. Gen-AI tools and services generate content, such as text, images, or music, or translate between languages based on the data they were trained on, the prompts they are given, and the algorithms they are programmed to work to. This short module(""https://canvas.sydney.edu.au/courses/51655"") built by students at the University of Sydney, provides a helpful introduction to Gen-AI and explains how it works.

Which Gen-AI tools can students use?

There has been huge growth in the number and range of Gen-AI tools and services (and other tools and services which have incorporated Gen-AI into their processes) over the past few years. Whether you can or should use a particular Gen-AI tool or service will depend on a number of factors, including the nature of the task you are facing, the learning objectives that are associated with that task, and your Department’s expectations around how you should complete that task. Your module and/or programme leader will make it clear whether or not the use of Gen-AI in general and any Gen-AI tools or service in particular is permitted when they explain the task they are asking you to complete.
There are a wide range of Gen-AI tools and services available, most of which require an account and/or subscription. The only Gen-AI tool that the University currently allows staff and students to sign-up to with their University credentials is Microsoft Copilot in Edge. You can access this through the Edge browser when you are signed into to your University Microsoft account. Please note that at the time of publishing this guidance, students who are under the age of eighteen are not permitted to use Microsoft Copilot in Edge while logged into their University Microsoft account. If this condition changes, this guidance will be updated and students and staff will be informed. Staff and students will also have access to the in-built Zoom AI Assistant while using Zoom. You should follow the guidance provided by their module and programme leaders on when the use of this tool is (and isn’t) appropriate in their studies.      
You should be aware that there are risks associated with using any Gen-AI tool, especially those that they are signing up to without the University’s explicit knowledge and support. Guidance on using Gen-AI tools safely and responsibly and some critical questions about using Gen-AI are provided in the additional resources section of this page. You should read this guidance before using any Gen-AI tools in their learning and assessment tasks.
Finally, you should note that the recent growth in the availability of (often) free to access Gen-AI tools may not last forever, and that charges for use and the disappearance of tools and services are always possible. This means that any dependency on these tools or services that is built up now could be damaging to your learning and development in the future.

Does the use of Gen-AI compromise my academic integrity or mean that I am cheating?

Not necessarily, but you should always ensure that you are aware of the expectations of the module or programme leader around the use of Gen-AI and understand what is required of you in any given learning or assessment task. Consult your module handbook and Myplace site for guidance and ask for clarification if you need it.

Can Gen-AI help me to learn?

Gen-AI tools, used carefully and responsibly, could be helpful in a wide range of learning contexts. Gen-AI tools may help you understand some concepts, or create study materials, summarise complex topics, and so on, but you should always be aware of the fact that Gen-AI tools can be biased, inaccurate and misleading in their outputs. Ensure that you are always thinking critically about information you know has been produced using Gen-AI and fact check anything you intended to rely on. You also need to be sure that you are not undermining the learning process. Follow the guidance that your module or programme leader has provided for you, they will have thought carefully about the learning or assessment task and will know whether the use of Gen-AI is (or isn’t) appropriate in that context.  

Can I use Gen-AI to help me with writing and creating other content I will submit for an assessment?

The work you submit for assessment should always be your own. Depending on the context, the use of Gen-AI may be permitted, but not always, so you should ensure that you know what is allowed. If you are not sure, ask your module or programme leader for guidance.
While Gen-AI tools can write and create other content quickly, and sometimes this content is impressive, there can be significant flaws in these outputs, including (among other things) inaccuracies in information, harmful biases, and issues with focus and structure. You should not assume that Gen-AI content is perfect or even good enough or that the act of creating it has helped them to learn. Staff guidance on the use of these tools and services to create content in relation to a particular learning or assessment task should be followed. This guidance reflects the staff members’ experience and expertise in the subject you are studying and has been given to support students’ learning and development.  

What is meant by thinking critically about Gen-AI output?

Gen-AI tools and services are prone to offering responses which contain inaccurate or biased or misleading information. Gen-AI tools can also generate fake references that look genuine and may even contain some correct details such as real author names or journal titles. Always check the original source to verify outputs. Do not simply accept Gen-AI outputs as fact or authority.
Make sure that you question assumptions and claims; fact-check key points; seek out diverse perspectives; evaluate the strengths and weaknesses of arguments, and think about how the information has been presented, including the structure and tone of the writing. This critical thinking requires subject or ‘domain’ knowledge which you will be developing through your studies and will help you ensure that you continue to develop a well-rounded understanding of the material you are studying.
In short, do not allow any Gen-AI tools or services to think for you or create work which isn’t yours or the result of your efforts.

Is it ethical to use Gen-AI?

Before using Gen-AI tools or services, there are a number of ethical questions you should consider. Six of the most important questions are outlined in the Essential Questions to Consider document below. The University takes a principled approach to the use of Gen-AI in all Learning and Teaching contexts. These principles can be viewed below in the Principles document. All uses of Gen-AI by students (and staff) should align with these Principles. Ultimately, the question of how ethical it is to use Gen-AI tools and services will depend on a range of contextual factors. In general, however, use of Gen-AI when it undermines important learning and assessment outcomes, when it might be considered unnecessary or frivolous, when it is used to mislead or deceive in any way, not disclosing the use of Gen-AI when this is required, and in any circumstances where the module or programme leader has prohibited its use could be unethical.

What are the consequences of unethical Gen-AI use?

Unethical use of Gen-AI undermines your learning and could even contribute to the erosion of trust and compromise the quality of the higher education system. Where the misuse of Gen-AI has been identified, the University’s Academic Misconduct Procedure will be followed, which could lead to a range of penalties for any individual who is found to have committed academic misconduct. Ensure that you follow assessment instructions and University policies at all times.

Is my data safe and secure when I use Gen-AI tools and services?

Gen-AI tools may collect user data. Read privacy policies carefully and avoid sharing Personal, sensitive or copyright protected information. Make sure you are not giving any tools or services access to restricted or copyright protected content including materials provided to you by the University (for example lecture slides, assessment questions or feedback on assessment, library resources or research papers).

What are the legal considerations with Gen-AI?

Gen-AI models can generate content that may infringe upon existing intellectual property rights, such as copyright. To ensure that you do not do anything unlawful, you should follow the advice and guidance provided to you by your Department and the University.  This Generative AI and Copyright libguide(""https://guides.lib.strath.ac.uk/copyrightandgen-ai"") provides an overview of copyright and privacy issues.

What are the university’s policies on using Gen-AI?

The University’s guidelines on academic integrity(""https://www.strath.ac.uk/professionalservices/educationenhancement/qualityassurance/academicintegrityguidance/"") can be found on the website. You should check this guidance regularly and especially whenever you are completing a new piece of work involving Gen-AI, as it is a rapidly evolving area, and the guidance may have changed since you last checked it. You should also check the rules and guidance for each individual assessment as these may vary. Details will be published in programme and module handbooks and Myplace pages.

Where can I get help with Gen-AI tools?

The University has provided a range of guidance and support through this FAQs page and the related resources. An introduction to Gen-AI can be found on MyPlace(""https://classes.myplace.strath.ac.uk/enrol/index.php?id=28666""). If you have further questions or concerns, you should contact your module or programme leader for help."
12,Loughborough University,12_Loughborough.rtf,https://www.lboro.ac.uk/students/handbook/assessments/assessment-information/generative-ai/,"Requirements for acknowledging, describing and referencing the use of Generative AI tools in assessed work
Generative Artificial Intelligence (AI) refers to the use of AI to create new content, such as text, images, music, audio, and videos. There are many Generative AI tools, but common tools are ChatGPT, Microsoft Copilot, DALL.E and Google Gemini.
You are expected to practice good scholarship and uphold academic integrity in all of your assessments. This involves being honest and transparent about any elements of your work or ideas which have come from elsewhere. Often this will be other academic sources, such as published papers, which you may feel used to referencing, but this also includes output from Generative AI.
If you have used Generative AI tools when producing your work, it is important that you acknowledge this when submitting your work for assessment. This includes if you have used it to generate materials for background research and independent study, or if you have used it to produce materials which you have subsequently adapted and included in your work.
If you are suspected of inappropriately using AI or have failed to acknowledge its use, this will be regarded as academic misconduct by the University and you will be referred to one of its Academic Misconduct Committees. 
If using AI tools to correct spelling and grammar, you must follow the Guidance note for Proofreading Written Work and you should acknowledge their use when submitting your work for assessment.
Academic Misconduct(""https://www.lboro.ac.uk/students/handbook/assessments/assessment-information/academic-misconduct/"") Guidance on Proofreading Written Work(""https://www.lboro.ac.uk/students/handbook/assessments/coursework-feedback/proofreading/"")
(Step 0. Check what's allowed)
Before you start each assignment, always check the assessment brief which will outline how you are and aren’t allowed to use GenAI in that particular piece of work. You can contact your Module Leader if you have any questions about this.

Step 1. Save your AI outputs and drafts of your work
You must retain the developmental work (plans, drafts, sketches etc.) that you have produced when working on your assignment so that you can demonstrate, if requested, the process you undertook to produce the work submitted for assessment.
For example, if you used Generative AI tools as your initial background search, you must keep the outputs they generated and (if requested) be able to show through a version history how you developed and moved on from the content to create your own independent work.

Step 2. Acknowledge the use of Generative AI tools
If you have used Generative AI tools when producing your work for assessment, you must include a statement in your work, acknowledging their use by naming the tool(s) and how it was used, using the following statement:
I acknowledge the use of (insert name of AI tool(s) and link) to generate materials for background research and independent study and/or that I have adapted to include within the work submitted for assessment. I confirm that all use of AI content is acknowledged and referenced appropriately.

Step 3: Describe their use
You must describe how the information or material (including images, computer code, video content etc) was generated, including the prompts you used, and how the output was changed by you. You do not need to submit the AI outputs as part of your declaration, however you must keep copies of these as outlined in Step 1. You should use the following style of wording, depending on the nature of use:
The following prompts were input into (name of AI tool: [Provide details]) 
Full detail of how the output was adapted: (explain how you adapted the output for use in your work) 

Step 4. Reference them correctly
When the content created in Generative AI tools cannot be replicated by another person and cannot be linked to, in many referencing styles you must reference the outputs in the same way that you would a personal communication or correspondence.
Since this is a fast-evolving area, please ensure you follow up-to-date guidance on Cite Them Right(""https://www.citethemrightonline.com/search-results?any=generative%20ai"") or provided by your School/department for referencing content created in Generative AI tools. Where School or department guidance is available, this should take precedence. 
For example, at the time of writing (October 2025), referencing content only available to you in the Harvard Style is as follows according to Cite Them Right Online(""https://www.citethemrightonline.com/sourcetype?docid=b-9781350927964&tocid=b-9781350927964-217&st=ai""):
In-text Citation:
Format: (Corporate Author, Year)
Example: (OpenAI, 2025)
Reference list:
Format: Name of AI (Year) Medium of communication to Receiver of communication, Day Month of communication.
Example: OpenAI (2025) ChatGPT response to John Stephens, 2 April.
Link to CiteThemRight for generative AI

More guidance on Academic Integrity
The University's guidance on Academic Integrity shows you how to conduct your academic work:
Demonstrate honesty in your work – if we read something that does not seem trustworthy, we are unlikely to engage with it effectively
Take responsibility for the research you undertake and the skills you need to develop
Conduct ethical practice and make good choices throughout your degree
Fairly give credit to others when using their words and ideas to support your arguments and research
This includes the GenAI checklist which you should be using to ensure you use GenAI responsibly.
Study with Academic Integrity(""https://www.lboro.ac.uk/students/academic-integrity/"")"
13,University of Sheffield,13_sheffield.pdf,https://sheffield.ac.uk/saas/elevate/ai-principles,"The University of St Andrews is a charity registered in Scotland, No: SC013532 UNIVERSITY OF ST ANDREWS  GENERATIVE AI – FAQs FOR STUDENTS    1. What is generative AI?   o It is artificial intelligence (AI) technology that actively generates content based on patterns learned from existing data in response to prompts.     2. How can I access AI tools?   o AI tools are available in an open format online, such as ChatGPT, DALL-E, Claude  o They are provided by online platforms, such as Google Cloud AI   o They are accessible via software, such as Microsoft Co-Pilot.  o The University’s provided AI tool is Microsoft Copilot.  This is available to all staff and students, with ‘Commercial Data Protection’ services enabled.      3. What is St Andrews’ standpoint on the use of generative AI for assessment?   o The University is committed to upholding academic integrity, including the prevention of the misuse of Generative AI.   o Skills in selectively utilising Generative AI as a resource will be required by our graduates.  o The University recognises that there are academically justifiable applications of Generative AI in the process of educational research and enquiry.  o The University acknowledges that AI offers students exciting opportunities to develop their academic, employability and life skills, and we are committed to support them to use this technology ethically.   o The University prides itself on developing students with excellent skills in research techniques, project planning, design, and critical thinking. These skills are core to a graduate’s education and cannot be replaced by AI use. Students should be aware of the many risks associated with using Generative AI – see Question 9 below.   o While students may choose to use Generative AI to generate notes, study aids, or other materials that they consider helpful in their learning, this type of usage may not be allowed in specific modules, so students should always check the relevant School or module handbook. Even when this type of usage is allowed, students should be mindful that they are still expected to develop relevant study skills they can employ independently of AI tools.       4. Can Students use AI to produce assessed work?    o Students should not use Generative AI for the preparation and presentation of assessed work unless authorised explicitly by the module co-ordinator. If AI use is permitted, the extent to which it can be used in assessment will be clearly outlined in the module handbook.   o If AI has been used, this should be clearly declared by the student on an assessment coversheet.     5. How does the Good Academic Practice policy address the use of AI?   
 The University of St Andrews is a charity registered in Scotland, No: SC013532 o The Good Academic Practice Policy states that Unauthorised use of AI is a type of academic misconduct.   o Using AI is considered academic misconduct when a student presents the output of an AI technology, such as a large language model (LLM) or paraphrasing application, as their own work without acknowledgment in all situations.   o The University’s position regarding students who submit content produced by Generative AI as their own work is identical to that of any type of plagiarism.   ▪ If a module does not allow Generative AI at all, then any use would be considered a case of Unauthorised Use of AI and, therefore, academic misconduct.   ▪ If a module does not prohibit the use of Generative AI, and yet a student submits content produced by Generative AI as their own work without acknowledgement, this will also be considered academic misconduct.    6. How can I maintain academic integrity when using AI?   o You should only use AI for assessment when you are permitted to by the module co-ordinator.   o If AI use is authorised, it must be cited.   o If AI use is authorised, all prompts used should be retained for reference and should be available to the module co-ordinator on request.  o AI should not be used as a substitute for your own work.     7. How do I acknowledge use of generative AI?   o You should include a declaration statement along with your references stating the AI tool used, describing how you used it, and indicating the date you accessed it.   o Further requirements may be stipulated by a School, academic programme, or individual member of teaching staff, or for a particular assignment, and will be made clear when an assignment is set.     8. How may AI assist me in my studies?  o It can help automate routine tasks, e.g., scheduling, task prioritisation, note management  o It can help improve your time management skills, e.g. you could experiment with asking AI to design a study plan.  o It may help with notetaking and summarisation. Where summation is required as part of formative or summative assessment, AI should only be used with the express permission of the module co-ordinator.     o It can create practice learning exercises.  o It may help practice your evaluation skills by assessing the quality of arguments given, e.g. some people find it helpful to ask a Generative AI based chatbot to critique their own writing.  o It may be used to proof-read for grammatical errors, as directed by your module co-ordinator.  o It may be used to suggest improvements to your writing, as directed by your module co-ordinator.   o It may help explain terms or key concepts in different ways to suit your own individual learning style.  o It may help you to learn new skills.      9. What are the risks of using AI in my academic work?   
 The University of St Andrews is a charity registered in Scotland, No: SC013532 o AI produced content is plagiarised content, and is not your own work, if it is not cited.    o As AI generates content from existing data, it can re-produce content copied from other sources.    o There are risks of copyright infringements on pictures and other copyrighted material.   o AI can generate incorrect data, produce “hallucinations” and out of date data.   o AI summarisation is not always correct and should always be checked for accurateness.  o AI can reproduce biased data.    o The energy required for AI data processing and storage is damaging to the environment, as this uses excessive amounts of electricity and water, as well as rare minerals.   o AI use may hinder a student’s independent thought and problem-solving skills.    o AI may capture data from input prompts, so it is important not to submit personal or sensitive information to an AI tool. The University Data Protection Policy can be accessed here.   o A reliance on Generative AI could impact your ability to develop important skills, including those associated with research design and critical engagement. It may also hinder the development of skills important in situations where AI is not available, e.g. in an exam setting.     10. How do I know that I am using AI?    In most cases, you would deliberately log into AI software (e.g. Co-pilot) and type in your prompt. However, there is now software available (e.g. Grammarly) which uses AI, embedded into it, so you may not be immediately aware that AI is underlying the functions of the software.  Here are some tips to help you identify if software uses AI:  • Check the Software’s Website: Look for mentions of AI, machine learning, or natural language processing. These terms often indicate AI usage.  • Read Reviews and Articles: Reviews and tech articles can provide insights into whether a software uses AI.  • Look at Features: Features like predictive text, automated suggestions, and real-time feedback are often powered by AI.  • Contact Support: If in doubt, reach out to the software’s customer support for clarification.  • University Resources: Consult IT guidelines – See https://www.st-andrews.ac.uk/it-support/services/software/students/    11. How can I determine if AI is allowed in my assessments?   o Read your School and module handbook and ask your module co-ordinator if AI use is permitted prior to starting your assessment.       12. Can I use Grammarly in my assessments?    o Grammarly has optional Generative AI features that aid the production of new content based on a series of prompts. These features should be disabled when writing assessments unless expressly permitted by your module co-ordinator or permitted as a reasonable adjustment by the Disability Team in Student Services.     13. Is AI detection software used at St Andrews?    o No.  Whilst Turnitin has developed AI-detection, this has not currently been  switched on at the University of St Andrews due to concerns over accurate detection. The Quality Assurance Agency (QAA) advised that universities should ‘be cautious in your use 
 The University of St Andrews is a charity registered in Scotland, No: SC013532 of tools that claim to detect text generated by AI and advise staff of the institutional position. The outputs from these tools are unverified and there is evidence that some text generated by AI evades detection’.    14. How can AI support disabled students?   o AI tools can provide support for students with physical, visual and auditory impairments   o ‘Use of AI’ is not a standard adjustment included in Student Support Plan, but it can be included should a student request this. Disability Advisers ensure that a student’s support plan is needs-led. If a student has information to suggest AI is needed due to their disability this can be discussed with their Disability Adviser.  o Examples of where AI may be permitted includes for students with Specific Learning Difficulties (SpLD) who may use AI to proofread their work. In such instances, the student should keep the original copies of their own work and drafts, where they haven’t used AI. Students with SpLDs may use generative AI to re-draft and improve sentence structure and phrasing and then combine the two in a finished piece of writing.  o The Scholarcy AI summarisation tool can help with condensing articles/reports/chapters into short summaries, this is helpful for students with SpLDs/ Autism spectrum disorder and underlying medical conditions like chronic fatigue or chronic migraines, where students may need to work in short bursts and take frequent breaks from screens.   o For visual or hearing impairments, one common problem is taking notes.  Glean, a note-taking piece of software, has in-built AI that can record, caption & transcribe lecture content. It can also provide ‘Question cards’ after a lecture, generated from this content.   o Software recommended through Disabled Student Allowance may have AI embedded in it, without you realising (Glean, Grammarly, Scholarcy). If you have been recommended this software as a reasonable adjustment, you may use it to adjust your work. You should not use Grammarly to generate content unless explicitly allowed to do so in your assignment guidance.     15. What should PGR students consider before using AI?   o PGR students considering the use of Generative AI should discuss and agree appropriate scope, boundaries, and applications with their supervisor at the start of the project or before commencing usage.   o Any Generative AI usage should also be highlighted during the annual review process and discussed with the review committee.  o Any use of Generative AI should be acknowledged.  ▪ a) AI use should be cited, and any prompts used, and responses received should be reported in an appendix. It is expected that Generative AI, even when used, will be applied only to specific sentences or paragraphs, and not used more broadly to contribute to the thesis. Extensive usage will still be considered poor academic practice or academic misconduct and investigated accordingly.   ▪ b) Use of AI specifically for language correction should be acknowledged in the same way as any other assistance with writing is acknowledged as per the Language Correction policy. If Generative AI forms an integral part of the research conducted or thesis production (e.g., a Computer Science thesis), a methodological statement must be included in the thesis.    16. How can I learn more about AI?   o IELLI Workshop - Understanding and using AI at University is available through PDMS"
14,University of Exeter,14_exeter.rtf,https://libguides.exeter.ac.uk/referencing/generativeai,"GenAI tools such as ChatGPT can help you in a variety of ways, but it is important that you are aware of how to use them responsibly - in an ethical, appropriate, and transparent way.|
See the AI: Understanding it guide for more information on how you can use GenAI responsibly(""https://libguides.exeter.ac.uk/c.php?g=725611&p=5278338"").|
GenAI Use in Assessments: An overview
From the start of the 2025-26 academic year, the University of Exeter follows a four-tier approach to GenAI use in assessments: 
AI-integrated – where the use of GenAI tools is required by the module’s Intended Learning Outcomes (ILOs) and included in the assessment brief. In AI-integrated assessments, you must include prompts and, where possible, hyperlinks to their output as part of your list of references. The lecturer running your module will explain how AI should (and should not) be used and explain the ILOs in the assessment brief. If anything is not clear, please ask them for clarification. 
AI-assisted -  where you may use GenAI tools ethically and responsibly to assist in the development of an assessment. In AI-assisted assessments, you must include prompts and, where possible, hyperlinks to their output as part of your list of references if you use GenAI tools. The assessment brief will include a checklist of the uses of AI allowed. If anything is not clear, please ask the lecturer running your module for clarification. 
AI-minimal– where you may use AI tools for checking spelling and grammar mistakes only, with no other impact on the structure or content of the assessment.  
AI-prohibited – you must not use GenAI tools as their use prevents achievement of the Intended Learning Outcomes.
For more detailed information on AI use within each assessment category, please scroll down to 'Guidelines for each category of assessment'.
If you are not sure what is expected for a particular assessment after reading all of the information on this page, please speak to your module leader before you complete the assessment. 
 2024-25 AI in assessments guidance(""https://libguides.exeter.ac.uk/ld.php?content_id=35969302"")If your department is still using the 2024/25 AI in assessments guidance, you can review it here. 
Guidelines for each category of assessment
1. Use of AI tools in AI-Integrated Assessments
For AI-Integrated assessments, you are required to effectively use GenAI tools in order to successfully achieve the module’s intended learning outcomes, as per your assessment brief. 
This means: You may use GenAI tools ethically and responsibly in accordance with the purposes in the checked boxes in your assessment brief.
When writing your assessment, you must never use AI tools: 
For uses other than those represented by checked boxes in your assessment brief. 
To translate more than a word or short phrase into English unless agreed in the checked boxes in your assessment brief. 
To upload sensitive or identifying material to an AI tool.
To present material that has been generated by AI as your own work or the work of someone else.   
When submitting your assessment, you must: 
Check the box during the submission process, that confirms you have adhered to the university’s academic conduct policy and the expectations on use of GenAI in your assessment brief. 
Treat the AI tool like a citation from any other source. 
Include a list of all AI prompts and, where possible, hyperlinks to their output with your references, at the end of your work.  You do not need to include the outputs themselves, just the links. 
Retain the full outputs generated by the prompts you have used during your assignment for your records. These outputs should be accessible through the hyperlinks which you have submitted with your assignment. If hyperlinks are not produced through the tools you use, save the AI-generated output in a document that you can easily access later (e.g. on OneDrive). You may be asked to produce this material in the event of an academic conduct inquiry. |
2. Use of AI tools in AI-Assisted Assessments
For AI-Assisted assessments, you may use GenAI tools if you choose to do so. This is because using AI tools in specific ways can assist with your learning and will not inhibit fair assessment of your achievement of the module’s intended learning outcomes.
This means: You may use GenAI tools ethically and responsibly in accordance with the purposes in the checked boxes in your assessment brief.
When writing your assessment, you must never use AI tools: 
For uses other than those represented by checked boxes in your assessment brief. 
To translate more than a word or short phrase into English unless agreed in the checked boxes in your assessment brief. 
To upload sensitive or identifying material to an AI tool.
To present material that has been generated by AI as your own work or the work of someone else.   
When submitting your assessment, you must: 
Check the box during the submission process, that confirms you have adhered to the university’s academic conduct policy and the expectations on use of GenAI in your assessment brief. 
Treat the AI tool like a citation from any other source. 
Include a list of all AI prompts and, where possible, hyperlinks to their output with your references, at the end of your work.  You do not need to include the outputs themselves, just the links. 
Retain the full outputs generated by the prompts you have used during your assignment for your records. These outputs should be accessible through the hyperlinks which you have submitted with your assignment. If hyperlinks are not produced through the tools you use, save the AI-generated output in a document that you can easily access later (e.g. on OneDrive). You may be asked to produce this material in the event of an academic conduct inquiry. |
3. Use of AI tools in AI-Minimal Assessments
You may use AI tools for checking spelling and grammar mistakes only, with no other impact on the structure or content of the assessment.  This is because using GenAI tools outside of these uses prevents fair assessment of your ability to achieve module learning outcomes. 
When writing your assessment, you must never use AI tools: 
For uses other than checking your spelling and grammar. 
To translate more than a word or short phrase into English. 
To upload sensitive or identifying material to an AI tool 
To present material that has been generated by AI as your own work or the work of someone else.   
When submitting your assessment, you must: 
Check the box during the submission process, that confirms you have adhered to the university’s academic conduct policy and the expectations on use of GenAI in your assessment brief. |
4. Use of AI tools in AI-Prohibited Assessments
You must not use GenAI tools under any circumstances when preparing and writing for this assessment.  This is because using GenAI tools prevents fair assessment of your ability to demonstrate module learning outcomes. 
When submitting your assessment, you must: 
Check the box during the submission process, that confirms you have adhered to the university’s academic conduct policy and the expectations on use of GenAI in your assessment brief. |
 Record of AI use template(""https://libguides.exeter.ac.uk/ld.php?content_id=35969900"")This document contains a template that you may use to record your AI use when completing AI-integrated and AI-assisted assignments. You can also create your own document to record AI use if you prefer. 
Academic Honesty and Policy
Academic honesty requires giving full credit to contributions (through proper referencing), never falsifying or fabricating the results of any research, and ensuring that all submitted work is a true representation of one’s own understanding. While AI tools can support your learning, they must not replace your independent thought and original work in assessments. The University needs to assess your knowledge and skills to award degrees. 
The Academic Conduct and Practice policy of the TQA Manua(""https://www.exeter.ac.uk/v8media/specificsites/tqa/apa/APA_Handbook_Chapter_12.pdf"")l clarifies that using AI-generated content should be acknowledged in the same way as that taken from human authors. Misuse of AI generated content can lead to a student being found guilty of one or more of the offences listed in section 12.3 of the policy. This could include: 
 Plagiarism which covers situations where students deliberately or accidentally represent work or ideas as their own without appropriate acknowledgement or referencing, including AI; 
 Misrepresentation includes misrepresenting an AI generated source as your own work;   
Fabrication (creation of false data/references) could also involve material taken from AI tools;  
Falsification if AI is used to manipulate results in an unapproved way. 
Declaring and referencing the use of GenAI
If you are using a GenAI tool as part of your academic work, please check that you have used this guidance on how to declare and reference your use of these tools.  
A. If you are not sure whether and how you can use GenAI in your academic work, please check your assignment brief and discuss with your module convenor.
B. Please be aware that practice and guidance in this area will change over time, so check this guide regularly for the University’s most up to date referencing advice.
C. While GenAI tools can be helpful, they should not be used to generate content which is included in an assessment without following guidance on acknowledging and referencing GenAI. This would be an offence under the University’s Academic Conduct and Practice policy(""https://www.exeter.ac.uk/v8media/specificsites/tqa/apa/APA_Handbook_Chapter_12.pdf"").
D. It is important to note that GenAI tools do not always output accurate information. Outputs are also subject to bias relating to the material on which they were trained. You should therefore verify any information that you plan to use in your academic work, including any references or sources. In addition, any content you generate using a GenAI tool should be critically analysed and evaluated, and appropriately acknowledged and referenced. See advice on the importance of taking a critical approach to AI.(""https://libguides.exeter.ac.uk/c.php?g=725611&p=5278326"")  
See Referencing the use of GenAI(""https://libguides.exeter.ac.uk/c.php?g=693244&p=5313980"") for more guidance.
GenAI and Assistive Technology
The University's guidelines on the use of GenAI in assessments appreciate that assistive technology using AI may have been recommended as part of the Disabled Students Allowance / Apprenticeship Needs Assessment Process.The majority of these tools are allowed even in AI prohibited assignments. If there is any uncertainty with this please check with your Faculty Hub(""https://www.exeter.ac.uk/departments/"").
If you would alike to discuss this further please engage with AccessAbility(""https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.exeter.ac.uk%2Fstudents%2Fwellbeing%2Fdevon%2Fsupport%2Fdisability%2F&data=05%7C02%7CI.Goodchild%40exeter.ac.uk%7C95955773589c420eb4e108dd7c2e68e9%7C912a5d77fb984eeeaf321334d8f04a53%7C0%7C0%7C638803260941609693%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=SHaQN4U1HemX5XUL%2Fwy7D3ZgoPo2VASm9l%2ByjWzb9Os%3D&reserved=0"")."
15,Lancaster University,15_Lancaster.rtf,https://portal.lancaster.ac.uk/ask/study/developing-academic-skills/using-ai-in-your-learning-and-assessment/,"Using AI in your learning and assessment

This page provides information and guidance relating to the use of Generative Artificial intelligence (Gen AI) in learning and assessment. The guidance expands on a set of Principles for the Educational Application of Generative AI(""https://portal.lancaster.ac.uk/ask/administration/policies-regulations/principles-for-the-educational-application-of-generative-ai-/""), developed at Lancaster University to describe our approach to exploring and using these technologies in teaching and learning.     Widespread access to Gen AI tools is relatively new and technologies are rapidly developing in capability and applications. The guidance on appropriate use of AI in learning and assessment is very likely to change as technologies and applications evolve. You should always check that the guidance you are referring to is current and seek advice from University staff if you are unsure whether use of AI is appropriate.  
What is Generative AI? 
Generative AI is a broad label that’s used to describe any type of artificial intelligence (AI) that can be used to create new text, images, video, audio, code or synthetic data (Rouse, 2023). 
These types of AI use algorithms to learn patterns and structures from large amounts of training data and can then apply that learning to generate content. They include Large Language Models (LLM) that can undertake a variety of Natural Language Processing (NLP) tasks such as: 
interpreting and responding to questions or prompts, e.g. chatbots 
translating from one language to another 
generating text and presenting it using different styles and conventions, e.g. create a bulleted list of… or write a poem in the style of… 
analyzing, categorizing, and summarizing text and data 
ChatGPT, Google Bard and Bing Chat are examples of tools based on LLMs. Other types of Gen AI tool are also based on LLMs, but while the inputs you provide are largely text, the outputs are images (e.g. DALL-E 2) or code (e.g. GitHub Copilot). 
It is important to remember that Gen AI tools cannot think or understand natural language, they process and recognize patterns in the text prompts or other data you enter, based on the training data that has been used to develop them. This enables them to provide what can appear to be, but may not be, credible responses. 
Gen AI tools cannot create new content. They generate content based on the information you provide as well as training data and other data available to them. This raises issues relating to accuracy of information and potential bias, intellectual property and copyright, data privacy and ethical use. Read more about these issues below. 
Rouse, M. (2023) Technopedia. Available at: https://www.techopedia.com/definition/34633/generative-ai,(""https://www.techopedia.com/definition/34633/generative-ai,"") (Accessed: 3rd July 2023)
Using Generative AI in your learning and assessment? 
Before you use Gen AI tools to support your learning or prepare for assessment, think about your motivations for doing so. Are you using AI tools with an understanding of their applications and limitations, and being critical of the content they produce, or trying to save time by cutting corners? Are you learning through your interactions with Gen AI? 
When preparing for assessment, think carefully before using Gen AI tools. Assessment often requires that you demonstrate an ability to draw on academic sources, to be creative, critical, and reflective, and that your authentic voice is present in work you submit. 
Where AI tools are used, their use should be appropriate, ethical and with a clear understanding of their limitations. Knowing the limitations of generative AI tools can help you to decide if and how to use them. Used inappropriately to take short-cuts they can negatively impact your learning, limiting the opportunities you have to develop academic skills, critical thinking and creativity. 
For more information on the the use of AI in teaching and assessment, please read the University's position on AI(""https://portal.lancaster.ac.uk/ask/administration/policies-regulations/university-position-on-artificial-intelligence/"").

Researching a topic and literature searching

You might use Gen AI tools to help you explore a new topic and find sources of information. The integration of AI into search engines (e.g. Bing) allows you to use natural language to search the internet and refine your search. 
While Gen AI tools might be a useful starting place for exploring a new topic, providing an overview, or helping you to identify search terms, you should not rely on them as your sole source of information. 
Some tools such as ChatGPT (the free version) are not able to generate content based on access to current web content. The content produced by Gen AI tools can also perpetuate and amplify biases, include factual inaccuracies, and fabricate references. A significant limitation is that Gen AI tools may not have access to academic sources that are often only available via subscription or through an academic library. 
As with any source of information, you should always evaluate the content provided and check it against reliable sources. For further guidance on evaluating sources see the Information Literacy(""https://portal.lancaster.ac.uk/ask/study/developing-academic-skills/information-literacy/"") page. 
Use Onesearch(""https://onesearch.lancaster-university.uk/primo-explore/search?vid=LUL_VU1&lang=en_US&sortby=rank"") and Library databases(""http://lancaster.libguides.com/az.php"") to search for trusted academic literature. 

Writing and text generation

Gen AI tools can generate written text very quickly, providing responses to your questions and prompts in a matter of seconds. You can direct the kind of response you receive and provide written feedback to modify the text generated, e.g. asking for text to be presented in a specific style or format.
Using Gen AI tools to explore different approaches to presenting text, may give you ideas for your own writing but is not a replacement. Remember that the text produced is based on analysis of patterns not on understanding. Developing your academic writing skills and authentic voice are important parts of your learning at university.
Applications for writing may have AI technology built in, e.g Editor in Microsoft Word. These tools can help with recommendations for spelling, use of grammar and sentence construction. Applications such as Grammarly and Wordtune may provide more guidance and recommendations, including suggestions for phrases and sentence construction. 
Translation tools such as Google Translate or DeepL can help you to develop your spoken and written language skills. 
If you are using Gen AI tools as an aid to creating, checking or translating text, as part of preparing for assessment, you must always explain how you have used them and it is essential that you are demonstrably the author of the final text. 

Using translation tools

The language of teaching and assessment at Lancaster University is English (except for the study of non-English languages). 
Throughout the course of your studies, you will be continually improving your use of English in an academic context (in reading and writing, and speaking and listening). 
The use of Gen AI platforms to translate substantial sections of written text into English which is then presented for assessment is not permitted. Examples of these platforms include DeepL and Google Translate. 
Unless otherwise instructed, use of translation software must not be beyond individual words or short phrases being checked for reference (as someone would with a physical dictionary). 
Use of AI translation without permission and disclosure is an act of academic misconduct. 

Summarising, analysing, and presenting information 

Summarising large amounts of information such as lengthy articles, academic papers or large data sets can be a time consuming and laborious process. Gen AI tools can anaylse and interpret patterns in data very quickly and may be a useful aid for extracting key information, identifying trends and themes. You might also use these tools to identify errors and anomalies, for example debugging code. 
Representing data in summary tables or graphically are also tasks where Gen AI tools might be used. As with all other uses, you should be careful not to rely on these as short cuts to learning. Developing skills in summarising and analysing information are an essential part of your academic development. 
Think carefully about the information and data, including research data, you are inputting when using Gen AI tools. This data may be retained and used by the application beyond the purposes for which you entered it. Always check terms and conditions to understand how the data you enter will be used and if it will be retained by the application.
Do not upload personal data(""https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/personal-information-what-is-it/what-is-personal-data/what-is-personal-data/#:~:text=%E2%80%9C%27personal%20data%27%20means%20any,location%20data%2C%20an%20online%20identifier"") to Gen AI, even where it has been anonymised, unless it is your own personal data and is done at your own discretion.

Creativity and design

Using Gen AI tools as an aid to creative and design activities is becoming increasingly common, with a wide range of applications that are able to generate images, audio and video based on the text prompts or other content you provide. 
Features powered by AI are now built into presentation tools you may use such as Microsoft PowerPoint and Canva. AI is also integrated into more advanced creative and design applications where it can be used to generate content from proprietary media collections. 
A wide range of free and subscription-based Gen AI tools have become available for generating images and other media. These tools make use of content drawn from across the internet, often without consideration of intellectual property or copyright. 
AI generated images and other media raise other ethical issues such as concern about deepfake images and video. 
Using Gen AI tools to generate images and other media may be a useful aid in exploring creative ideas or producing illustrative content. You should consider carefully the ethical and legal issues associated with using AI generated media.  
Generative AI and academic integrity 
Academic integrity is a commitment to honest, ethical and fair practice in your academic study. It means ensuring that the work you submit for assessment is an honest representation of your own knowledge and understanding. To do this, you must acknowledge and reference the ideas and work of others (including AI generated content) when you include them in your assignments. 
Using AI tools to help with research, generating ideas for or planning your assessed work may be appropriate but you must never include content provided by an AI tool representing it as your own work. 
You should also be aware that AI tools create content by drawing on material created by others without referencing it. 
Representing AI generated content as your own and failing to reference it appropriately counts as plagiarism and is addressed as described in the University’s Plagiarism Framework(""https://portal.lancaster.ac.uk/ask/download?document=/media/lancaster-university/content-assets/documents/student-based-services/asq/principles-policies-and-guidelines/Plagiarism-Framework.pdf"")  and Manual of Academic Regulations and Procedures (MARP)(""https://portal.lancaster.ac.uk/ask/administration/policies-regulations/marp/"") . 
Acknowledging AI in your assessed work 
If you are permitted to use AI tools in your assessed work, you must acknowledge their use. If AI has been used in research or preparation of assessed work you should identify the tool you used and describe how you used it. This might include details of the inputs/prompts you entered, and the content produced by the AI. 
Where you have included AI generated content in your work directly or derived content from it you must cite and reference the content. For AI tools that generate content with a perpetual weblink you can link to the content in the reference. For conversational tools like ChatGPT you will need to include details of your inputs and the AI responses in an appendix. 
Further guidance on referencing your use of AI tools is available on Cite them right(""https://www-citethemrightonline-com.ezproxy.lancs.ac.uk/""), where you will find examples of how to reference use of Gen AI using all referencing styles in common use at University."
16,University of Birmingham,16_birmingham.rtf,https://intranet.birmingham.ac.uk/student/libraries/asc/student-guidance-gai.aspx,"Student and PGR guidance on using GenAI tools ethically for work
In 'Academic Skills Centre'

What is Generative Artificial Intelligence?
Generative AI tools (GenAI), such as Open AI’s ChatGPT, Google’s Gemini and Microsoft’s Copilot, are advanced learning models which have been trained on vast amounts of diverse data. This pre-training allows them to create new content, including text, computer code, images, and audio. The technology has been around since the 1960s as chatbots, but recent advances now mean these tools are much better equipped to have sophisticated conversations using natural language and are able to produce complex outputs.
The University’s position on using Generative AI 
A framework for use 
The University recognises that the rise of Generative AI is likely to have a profound impact on the ways you learn, research, study and are assessed. Our University, alongside the Russell Group Universities, wants to ensure that Generative AI tools can be used for the benefit of students and staff alike. It is a University priority that you have the knowledge and skills to face an increasingly AI-enabled world. As a result, the University has set out a framework for using Generative AI. This includes a commitment to supporting students and PGRs to become ‘AI-literate’. This will include you knowing how to use the tools effectively, ethically, critically, and transparently.
The appropriate uses of Generative AI tools are likely to differ between academic disciplines, and so support will primarily be provided at School level, where you will be given an opportunity to explore and engage with these tools.
This guidance will be reviewed and continually updated as generative AI technologies develop.
Academic misconduct
Generative AI is a rapidly developing technology and there is still much to learn about using the tools effectively and ethically. Because of this, the University is committed to protecting academic integrity, ensuring that work submitted for assessment continues to be a student’s or PGR’s own. The University’s Code of Practice on Academic Integrity(""https://intranet.birmingham.ac.uk/student/academic-support/registry/legislation/codesofpractice/index.aspx"") sets out what plagiarism is and gives examples of academic misconduct. This includes the misuse of Generative AI tools:    
""1.5. Plagiarism can occur in all types of assessment when a Student claims as their own, intentionally or by omission, work which was not done by that Student. This may occur in a number of ways e.g. copying and pasting material, adapting material and self-plagiarism. Submitting work and assessments created by someone or something else, as if it was your own, is plagiarism and is a form of academic misconduct. This includes Artificial Intelligence (AI)-generated content and content written by a third party (e.g. a company, other person, or a friend or family member) and fabricating data.""  
The Code of Practice stipulates that you cannot use the output of Generative AI (i.e., the content it creates) in any assessment, unless explicitly authorised. This means you would be breaching the Code of Practice if you submit work generated by these tools as your own, or incorporate it into your own work, without explicit permission.
Student and PGR use of Generative AI tools 
Be assured that your School will give you all the guidance you need about when Generative AI tools can and cannot be used in academic work. They will also clearly outline the rationale for its use and explore any ethical or privacy issues that you should be aware of. If you have any questions about the appropriate use of these tools, then do speak to your tutors or supervisors in the first instance.  
Where the use of Generative AI tools is allowed, the assessment specification should also specify how use should be acknowledged(""https://www.birmingham.ac.uk/university/hefi/gai/acknowledging-and-citing-the-use-of-generative-ai-by-students.aspx""). This could include: 
a pre-defined statement that indicates whether you have used Generative AI tools.
Sharing prompts used, the outputs produced, or the modifications made because of using the tools.
A reflective component detailing how Generative AI has been used and the experience of engaging with it.
Using appropriate referencing as outlined in Cite them Right Online(""https://www.citethemrightonline.com/sourcetype?docid=b-9781350927964&tocid=b-9781350927964-217"") (Institutional login required).
The University's framework does allow you to use Generative AI tools as study aids for your personal learning and in your research. You are permitted to use these tools in this context, as long as you do not submit the actual AI-generated output as your own work for assessment. For example, you might use it to extend key ideas introduced or discussed within lectures or seminars or develop personalised study resources and revision materials. For more information about appropriate use see 'Ways you could use Generative AI tools for your work' below. 
Ways you could use Generative AI tools for your work 
If you have permission to use Generative AI tools in assessment or you are wanting to use them to aid your personal learning and research, there are lots of ways they can support you. They can speed up mundane or repetitive tasks, as well as act as your personal study aids or research assistants. Let’s have a look at some ways they can be used.
Close all sections(""https://intranet.birmingham.ac.uk/student/libraries/asc/student-guidance-gai.aspx#"")
1. Scope out a topic or develop your initial ideas

Similar to how you might use the internet, Generative AI can help you understand different views, ideas, and perspectives. It can be a starting point for getting a handle on a topic area.
Use it to define ‘task words’ in questions or assignment briefs so you are clear on what you should do e.g., defining the difference between ‘evaluate’ and ‘discuss’.
2. Develop personalised study or research resources

The tools are very good at summarising information so you could use it to draw out patterns, themes, and topics areas from your notes.
These summary notes could be condensed further into ‘flash cards’ useful for revision.
Some tools can present a mind map of the information inputted. This could help with visualising your ideas or showing the relationship between themes.
3. Test your critical thinking skills

Use it to compare two answers given in response to a prompt question.
Practise your evaluation skills by assessing the quality of arguments given.
Check the accuracy of information generated.
Find resources to back up or challenge the information generated.
Use it to pose alternative arguments to claims you are making to test their validity and strength.
4. A revision aid to test knowledge

Notes can be summarised into manageable chunks for revision purposes.
Generate practice questions based on topic areas you are revising.
5. Improve your time management skills

The tools can help you break larger tasks down into smaller, manageable steps.
Create to-do lists and identify objectives and tasks.
Offer solutions and helpful tips to avoid procrastination.
Help you devise a Gantt chart (a detailed schedule and timeframe) for longer projects.
6. Understand the fundamentals of academic writing

Provide a starting point for understanding different kinds of writing assignment e.g., exploring the differences between an essay, a report, or a blog post.
Help you understand the key features of academic writing e.g., what constitutes an effective introduction or conclusion.
7. Editing and proofreading work

It can act as a ‘third-party editorial assistant’, which means you can use the tools to correct spelling, punctuation and basic grammar errors; shorten long sentences or paragraphs, provided the meaning remains unchanged; ensure your writing adheres to standard English conventions; check consistency in formatting. For PGR theses, this use must be declared using the ‘third party editor declaration’ form. 
However Generative AI tools must not be used to alter your text in the following ways: to rewrite or improve your arguments, explanations or ideas; translate work into or from a language you’re being assessed on; shorten work to meet a word count; correct factual inaccuracies or enhance the content of your writing; rewrite code in computing or programming assessments.  
When using a Generative AI tool to correct grammar and syntax, you should not copy and paste large amounts of your own writing into the tool. You should apply the tool’s suggestions to your writing by paraphrasing or rewriting your sentences, rather than copying and pasting the tool’s output. See more information on privacy and copyright issues(""https://intranet.birmingham.ac.uk/student/libraries/asc/student-guidance-gai.aspx#copyright"") and what you should be aware of when adding your own text to these tools 
Please refer to the guidance on using Grammarly responsibly within your academic work(""https://intranet.birmingham.ac.uk/student/libraries/asc/grammarly.aspx"") for further examples of acceptable and unacceptable proofreading.  
8. Summarise and understand research

There are many tools available to help summarise information, make comparisons between text or data, and make reading articles easier and quicker. 
However, there are potentially serious copyright implications for doing this and you should only upload other people’s work if the item is no longer in copyright or if you have permission to do so.
Rather than supplying a full copy of a text by uploading or copying and pasting it directly into the Generative AI platforms, it is recommended that you point to the article title, DOI, or link for the Generative AI tool to then find the content itself and summarise it from there.
See more information on copyright issues(""https://intranet.birmingham.ac.uk/student/libraries/asc/student-guidance-gai.aspx#copyright"").
9. Develop effective search techniques using prompts

Although tools like ChatGPT and Gemini respond to natural language (such as the language you might already use to search Google), using effective prompts can result in better answers from the tools. When we talk about prompts, we mean the questions you ask the tool to generate a response. There is a skill to asking the right questions so that the output you receive is relevant and useful.
Try using an acronym like TAP(""https://www.timeshighereducation.com/campus/prompt-engineering-academic-skill-model-effective-chatgpt-interactions?utm_source=newsletter&utm_medium=email&utm_campaign=editorialdaily&spMailingID=25537218&spUserID=MTAxNzcwOTA1MjUxNgS2&spJobID=2215389030&spReportId=MjIxNTM4OTAzMAS2"") to help you write an effective prompt. This considers the topic, output and parameters:
Topic: identify the topic area and make sure it’s focused, specific and given a context.
Action: be clear what output is required and for what purpose. Use action words such as ‘summarise’, ‘clarify’, ‘propose’. How do you want the information to be presented?  i.e., do you want an explanation or a comparison between ideas?
Parameters: this is where you fine-tune the response and give additional information to focus the results, like demographic, geographical location, inclusion of references, or date range.
Once you have tried some prompts, you can then apply the acronym TASTE(""https://www.timeshighereducation.com/campus/prompt-engineering-academic-skill-model-effective-chatgpt-interactions?utm_source=newsletter&utm_medium=email&utm_campaign=editorialdaily&spMailingID=25537218&spUserID=MTAxNzcwOTA1MjUxNgS2&spJobID=2215389030&spReportId=MjIxNTM4OTAzMAS2"") to improve and evaluate the content generated by the tool. This involves:
Test: Generative AI can be inconsistent with its responses so click ‘regenerate response’ to consider new perspectives.
Adjust: Vary and refine the prompt to compare the output.
Simplify: it’s very easy to provide the tool with a vague, ambiguous, or wordy prompt. If the output produced isn’t focused, try and simplify your prompt.
Trust: Examine the truth and accuracy of the output
Examine: Start to critique the outputs, focusing on the quality of the information and/or argument provided.
The risks and limitations of using Generative AI tools
Generative AI tools have great potential to enhance your learning experience, but to ensure you are using the tools effectively and ethically, the following factors should be considered.
Inaccuracy and misrepresentation of information

It is important to understand that the information provided by Generative AI may not always be reliable or up to date, for example they have been known to commonly ‘hallucinate’ references which do not exist.  Always double-check and verify information obtained from Generative AI tools. Cross-referencing with other reliable or peer reviewed sources is recommended:
Use the Library Catalogue, FindIt@Bham, or an appropriate academic database. There are Library Guides(""https://libguides.bham.ac.uk/?b=p"") which identify suitable resources for your subject area.
Apply critical thinking skills. Be critical of the text produced by Generative AI, just as you would with any other source. Ask questions of the information generated: 
Does this information confirm knowledge I already have on the topic?
Can the information be corroborated by outside sources?
Does it include any bias, assumptions, or unverified opinions?
Inability to demonstrate higher order skills such as critical and creative thinking

Whilst at University, you’ll hear about the importance of developing your Graduate Attributes. These are the skills, behaviours and values that you are developing to support your progress whilst at UoB and beyond. ‘Critical and creative thinkers’ is one of these Graduate Attributes and it includes the following capabilities: 
To exercise discerning and autonomous thinking
To think critically in order to reach a solution
To analyse and evaluate the research you’re engaging with
To handle and analyse data
These are skills Generative AI tools currently struggle to replicate. They can synthesise information but are less able to analyse and evaluate the information presented. Weighing up research and presenting a coherent argument that is backed-up with evidence is a very human skill and consequently you cannot rely on Generative AI to do this for you.
Your assessment is likely to be geared towards assessing your ability to think critically and creatively so it’s important that you focus on developing these skills. The Academic Skills Centre has an Introduction to critical thinking Canvas course(""https://canvas.bham.ac.uk/courses/5026"") that can help you hone this skill.
Bias

Generative AI is only able to generate responses based on the information it has been trained on and the datasets it has access to. Therefore, if the dataset has bias within it, it is likely to be transferred to the information generated. This means biases, stereotypes, and an over-reliance on a Western perspective can be passed on if careful analysis is not given to the information it produces. Therefore, do make sure you check the information generated against a wider variety of reputable and trusted sources.
Privacy and data considerations

You should think carefully about the consequences of pasting your written work into a Generative AI tool. It’s advisable to remove any identifiable information from work you submit into the tool.
It is necessary to ensure that any tools protect your privacy and personal data. There will be privacy notices to read which detail how the tools use any personal data you provide.  The UK Data Protection Act (DPA) 2018 sets out rules about how personal data can be collected, used, and stored. If you are using Generative AI tools to collect or process personal data, you need to comply with the DPA. This includes ensuring that the data is collected fairly and lawfully, and that it is only used for the purposes for which it was collected. If you are collecting or processing personal data using an AI tool, you need to be transparent with the individuals whose data you are collecting. This means informing them about the purpose of the data collection, and how the data will be used. If you include other people’s personal data into the tools an ethics review might be required.  
Copyright

When using Generative AI tools, it is important to be aware of copyright laws as they will apply to the content uploaded to the Generative AI interface, the training data used to build the models, and potentially the outputs generated.
You should check the terms and conditions of any Generative AI tool that you use to understand the rights that you grant to the providers to re-use your work. For most Generative AI tools, by uploading your work you grant the providers the right to use it as they see fit, and this may include sharing it with other people. Your work will normally be incorporated into the training data and used to generate new outputs, at least in part. If you have really novel ideas or thoughts, you might not want to share these via Generative AI tools.
You should not upload content to Generative AI tools, or social media platforms, without the permission of the copyright holder. This includes text, images, data, songs, videos, and other copyright works, or any part of these. If the content is still in copyright the person that owns the copyright in the content is the only party that can grant the permission the tool asks for in the terms and conditions. If you do not have clear permission from the copyright owner to use their content with the Generative AI tools, do not upload it.
Please note that none of the print or electronic content held by the Library is currently licensed for such use. More about Copyright can be found on the Library Services' Copyright pages(""https://intranet.birmingham.ac.uk/student/libraries/copyright/index.aspx"").   
Exploitation

It is important to be aware of the process by which generative AI tools are built and how these can present ethical issues such as social and environmental exploitation. For example, there are claims(""https://www.theguardian.com/technology/2023/aug/02/ai-chatbot-training-human-toll-content-moderator-meta-openai"") that developers have outsourced data labelling to low-wage workers in poor conditions.
Plagiarism

Academic integrity is an important part of your university studies. This involves you completing your assessment honestly and respecting other people’s ideas. It’s about ensuring that what you submit for your assessment is your own work. The Code of Practice sets out the guidelines for academic integrity and your responsibilities as a student or PGR. As noted in Academic misconduct(""https://intranet.birmingham.ac.uk/student/libraries/asc/student-guidance-gai.aspx#academicmisconduct""), the misuse of Generative AI tools in assessment, such as improper referencing or non-acknowledgement of use, will be dealt with in-line with this Code of Practice. It is also very important that you do not use these tools in assessment unless given explicit permission to do so. Therefore, to avoid plagiarism, it’s vital that you know when the tools can be used and how they should be acknowledged. Your School should provide you with this information, so please ask if you are unsure. 
Summary
The University’s Framework on Generative AI within Teaching, Learning and Assessment stipulates that you cannot use the output of Generative AI (i.e., the content it creates) in any assessment, unless explicitly authorised.  It is important to check that your particular use of Generative AI in assessment is permitted by your module lead.
While Generative AI can be a valuable tool for understanding concepts and exploring ideas, it should never replace your own critical thinking and analysis. Use it as a supplement to enhance your understanding, rather than as a substitute for your own work.
These tools should not be used to write your assignment or theses and/or to clarify and develop your arguments. You should not use them to translate large amounts of text into English.
Only upload other people's work, that is still in copyright, if you have the permission of the copyright owner.
Further resources and contact information
This guidance is also available as an interactive Canvas course(""https://canvas.bham.ac.uk/enroll/PHDWWD"").
The Academic Skills Centre supports undergraduate and postgraduate taught students to develop their academic, digital and maths skills. See more information about how they can support your skills development.  If you would like to discuss this guidance, please get in touch: asc@contacts.bham.ac.uk(""mailto:asc@contacts.bham.ac.uk"")
The Research Skills Team supports PGRs to develop a framework for understanding the ethical use of AI in their work. https://intranet.birmingham.ac.uk/student/libraries/research/workshops-and-training/ai-tools-researchers.aspx(""https://intranet.birmingham.ac.uk/student/libraries/research/workshops-and-training/ai-tools-researchers.aspx"")
Cite Them Right Online(""https://www.citethemrightonline.com/sourcetype?docid=b-9781350927964&tocid=b-9781350927964-217"") (Institutional login required) has a section on how to reference generative AI content.
Please refer to the guidance on using Grammarly responsibly within your academic work(""https://intranet.birmingham.ac.uk/student/libraries/asc/grammarly.aspx"") for further examples of acceptable and unacceptable proofreading.
Information about Copyright can be found on the Library Services Copyright pages. (""https://intranet.birmingham.ac.uk/student/libraries/copyright/index.aspx"")
The University’s framework(""https://www.birmingham.ac.uk/university/hefi/gai/index.aspx"") for using Generative AI in teaching, learning and assessment."
17,University of Southampton,17_southampton.rtf,https://www.southampton.ac.uk/about/governance/regulations-policies/policies/using-gen-ai-during-your-studies,"Using generative artificial intelligence during your studies
This page sets out how we as a university recommend using generative artificial intelligence (GenAI) in your studies as a student with us.  You'll find information including:
		what GenAI is
		our views on using GenAI
		using GenAI in your studies
		acceptable and unacceptable GenAI use
		further guidance for students and staff
What is GenAI?
Generative artificial intelligence tools or services can be used to generate text, video, audio and image content in response to questions or instructions, often referred to as prompts. They can give responses to data that is input into them too, such as code or text.   The most common example of a GenAI tool is ChatGPT.
Our views on using GenAI
At the University of Southampton, we aim to develop our teaching, learning and assessment to ensure that an education prepares you to be:
		critically digitally literate
		a responsible, ethical, skilled user of GenAI
		ready for work and life in an AI-enabled world
Student and members of staff currently have access to the generative AI tool CoPilot within Microsoft Office365.
GenAI tools can be enormously useful in supporting your studies by generating ideas, or by checking or editing work.
However, they often get things wrong, include biased information, and create generic, bland text that does not show the knowledge, understanding and critical thinking your university studies give you.


How can you use GenAI at the University of Southampton?
In this 2 minute film, we set out the University’s position on the use of GenAI in education.
Using GenAI in your studies
You are allowed to use GenAI tools like ChatGPT to develop your learning and support your studies. However, you should never submit work that has been created or part-created by GenAI for assessments that you claim as your own work.
Work submitted as your own  should genuinely be your own work.  If you submit work that has been created by someone other than yourself (including GenAI), then this breaks our rules on Academic Responsibility and Conduct(""https://www.southampton.ac.uk/about/governance/regulations-policies/student-regulations/academic-responsibility-conduct""). We will take disciplinary action that may result in penalties on your marks.
Always talk to your module tutor to check how to use GenAI to support your studies in their subjects. How far, and in what ways, you can use generative AI will depend on the particular task or learning you are carrying out and what capabilities you are expected to demonstrate. 
This includes situations where you may not be allowed to use GenAI tools because learning outcomes indicate you need to develop and demonstrate your own individual skills and knowledge. In other cases, you may be asked to complete a declaration statement that describes how you have used generative AI. For some learning activities your tutor will build use of GenAI into teaching and give guidelines on how to use the tools.
Remember, if in doubt, ask.


Top Five Things you need to know about using GenAI
Students Chloe, Adele, Saddir and Rommel present from Valley Gardens on Highfield Campus in this 3 minute video.
Acceptable and unacceptable GenAI use 
Please check with your tutor before using generative AI in your work.
Acceptable uses include:
		using GenAI as an assistive technology by arrangement with our Disability and Inclusion team(""https://www.southampton.ac.uk/edusupport/disability_support/index.page"")
		using GenAI as a study buddy, for example, giving feedback on some of your writing for spelling or grammar errors, or for getting started with ideas
		citing or clearly referencing your use of GenAI
		summarising complex ideas or academic texts
Unacceptable uses include:
		copying and pasting information created by GenAI straight into your work
		asking GenAI to write or rewrite your work or part of your work for you
		directly asking GenAI to answer an assessment question
		sharing the materials and resources from your module tutors in a GenAI tool - you do not have permission to share these materials openly because they belong to the University


Southampton students explain how they use GenAI in their studies
In this 8 minute YouTube video, Rommel chairs a discussion with students Saddir, Chloe and Adele. They talk through the risks and benefits of using GenAI in their studies.
Further guidance for students and staff
Guidance for students:
		Artificial intelligence tools and academic work(""https://sotonproduction.service-now.com/serviceportal?id=kb_article_view&sys_kb_id=45a9f8051b86da90384d4043b24bcb50"") – Student Hub advice for all levels of study 
		Searching and Generative AI(""https://library.soton.ac.uk/sash/generative-ai"") – advice from our Library Services
Guidance for staff (links open in SharePoint):
		Using GenAI in education and the University’s position(""https://sotonac.sharepoint.com/teams/GenAI"") 
		Using University tools to support the use of GenAI and digital capabilities(""https://sotonac.sharepoint.com/sites/DigitalLearningTeam/SitePages/Artificial-Intelligence-(AI).aspx?xsdata=MDV8MDJ8fDNhZWFkMmQ0MjEyMTRiZTM3YTkzMDhkY2U4NGUxYmI0fDRhNTM3OGY5MjlmNDRkM2ViZTg5NjY5ZDAzYWRhOWQ4fDB8MHw2Mzg2NDA2NjkzNDk2NzM2MTl8VW5rbm93bnxWR1ZoYlhOVFpXTjFjbWwwZVZObGNuWnBZMlY4ZXlKV0lqb2lNQzR3TGpBd01EQWlMQ0pRSWpvaVYybHVNeklpTENKQlRpSTZJazkwYUdWeUlpd2lWMVFpT2pFeGZRPT18MXxMMk5vWVhSekx6RTVPbTFsWlhScGJtZGZXa2ROTTFsVVNUSk5la1YwV2tSQk1FMURNREJhYlVac1RGZEthRTU2VVhST2JVVjNUa1JhYWs1RWEzcE5WRkY1UUhSb2NtVmhaQzUyTWk5dFpYTnpZV2RsY3k4eE56STRORGN3TVRNek9UY3l8NTYyYWRjYjc5ZTA2NDA3YzdhOTMwOGRjZTg0ZTFiYjR8MzZjZDA2OWE1YWI5NGRhOGJlYjBiN2ExNzIzYzc3MTE%3D&sdata=MnVuM0JWK3NSSVQ4bnVxZElpQ2MvRG5yOUpneER1UXE2OXJqcWxlT01pYz0%3D&ovuser=4a5378f9-29f4-4d3e-be89-669d03ada9d8%2Ckb2%40soton.ac.uk&OR=Teams-HL&CT=1729677176539&clickparams=eyJBcHBOYW1lIjoiVGVhbXMtRGVza3RvcCIsIkFwcFZlcnNpb24iOiI0OS8yNDA5MTIyMTMxOCIsIkhhc0ZlZGVyYXRlZFVzZXIiOmZhbHNlfQ%3D%3D"")
		AI and research at Southampton(""https://sotonac.sharepoint.com/teams/AISouthampton/"")"
18,University of Liverpool,18_liverpool.pdf,https://www.liverpool.ac.uk/media/livacuk/centre-for-innovation-in-education/digital-education/generative-ai-teach-learn-assess/guidance-on-the-use-of-generative-ai.pdf,"Suppo rt | Enga ge | Innovate University Guidance on  the use of
Generative Artificial 
Intelligence by students and staff, in learning, teaching, andassessment 
Academic Year  2024/2025
Authors:
Dr Ceri Coulby, Dr Sam Saunders & Dr Claire Ellison | Date: February 2024
Revised 2024, by Prof David Webster, Gordon Sandison, Rob Lindsay, Dr Sam Saunders, Dr Claire Ellison &Richard McKenna
Contents2
Introduction 3
Data Protection Policy and Your Responsibility  4
Generative AI and Copyright  5
Acceptable Uses of GenAI Tools  5
Unacceptable Uses of GenAI Tools  7
Poor Academic Practice  8
Academic Misuse of GenAI Tools  9
Referencing GenAI Tools 9
Further Information/Contact 10
Introduction3
Generative Artificial Intelligence (GenAI) tools are software applications that create content 
in any form (including but not limited to text, graphs, data, code, images, audio, and video) 
automatically based on the prompt entered by the user. Examples include, but are not 
limited to, OpenAI’s ChatGPT, Google Bard/Gemini, Microsoft’s Bing Chat/Copilot, DALL-E (and 
DALL-E2/3), and Perplexity.ai. 
Artificial intelligence tools are rapidly developing and increasingly becoming embedded into 
everyday activities across personal and professional contexts. To ensure our graduates have 
the skills and experience they will need in their future careers, the University of Liverpool seeks 
to incorporate the technology in their pedagogical approach. However, it is also vital that 
such technology is used ethically and does not undermine academic integrity principles.  
To help students and staff to use such technologies appropriately, the University has 
developed this guidance on acceptable and unacceptable uses of GenAI and AI (Artificial 
Intelligence) technology and its appropriate citation. This guidance is designed to be applied 
alongside Appendix L of the Code of Practice on Assessment (CoPA), which supersedes this 
guidance in regulatory terms . This guidance also serves as the University’s default position 
on usage. If module or programme/course component leaders wish students to use GenAI 
as part of an assessment, students will be informed of this specifically in module materials 
and assignment briefs. In these cases, specific guidance will be provided in the assignment 
brief on what constitutes appropriate use of the GenAI tools and how the work from such tools 
should be cited. 
The underlying philosophy and/or ethos surrounding the use of Generative AI at the University 
of Liverpool is one of promoting literacy around the technology in both students and staff, 
and using the technology as openly, honestly, and transparently as possible. This ensures that 
any engagement with the technology is in line with both the Liverpool Curriculum Framework 
(LCF) - which promotes ‘Digital Fluency’ as a Graduate Attribute – and Strategy 2031, which 
states that the university will work to integrate AI into its practice(s). An outright ban on 
the use of the technology, therefore, contravenes both requirements, in addition to being 
impossible to enforce.
4
In general, therefore, the guiding principle(s) of the use of Generative AI that should inform all 
practice is that 
1. Both students and staff should openly discuss, experiment with, and engage with the 
technology in discursive ways where possible, to help improve general understanding of 
its capabilities, functionalities, limitations, and problems/biases.
2. Any use of the technology in either an assessment or any other context should always 
be declared and evaluated/reflected on, and if necessary, cited and referenced. 
Citations and references to AI should follow the same process as if referencing or citing 
an academic source. This goes for both staff and students – for example, students can 
be asked to declare their use of GenAI on an assessment cover sheet, while staff should 
make it clear on their teaching materials where and how GenAI has been used to help 
create them.  
3. The technology is not used as a substitute for original thought, independent research, and 
the production of original work. Rather, it is used to support these processes.  
That said, the university recognises that there are some situations where the use of 
Generative AI is simply unacceptable and will attract sanctions under Appendix L of the Code 
of Practice on Assessment (CoPA). This guidance provides some steerage on what that 
unacceptable use of Generative AI looks like and should be consulted in line with the relevant 
sections of CoPA that deal with academic integrity.   
Data Protection Policy and Your Responsibility 
Students and Staff interacting with GAI systems bear responsibilities for ensuring the 
Universities Data Protection Policy  is followed.  
The UK General Data Protection Regulation (GDPR) and Data Protection Act (DPA) 2018 
emphasise the importance of not submitting sensitive or personal data unless necessary and 
appropriate measures are in place. Users should be aware of the information they provide to 
AI systems and avoid sharing personally identifiable information, sensitive data, or any other 
data that could potentially violate privacy rights or lead to unethical use.
5
Generative AI and Copyright 
Understanding the legal aspects of how copyright operates in the context of Generative AI 
is central to supporting staff and students to become more Generative AI literate and to 
mitigate the risks. 
Staff and students must ensure that they are aware of the intellectual property and copyright 
concerns that might arise when using Generative AI tools. These are outlined by the UK 
National Centre for AI at: ‘ An introduction to copyright law and practice in education, and the 
concerns arising in the context of GenerativeAI ’ 
Additional guidance can also be found on the Library website pages on copyright .
Acceptable Uses of GenAI Tools 
In general, using GenAI tools for preparatory research work for an assignment is considered 
acceptable practice, however such tools should never be the only source of information 
used . GenAI tools are not academic sources; they do not produce fact-checked content, and 
they can, and often do, reproduce inherent biases in provision of information, and they often 
do not accurately state the sources from which the content provided has been gathered. It 
is therefore vital that students use academic and trusted disciplinary-specific sources when 
developing their work. None of the content generated by AI should be used in submitted work 
unless it is quoted and referenced as such.   
AI is at its best when it is used to help synthesise ideas, so that users are in a better position to 
write an assignment. It may be helpful for students to consider GenAI tools in a similar light to 
Wikipedia: as a source of information, but not always a reliable one.
6
See some potentially acceptable uses of GenAI here. Please note, this list is not exhaustive 
and is indicative only
• Initial research into a topic, idea, or concept to gain an overview for example: “what are 
the main ethical concerns for students when using generative artificial intelligence tools?” 
• Identifying/summarising core concepts or viewpoints in a particular disciplinary area for 
example “what were the prevalent influences on 19th century writers?” or “what are some 
alternative explanations to string theory?”
• Summarising texts- Sections of text can be pasted into a GenAI tool and it asked it to 
summarise the content. This is especially useful if you are unsure that you understand 
what the key message or concept in a piece of text is. 
• It is important to note that summaries cannot be pasted into work for assessment 
purposes unless they are being used as short quotations for a specific purpose. These 
quotations must be appropriately cited and the correct referencing conventions in the 
subject area used.
• Taking notes during group work discussions
• Getting ideas on how to present work
• Organising work
• Formatting a reference list
It is also possible to use GenAI tools for proof reading and self-assessment (i.e. to get 
feedback on your work prior to submission), as deemed acceptable according to section 
2.4 of the University’s Academic Integrity Policy ( Code of Practice on Assessment , Appendix 
L) - however, it is not clear what happens to the data submitted to Generative Artificial 
Intelligence Tools, and so caution must be exercised. If work uploaded to GenAI platforms is 
used to train the dataset from which it creates new responses for others, your work might be 
used in another’s work, thereby risking plagiarism.  
Therefore, students should not upload their work to sites that do not have clear privacy 
policies and opt outs. Equally, it is not permissible to upload any personal or sensitive data, 
or university materials (e.g. lecture slides, teaching content, etc.) onto these systems 
without permission. 
7
Unacceptable Uses o f GenAI Tools 
The unacceptable use of Generative AI software broadly falls in line with other examples of 
academic misconduct that exist outside of the GenAI space. Students using the technology 
to simply circumvent the requirements of an assessment or using it to create entire 
assessments that they then disguise as their own original work is not acceptable. The 
requirement to declare, cite, reference and reflect on the use of Generative AI is designed to 
prevent students from simply using the technology to create assessments that they 
then claim as their own, and a student that refuses to declare how they have used the 
technology, does not cite it, reference it or reflect on its outputs may be attempting to hide 
the fact that the work is not their own. 
Some examples of misuse of Generative AI may include, but are not necessarily limited to:  
•Students generating an entire assignment submission and passing it off as their own
work.
•Submitting content generated by Generative AI tools without appropriate and correctlypresented acknowledgement and citation of the source(s).
•Using tools which paraphrase text to pass off the work of another person (includinganother student), organisation, or content generated by artificial intelligence as thestudent’s own.
•Using manual or machine translation to translate the work of another person (includinganother student) or organisation originally developed in a language other than Englishwithout appropriate and correctly presented acknowledgement and citation of theoriginal source.
•Submitting assessed work where use of GenAI has been cited, but the prompt given isin contravention of good academic practice* e.g. “write me a conclusion for my essayon XXXX.” All work submitted must be the student’s own in line with section 9.1 of theUniversity’s Code of Practice on Assessment
8
• Using tools in any other way that conflicts with the standards articulated (1) in programme 
level guidance or (2) in module level guidance or (3) in the instructions you were given for 
the specific piece of assessed work. 
• Uploading any data generated from empirical research projects in contravention of 
ethical approval conditions - for example, information on participants of research studies. 
*Good Academic Practice as stated in the Academic Integrity Policy: Guidelines for Students 
(CoPA, Appendix L, Annexe 1 ) is demonstrated through: 
• Honesty and integrity 
• Trustworthiness 
• Respect for the wider academic community and your fellow students 
• Fairness, knowing that you have truly earned the marks awarded for your work and that 
you have not used unfair means to gain an advantage
The assessment brief issued by staff for a piece of work can specify the scope and extent of 
the usage of GenAI that they expect students to comply with, albeit in line with the ethos of 
the introduction to this guidance. 
Poor Academic Practice 
If students base their work purely on the output generated by GenAI/AI tools, and do not 
consult any other sources of information, it is unlikely that their work will be (1) completely 
accurate and/or (2) have the sufficient depth of understanding and critique expected for the 
level of study (e.g. UG/PGT/PGR). Students are encouraged to go directly to academic and 
discipline-specific sources for several reasons. It is possible that AI tools and/or secondary 
sources might have misinterpreted or misrepresented information which will result in students 
importing errors into their work. Additionally, engaging with academic and discipline-specific 
sources allows students to develop their own thoughts and ideas in the context of established 
scholarship. Students who do not do this are unlikely to pass their assessments. Assessment is 
an important part of learning and students who do not complete assessments appropriately 
risk not only wasting their own time at university, but also not having the necessary skills 
required by employers when they leave. 
9
Academic Misuse of GenAI Tools 
If students use GenAI tools in an unacceptable way, as outlined both in this document and the 
Academic Integrity Policy (Appendix L of the Code of Practice on Assessment), then they risk 
receiving a potentially severe penalty for academic misconduct. The penalties for academic 
misconduct are ranked from A to E, ranging from Minor Error (A) to Unfair and/or Dishonest 
Academic Practice or Research Misconduct (E). Information on the specific penalties is 
included in the Academic Integrity Policy ( CoPA, Appendix L ) and accompanying Guidelines 
for Students ( CoPA, Appendix L, Annexe 1 ). Academic misconduct is taken very seriously, and 
penalties vary from losing marks to termination of studies.  
If students are struggling with their studies or are unsure of what is and is not acceptable on 
a particular assignment brief, they should contact their module or programme component 
leader/convener for support and/or advice.
Specific queries on whether the use of Generative AI constitutes a breach of academic 
integrity should be directed to either the Academic Quality and Standards Division (AQSD) or 
the Student Conduct, Complaints and Compliance Team (SCCCT).
• AQSD
• SCCT
Referencing GenAI Tools
Using GenAI/AI tools for research and in preparation of work does not require citation, in the 
same way that an initial Google search for information does not require citation . Prior to the 
introduction of GenAI, students were not required to reference web searches, sources that 
had not directly informed their submitted work or use of spell checkers. Therefore, the use of 
GenAI for similar purposes need not be referenced, unless an assignment brief specifically 
states otherwise. 
It is unlikely that students will need to directly quote content from AI-generated sources very 
often due to the limitations of GenAI tools. Students need to critically evaluate any content 
generated using AI.
10
However, in certain circumstances, or for content types, this may be required. For example, 
part of the assessment may require the use of AI to generate text which is then critiqued by 
the student. In these instances, if students’ work includes a verbatim quotation, embedded 
image, or figure this should be referenced within the text or content of the assignment and 
in the reference list. Students should use the referencing system they have been instructed 
to use within their discipline (e.g. Harvard, APA, Chicago etc.). Most referencing systems 
have guidance on how to quote content generated by GenAI/AI tools (usually with reference 
to ChatGPT) so students should consult these if they are unable to find what they need on 
citethemright
• APA guide to citing Generative Artificial Intelligence tools
• Chicago Guide to citing Generative Artificial Intelligence tools 
• Harvard Guide to citing Generative Artificial Intelligence tools
• MLA Guide to citing Generative Artificial Intelligence tools
Further Information/Contact
If students have questions regarding appropriate use of GenAI/AI tools or referencing thereof 
they should contact their module lead or visit the appropriate KnowHow resources located 
here: KnowHow - Library at University of Liverpool
Staff looking for advice on the appropriate use of GenAI/AI tools should contact CIE.
© 2023 by the University of Liverpool, Centre for Innovation in Education.
Acceptable and Unacceptable use of Generative Artificial Intelligence in Assessment - Guidance for staff and students by Dr Ceri Coulby, Dr Sam Saunders & Dr Claire Ellison is made available under a 
Creative Commons Attribution-NonCommercial 4.0 International License. Revised 2024, by Prof David 
Webster, Gordon Sandison, Rob Lindsay, Dr Sam Saunders, Dr Claire Ellison & Richard McKenna."
19,King's College London,19_KCL.rtf,https://www.kcl.ac.uk/about/strategy/learning-and-teaching/ai-guidance/student-guidance,"What do you mean by AI and generative AI?
This is guidance not policy and it is intended to assist decision-making across a range of disciplines at King's. It should be considered alongside the Academic Policy and Procedure which can be found here: Academic Misconduct Policy | King's College London(""https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.kcl.ac.uk%2Fpolicyhub%2Facademic-misconduct-policy&data=05%7C02%7Cbilly.bryan%40kcl.ac.uk%7C813417a9426b48ec378a08dd40531666%7C8370cf1416f34c16b83c724071654356%7C0%7C0%7C638737447770912216%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=UgS5u8rbZsJHr00XlHzbquMgaqyX25a%2Bw3%2Bx2N8ryvo%3D&reserved=0"") and any faculty or programme level guidance given. If the reader finds any apparent inconsistency between this Guidance and the Academic Policy and Procedure or any other policy then please do note the precedence of Policy over guidance. Failure to do so could lead to misconduct proceedings being taken. The Non-Academic Misconduct Policy | King's College London(""https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.kcl.ac.uk%2Fpolicyhub%2Fnon-academic-misconduct-policy&data=05%7C02%7Cbilly.bryan%40kcl.ac.uk%7C813417a9426b48ec378a08dd40531666%7C8370cf1416f34c16b83c724071654356%7C0%7C0%7C638737447770936315%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=qu0WycDSYhWzLBbTRiTw5ARzwaBd98hcuubp%2F%2BSj4R8%3D&reserved=0"") may also apply to any misrepresentations of AI use.
Artificial Intelligence, or AI, refers broadly to any technology or system that can reason and/or adapt, sometimes on its own, to achieve certain goals. For example, predictive text on a smartphone guesses what you will write next, or a robot that can analyse what’s around it and then make decisions to act within its environment autonomously.
AI-based systems can be based purely in the virtual world with things like voice assistants (e.g. Siri or Google Home), image analysis tools, search engines, and technology that can recognise speech and faces.
AI can also be embedded in hardware, or objects in the physical world around us such as advanced robots, self-driving cars, drones, or devices connected to the Internet of Things.
Within AI, generative AI refers specifically to a type of AI where applications are trained to learn from data to improve at performing certain tasks such that it can create content like text, code, images, video and audio based on the vast amounts of data that the AI has been trained on. Generative AI (exemplified here but not necessarily endorsed by King's) includes:
Text generation
Microsoft Copilot(""https://copilot.microsoft.com/""), ChatGPT, Google Gemini, Claude. These are AI systems that can generate human-like text by predicting probable next words after being given a prompt. Writing prompts accurately and in order to fine tune outputs is referred to as ‘prompt engineering’.
These tools are NOT databases of knowledge. They ’predict’ combinations of plausible words; they should never be used instead of, but may be used alongside, conventional approaches to sourcing information.
Please note that Microsoft Copilot(""https://copilot.microsoft.com/"") is available to all King's students with your KCL Microsoft log in credentials. Make sure you are logged into your KCL account and switch ‘safe search’ to ‘moderate’ to use it.
Other media and code generation
DALL-E, Midjourney and Stable Diffusion are examples of AI systems that create images from text prompts by analysing vast datasets of image-text pairs and producing novel images.
Descript and Murf.ai are examples of AI tools that can generate human-like audio narration and conversation from text.
GitHub Copilot and TabNine are examples of AI coding assistants that suggest completions for code based on analysing large codebases. These are but a few of the thousands of tools available.
Please note that there are ongoing controversies and challenges across the globe about use of text and images generated by AI, with many arguing that these breach copyright rules.
Is generative AI banned at King’s?
No, King's does not ban the use of any type of AI. It is increasingly part of the wider world and is changing the nature of many aspects of life including the jobs you are in or will progress into. At King’s we are a signatory to the Russell Group principles:
		Universities will support students and staff to become AI-literate.
		Staff should be equipped to support students to use generative AI tools effectively and appropriately in their learning experience.
		Universities will adapt teaching and assessment to incorporate the ethical use of generative AI and support equal access.
		Universities will ensure academic rigour and integrity is upheld.
		Universities will work collaboratively to share best practice as the technology and its application in education evolves.
We do, of course, expect students to critically engage with ideas and content produced from or with generative AI, to own outputs and to adhere to academic integrity policies to ensure appropriate and ethical use of AI.
Above all, any work submitted must represent a genuine demonstration of your own work, skills and subject knowledge, adhere to the guidelines of the assessment task, and respects the university's value of academic integrity and honesty.
How could generative AI help with my studies?
Many of the tools we are already familiar with have built in AI elements and this will increase quite rapidly over the forthcoming months and years.
The key distinction of generative AI from e.g. a search engine output is its ability to create completely novel content at scale, as opposed to just accessing existing data. However, where outputs are fully AI-generated, they lack human understanding, critical engagement and precision and often exhibit a bland style of expression that, whilst technically accurate and impressive at first glance, is often flawed. The tools may generate biased, incorrect, or misleading information, and it is good practice to check information via other sources.
Generative AI can be extremely useful if used appropriately, but it's important to be aware of its limitations compared to human creativity and cognition. Used properly and strategically, generative AI can augment our creativity and productivity. The key is developing skills to harness it effectively as part of your own learning process, while maintaining full academic integrity through proper attribution and transparency.
Used properly, generative AI tools can:
		Help generate ideas and frameworks for study and assessments
		Upscale and organise(""https://youtu.be/nqR5l4Ryym4"") rough typed notes
		Provide explanations of concepts you are struggling to understand through dialogic exchanges(""https://www.youtube.com/watch?v=iCRe-lZJ9ds"")
		Paraphrase and summarise sources as a study aid
		Provide feedback on your ideas and work, and help you improve it
		Re-format text(""https://mcompton.uk/2023/07/04/using-chatgpt-to-support-neurodivergent-reading-and-comprehension/"") (e.g. from full prose to tables)
		Suggest code completions or assist with debugging for programming work
		Translate texts between languages for multilingual research or for communicating with researchers across the globe
		Summarise meeting, video or podcast transcripts
		'Clean’ and punctuate automated transcripts (e.g. those produced in YouTube)
		Help you create effective presentations
		Help challenge some of the issues in study(""https://youtu.be/hFui2EfjGlo?si=EW4mYVHwwumvU5gs"") experienced by neurodivergent students.
What should I be alert to?
		It is absolutely essential that you are clear about any particular requirements or restrictions at programme level as these can vary, even across modules. For most of our students you will not be required or even recommended to use these tools if you do not want to. Maintaining academic integrity requires human direction over how generative AI is leveraged in the learning process. It is unlikely that copying and pasting from a generative AI tool will likely ever be appropriate practice in a summative assessment.
		Please also note you should exercise caution when using any tools that require additional log ins or account generation as these will likely collect personal data.
		You should not input personal data, sensitive information or content created by others into any AI platform.
		Outputs from generative AI can seem convincing and plausible but due to the way these systems work, could be factually incorrect, contain ‘sources’ that do not actually exist and/ or reflect biases and prejudices derived from the data the models were trained on.
If I use AI in an assignment will it affect my grade?
We understand that common tools (such as grammar and spell checks) are already embedded into the software you use for assignments and, unless measurement of spelling, for example, is an aspect of an assessment we would not anticipate any issues. The same principle should be used when considering whether AI is appropriate to use within your assessment.
What constitutes appropriate use?
You should be given clear guidance on what level of generative AI is appropriate in any given assessment. Things are moving quickly so if you are uncertain, please do ask. We have suggested four broad levels that your Programme and Module leaders may adjust to the specifics of an assessment:
1. Minimal
Includes routine and established use of tools such as auto transcription, spell checkers, grammar check.
2. Limited/selective
Use for clearly delineated tasks as appropriate/allowed/recommended. May include:
		Ideation/brainstorming
		Concept checking/explanation
		Suggesting structures
		Suggesting titles
		Summarising own or other’s key ideas
		Illustrative image or other media generation
3. Open
No specific restrictions but with requirement to track key stages/tools utilised. Possible uses may include:
		Socratic chat bot/tutor
		Summarisation, simplification, synthesis, translation
		Generate illustrative media content
		Support production of multimedia artefacts
4. Embedded
AI use is a feature of the assessment itself. Here the use of generative AI is a focal aspect of the assessment. This may include:
		Using named tools for a specific outcome
		Output comparison and critique
		Develop or error check code
Once again, we state that in no circumstance is it appropriate to use generated content verbatim without clear indication and acknowledgement, or to effectively outsource the writing task as much as it is inappropriate to get someone else to write something and claim it as your own.
What are the ‘golden rules’ of use?
We suggest three golden rules:
		Golden Rule 1: Learn with your chats and interactions with AI, but never copy-paste text generated from a prompt directly into summative assignments (unless you are specifically told you can do this).
		Golden rule 2: Ask if you are uncertain about what is allowed in any given assessment.
		Golden rule 3: Ensure you take time before submission to acknowledge use of generative AI.
If you follow these three rules you are essentially ensuring that your assessed outputs are unlikely to breach academic integrity guidance in terms of use of generative AI.
How do I acknowledge use of generative AI?
King’s College London, unlike some other universities, does not require students to reference generative AI as an authoritative source in the reference list for much the same reason you would not be expected to cite a search engine, a student essay website or be over-dependent on synoptic, secondary source material.
However, as we learn more about the capabilities and limitations of these tools and as we work together to evolve our own critical AI literacies, we do expect you to be explicit in acknowledging your use of generative AI tools such as Microsoft Copilot(""https://copilot.microsoft.com/"") (available via your KCL account), Google Gemini, ChatGPT or any other media generated through other generative AI tools.
King's requires students to acknowledge any use of generative AI tools in coursework by including a declaration statement along with your references. Please note that so long as acknowledged use falls within the scope of appropriate use as defined in the assessment brief/guidance then this will not have any direct impact on the grades awarded. Unless alternative wording is suggested in an assessment brief then you should append one of the following:

1. I declare that no part of this submission has been generated by AI software. These are my own words. 
Note. Using software for English grammar and spell checking is consistent with Statement 1. 
[or]
2. I declare that parts of this submission has contributions from AI software and that it aligns with acceptable use as specified as part of the assignment brief/ guidance and is consistent with good academic practice. The content can still be considered as my own words. I understand that as long as my use falls within the scope of appropriate use as defined in the assessment brief/guidance then this declaration will not have any direct impact on the grades awarded.
I acknowledge use of software to [include as appropriate]: 
(i) Generate ideas or structure suggestions, for assistance with understanding core concepts, or other substantial foundational and preparatory activity.
[insert AI tool(s) and links and/or how used] 
(ii) Write, rewrite, rephrase and/or paraphrase part of this essay.
[insert AI tool(s) and links] 
(iii) Generate some other aspect of the submitted assessment.   
 [insert AI tool(s) and links] / Include brief details]

What are the consequences of inappropriate use of generative AI?
Inappropriate use without attribution is considered academic misconduct. For further details please see the Academic Misconduct Policy and Academic Misconduct Procedure(""https://www.kcl.ac.uk/policyhub/academic-misconduct-policy"").
Potential penalties can range from formal warnings, resubmitting the coursework, suspension or expulsion.
What is an Academic Integrity meeting (AIM)?
If inappropriate use is suspected, a student may be called to an academic integrity meeting with academics to discuss authorship concerns and resolve any issues. The purpose of the AIM is to discuss the student’s assessment. The following topics would be explored in the AIM:
• How the student prepared the assessment task
• Feedback on the academic integrity concerns identified
• Any other circumstances impacting the student’s submission which they may wish to raise.
The Staff members discuss the concerns with the student, and the student is given an opportunity to input and discuss their perspectives and reflect on their work process.
What support is available?
In line with the Russell Group statement that universities will support you to become AI-literate, King’s sees this as a key academic skill that you will need to develop to succeed in your studies and career.
The existing providers of academic, digital, and data literacy skills support (including King’s Foundations, CTEL, Libraries and Collections, Centre for Doctoral Studies) will work closely with King’s Academy to be able to provide a coherent and comprehensive level of support and skills development provision. Access Generative AI in Higher Education FutureLearn course(""https://www.futurelearn.com/courses/generative-ai-in-higher-education/1"") that has contributions from staff and students from across King’s too. If you have never accessed FutureLearn while at King’s then please make sure to sign up for your free FutureLearn Campus access(""https://www.futurelearn.com/campus/kings-college-london"") first."
20,University of York,20_york.rtf,https://www.york.ac.uk/students/studying/assessment-and-examination/ai/,"STUDENT GUIDANCE ON USING AI AND TRANSLATION TOOLS
This guidance explains how you can appropriately use a variety of digital tools (including generative AI) to assist you in the completion of your assessments. It also details inappropriate uses that you must avoid.
Published November 2023
This guidance applies to students on undergraduate and postgraduate taught courses and should be used in conjunction with the Policy on Acceptable Assistance with Assessments (Nov 2023) (PDF , 88kb)(""https://www.york.ac.uk/media/abouttheuniversity/supportservices/academicregistry/registryservices/sca/guidetoassessment/UoY%2023_24%20Policy%20on%20Acceptable%20Assistance%20with%20Assessments%20(including%20Generative%20AI,%20Proofreading%20and%20Translation).pdf"")
PG researchers should refer to Use of generative Artificial Intelligence in PGR programmes(""https://www.york.ac.uk/research/graduate-school/research-integrity/ai/"").
At the University of York, we value digital literacy as an important skill, both in Higher Education and in the workplace. We believe that translation tools and generative AI, when used appropriately, can be valuable resources for students. On the other hand, there are limitations, risks and ethical issues which users need to be aware of. We will support you in developing your understanding and application of such tools, but importantly, it is crucial that your use of AI, translation, or proofreading services to generate or improve your work does not lead to ‘false authorship’ of the formative or summative work that you submit. False authorship is considered an academic misconduct offence under University policy and is treated very seriously.

What is ‘false authorship’?
‘False authorship’ refers to creating or modifying academic work, either fully or partially, using unauthorised or undisclosed help from people (eg family, proofreaders, essay mills) or technology (eg generative AI, software, machine translation) without approval or acknowledgment and to such an extent that you can no longer be considered the author of the work.
Certain tools and services certainly have the potential to help learning and development in many ways, including broadening your knowledge and understanding and improving the quality of your writing. If, however, the use of such tools and services means you are effectively no longer the author of the work you submit for assessment, then you could be committing academic misconduct. 
See further details in the University’s misconduct policy(""https://www.york.ac.uk/staff/essentials/supporting-students/academic/taught/misconduct/"")
Generative artificial intelligence (AI)
Please ensure you have read the information on the Generative AI tools webpage before you start using any recommended tools.   Google Gemini(""https://www.york.ac.uk/it-services/tools/google-gemini/"") is the University's preferred generative AI tool because any data inputted is fully protected and chats are never used for training or human review by Google. You must sign into Gemini using your University credentials to ensure this.
Generative AI (eg ChatGPT) is rapidly becoming an integral part of our daily lives. Similarly to other tools and services discussed, when used responsibly and judiciously, generative AI can facilitate understanding, develop your learning, and support academic progress. Likewise, generative AI can help teachers and educators better communicate knowledge and engage students. However, it is crucial to recognise the limitations, biases, and ethical concerns associated with AI use, which we are all continuously learning about and addressing.  
For some assignments, you may be allowed to use generative AI, but for many of your assessments (and unless otherwise stated), there will be a strict expectation that any use of generative AI in the production of work you submit will adhere to University policy regarding false authorship. The use of AI undoubtedly has the potential to hinder your learning, misrepresent your genuine academic ability (both positively and negatively), and lead to misconduct cases that will be treated very seriously. As always, check your assessment briefs and guidelines carefully, and if you are not sure about acceptable use, ask your teacher or coordinator.    
University of York policy and guidance aligns and agrees with the Russell Group principles on the use of generative AI tools in education, and with the QAA advice on maintaining quality and standards in an AI-enabled world(""https://www.qaa.ac.uk/docs/qaa/members/maintaining-quality-and-standards-in-the-chatgpt-era.pdf?sfvrsn=2408aa81_10"").
Read our Generative AI - Taught Student guidance(""https://www.york.ac.uk/students/studying/assessment-and-examination/ai/taught-student-guidance/"")

Examples of good and/or acceptable use of generative AI in assessments
Learning enhancement: utilising generative AI to deepen understanding, explore complex concepts, and reinforce learning in the preparation stages of assessments. 
Clarification: using AI to clarify doubts, seek explanations, or understand complex vocabulary or sentence structures, but not as a substitute for deeper analysis and comprehension when producing assessed work. 
Further reading and research: seeking suggestions for additional resources or references related to the topic.
Generate ideas - but not generate assessed work: AI can be used to assist you in generating ideas, but again, this should not be a shortcut for critical thinking, deeper analysis and academic writing, all of which should be your own and you should be able to explain if asked.

Examples of poor and/or unacceptable use of generative AI in assessments
Enhancement beyond expectations: we expect the work you produce to reflect what we know of you from classroom participation, VLE engagement, oral tasks, homework submissions, and day-to-day interactions. Depending on the student, the production of work which is consistently grammatically flawless and highly cohesive may suggest false authorship, particularly when similar work cannot be produced under conditions where you do not have such tools available to you.  
Requesting direct answers or responses: asking generative AI your assessment questions or titles, and then using the generated response in assessed work without approval or attribution.  
Submitting chunks of unedited text generated by AI: submitting academic work that is partly or entirely generated using AI, without any personal review, understanding, or modification, will be deemed false authorship. 
Over-reliance: if your assessment submission has indicators of generative AI  you may be found to have committed false authorship. Depending on AI can hinder your learning and misrepresent your genuine academic ability.  
Uncritical acceptance: accepting suggestions without critical evaluation, careful review, or consideration of accuracy, context or appropriateness will likely not only lead to a case of misconduct but also increase your chances of receiving a low grade. 
Translation tools or services (human or digital)
When used appropriately and judiciously, translation services or tools (eg Google Translate, Youdao Translate, Baidu Translate) can facilitate understanding, enhance language skills, and support academic progress. However, it is crucial to highlight that section 4.1 of the UoY Policy of Assessment, Examiners, Marking and Feedback 2023/24 (PDF , 1,016kb)(""https://www.york.ac.uk/media/abouttheuniversity/supportservices/academicregistry/registryservices/sca/Policy-assessment-examiner.pdf"") specifies that English is the language of assessment on university programmes, unless another language of assessment is clearly stated. Therefore, over reliance on machine translation to the extent that it diminishes your active involvement and understanding, and results in false authorship, is strictly prohibited. Please also note that some assessments will prohibit translation entirely, and/or you will be unable to access translation tools (such as in closed exams or oral assessments).

Examples of good and/or acceptable use of translation services or tools in assessments
Clarification: for example, checking assessment instructions and guidelines. 
As a dictionary: translating a word, collocation or phrasal level when writing and reading text. 
As a language learning aid: to support language learning and improve proficiency by comparing translations with the original text, identifying vocabulary, checking pronunciation, and grasping grammatical structures.
Articulation check: when using translated text, ask yourself: do you truly comprehend the meaning of the translated text? Can you articulate it effectively if asked to explain? Translation should serve as a comprehension aid rather than a replacement for understanding.

Examples of poor and/or unacceptable use of translation services or tools in assessments
Submitting lengthy chunks of translated work: translated text which is at sentence level or beyond risks submitting work of false authorship. 
Uncritical acceptance: accepting machine-translated text without critical evaluation, careful review, or consideration of accuracy or appropriateness.
Over reliance and lack of engagement: over using machine translation to the extent that it replaces active engagement and understanding of the academic material, resulting in a loss of personal authorship and critical input.
Translating work into the language of assessment: submitting academic work that is entirely generated using machine translation or a human translator, without any personal review, understanding, or modification.
Language-enhancement applications and proofreading services
Language-enhancement applications (LEAs) such as Grammarly and ProWritingAid are online tools which highlight issues and offer suggestions for improvements in various areas of writing, eg with grammatical errors, alternative vocabulary, and sentence rephrasing. Proofreaders, on the other hand, are professional individuals who review written material to identify and in some cases correct errors in grammar, punctuation, spelling, syntax, and formatting (see Policy on Acceptable Assistance with Assessments (Nov 2023) (PDF , 88kb)(""https://www.york.ac.uk/media/abouttheuniversity/supportservices/academicregistry/registryservices/sca/guidetoassessment/UoY%2023_24%20Policy%20on%20Acceptable%20Assistance%20with%20Assessments%20(including%20Generative%20AI,%20Proofreading%20and%20Translation).pdf"")). 
Such tools and services are intended to assist and support you with your writing, but not to produce work which is not your own. If used in an appropriate way, and if permitted in your assignments, the use of online LEAs is not considered academic misconduct and can be beneficial during degree programme. It is important to distinguish online LEAs from other methods used to improve your writing. Using automated paraphrasing tools, for example, can result in work of false authorship being submitted (as well as often poor paraphrasing!) and means you are not applying the skills that you are here to learn.

Examples of good and/or acceptable use of LEAs in assessments
Vocabulary enrichment: using LEAs in a considered way to expand and enrich your vocabulary, aiding in the selection of appropriate and precise words for academic expression.
Grammar and language improvement: utilising LEAs to improve grammar, syntax, punctuation, and overall language structure to enhance the clarity and coherence of your academic writing.
Identify problems: point out and automatically correct typographical errors, and point out but not automatically correct poor grammar and phrases.
Enhance - not mislead: LEAs should be used in a manner that still preserves and reflects your natural ability and competency in English. Enhancements should maintain your voice and style.

Examples of poor and/or unacceptable use of LEAs in assessments
Uncritical acceptance: accepting suggestions without critical evaluation, careful review, or consideration of accuracy, context or appropriateness.
Excessive dependency: if your assessment submission has substitutions which appear to be that of a third party and not your own work, it will be deemed false authorship. Excessively depending on LEAs can hinder your active engagement in learning and ability to independently craft well-written academic work.
Enhancement far beyond unsupported ability: we expect the work you produce to reflect the fact that you are a student, and that you are learning from your mistakes. Depending on the student, producing work which is consistently grammatically flawless and highly cohesive may suggest false authorship, particularly when similar work cannot be produced under conditions where you do not have LEAs or other tools available to you. 
Warnings
It is very important to note the following regarding the use of any of the tools discussed above:
Standard of work and academic misconduct: be aware that misuse and over reliance on the tools and services discussed could result in a) a lower grade in comparison to the original draft; and b) being referred for academic misconduct as the submission may be considered false authorship.
Assistance which hinders learning: it is important to realise that some assessments will be held under closed exam conditions, where you will not be able to use any of the tools or services discussed. Therefore, you should take every opportunity to learn from corrections, suggestions, explanations and misinterpretations provided via these applications in addition to your teachers’ feedback.
Equity and fairness: much of the supportive functionality of the tools discussed above is often only available in ‘premium’ editions which must be paid for. Therefore, tutors can advise on and support students with some applications but such guidance will be limited so as not to disadvantage students who may not have access to the functionality available in the premium, paid-for editions.
Data security, intellectual property and ethics: providing your own work to an individual or software has a degree of risk. Once you have shared your work, you cannot guarantee how that will then be used. The emergence of generative AI, for example, has raised serious concerns about how data is processed and used by the companies and software. 
Recommendations for students
1. Follow policy and guidelines
Pay close attention to this guidance, your assessment specifications and use it in conjunction with the .
2. Keep records of your draft work and notes
It is advisable to keep records of the work you have done and to save different copies of your work rather than overwriting the same file all the time. Keep copies of the research notes you used, the calculations you made, etc. An academic misconduct panel may ask for copies of a student’s work where there is a suspicion of generative AI use. 
3. Be ready to explain your answer and how you produced it
If there is a suspicion of academic misconduct through generative AI use, you may be requested to attend a panel hearing on the case and asked to explain how you produced your work.
4. Make sure you understand what is appropriate for each assessment you take
If you are not sure whether it is acceptable to use generative AI content tools, you should discuss this with your programme leaders, module leaders or supervisors as soon as possible.
5. If you have concerns about other students
We hope that you share our aim of ensuring that everyone is assessed fairly and appropriately and we welcome your help in encouraging each other to adopt appropriate academic practices in your studies. If you have concerns about other students, speak to your supervisor, programme leader or module leader first. See AM2.1.7 Reporting of Academic Misconduct by third parties in our Academic Misconduct Policy(""https://www.york.ac.uk/staff/essentials/supporting-students/academic/taught/misconduct/"") for our formal process but please speak to your department first so that we can be sure that there is no misunderstanding and accusations are not made inappropriately.
ASSESSMENT AND EXAMINATION(""https://www.york.ac.uk/students/studying/assessment-and-examination/"")
University Assessment policies and procedures(""https://www.york.ac.uk/students/studying/assessment-and-examination/guide-to-assessment/"")
Academic misconduct(""https://www.york.ac.uk/students/studying/assessment-and-examination/academic-misconduct/"")
Taking an exam(""https://www.york.ac.uk/students/studying/assessment-and-examination/taking-an-exam/"")
Disability(""https://www.york.ac.uk/students/studying/assessment-and-examination/disability/"")
Artificial Intelligence use in assessment"
21,"Queen's University, Belfast",21_belfastQueens.pdf,https://blogs.qub.ac.uk/wp-content/uploads/sites/7/2024/02/RAISE-Student-1.pdf,"QUB Student Guidance on the 
Use of Generative AI 
Sept 2025

Welcome to the university’s guide on using generative 
AI for students. We want to use AI to help both students 
and staff. Our goal is to make learning better, improve 
how we teach, and ensure that our students acquire the 
skills essential for success in their future careers. As 
we integrate AI, we will do so responsibly, taking into 
account AI’s ethical and social implications.
This guide outlines the principles we commit to uphold 
and provides practical advice on the adoption and use of 
generative AI.R-A-I-S-E

Responsible Use
Students will receive support to understand AI, including its opportunities, 
limitations, and ethical issues.
Students are encouraged to use AI appropriately to support learning. This might 
include using AI to summarise course materials or as a personal tutor that can 
explain concepts and ask revision questions. While AI offers a means to improve our 
productivity and understanding, it needs to be used carefully and appropriately. 
Generative AI systems are trained on vast amounts of data, typically sourced from 
a wide range of public or online resources. They operate by generating outputs that 
draw upon statistical patterns contained within the training data. However, current 
generative AI systems do not possess the critical analysis or ethical judgment 
typically associated with human intelligence. As a result, AI systems might deliver 
inaccurate or even fabricated information, sometimes referred to as ‘hallucinating’. 
Moreover, if the training data contains biased, false, or otherwise inappropriate 
information, then this may be included within the generated output. Therefore, 
results from generative AI systems should always be carefully checked and 
validated. Beyond this, care must also be taken when using public AI tools that 
confidential or protected data is not submitted as this may be a breach of data 
protection requirements. 
For more guidance on the appropriate use of AI, please visit Queen’s AI Hub.

AI Best Practice
The University will collaborate broadly on AI best practices, building diverse 
partnerships and emphasising interdisciplinary and ethical approaches.
Several AI discovery working groups have been established. These groups bring 
together those who want to take on a more active role in exploring how AI can 
be integrated into our activities. This includes exploring new developments, 
creating case studies, and influencing broader discussions. If you’re interested 
in participating, please contact get in contact at AI-Hub@qub.ac.uk.

Integrity
Integrity and academic rigour will be upheld.
Academic integrity is of paramount importance and rigorously upheld within 
all programmes. Students need to be fully aware of when and how they can 
use AI in assessments, including any limitations on certain tools or the need 
to cite or document how AI has been used. If students misuse AI, they will be 
subject to the University’s academic misconduct regulations.
This academic year, those delivering modules will clarify if and how AI can be 
used when completing assessment. If you have any doubts about how AI can 
be used, please consult your tutors. It’s always better to be sure than to take 
risks.

Support
Students will be guided on how to use AI effectively and appropriately.
Support available for students: Queen’s AI Hub offers comprehensive 
information on different aspects of AI and is accessible to both staff and 
students. Explore the responsible use of AI and how it can be applied to 
education and research, or how it can be used to improve our efficiency and 
effectiveness. Additionally, adoption guides tailored to students are available.
Available AI tools and systems: Guidance on the use of AI tools, including 
both QUB-supported tools and publicly available/open systems, can be found 
at Queen’s AI Hub.

Equitable Access
Teaching and assessment practices will be adapted to incorporate appropriate 
AI tools, ensuring equitable access for students.
All students will have opportunities to learn and develop skills in the 
appropriate use of AI tools during their studies. These skills will be essential in 
many future careers. Alongside this, AI can also be a valuable aid in learning 
and revising. However, it’s crucial to use AI correctly. It’s not a panacea and 
can be misused.

AI will be a powerful tool to support student learning 
and prepare for future careers. But, with great power 
comes great responsibility.
Share your experience of using AI in your learning with 
us. We want you to shape how the University can make 
AI relevant to your student life.
Students and AI"
22,University of Glasgow,22_Glasgow.rtf,https://www.gla.ac.uk/myglasgow/sld/ai/students/,"INFO FOR STUDENTS

WHAT IS THE UNIVERSITY OF GLASGOW'S POSITION ON AI?
The University of Glasgow believes artificial intelligence (AI) tools are potentially transformative as well as disruptive. They increasingly feature in academic and professional workplaces.
You will graduate into an AI-augmented world. The university therefore has a responsibility to prepare you for this world, providing space to experiment with, and understand the potential of, AI in an ethical way.
Consequently, rather than seek to prohibit your use of these tools, we want to support you in learning how to use them effectively, ethically, critically, and transparently. 

For advice, classes, and 1:1 appointments to develop your academic writing, visit the Student Learning Development team
www.gla.ac.uk/SLD(""http://www.gla.ac.uk/SLD"")

Are you a PhD student or researcher?
AI Guidance for Researchers(""https://www.gla.ac.uk/research/strategy/ourpolicies/ai-for-researchers/"")


QUICK GUIDANCE FOR STUDENTS
The term 'AI tools' is currently used to refer to a range of tools and resources (not just ChatGPT), which range from being unsuitable for any academic work to being helpful when used appropriately and with academic integrity.
Using machine learning, AI tools can produce human-like text, images, and information, and can respond to specific queries. Tools that can replicate and create the complex responses and behaviours of humans are referred to as 'generative AI'. There are also many computational aids that are used for similar purposes. 
It is important to note that using any form of AI or other computational aids in your university coursework, study, exams, or research without acknowledging that input counts as academic misconduct. 
Don't
assume that all AI tools are equally effective, equally responsible, equally resourceful, and equally capable of being used with academic integrity. AI tools replicate biased results, and do not provide contextualised, evaluated or critiqued evaluation of information.
pay for AI services or tools; your courses will never require you to pay for external software. 
use AI tools as a replacement for your own understanding, analysis, or summary of a topic. 
rely on AI to produce references, resources, materials or any other forms of content. AI is liable to produce 'hallucinations' where it can make up false information and references. 
upload full copies of your work, essay questions, reports, results, and discussion into any AI tool. AI tools should not be used to conduct research or investigation into a topic. If your lecturers want you to use AI for specific activites, they will provide guidance on what is allowed or expected, and what is not.
Do
acknowledge the use of any form of AI in your coursework for all submissions.
question the validity and accuracy of any output, data, results, and information you receive from AI tools.
ensure that all your submissions are the result of your own thought, workings, analysis, and critique.
keep up to date with your course guidelines and information around academic integrity and AI. Pay particular attention to your marking criteria and ILOs; it is your responsibility to demonstrate how you meet these.
be aware of how research AI tools are advertised: they'll often promise time-management and efficiency benefits but will in practice break academic integrity rules.
Continue reading below for more detailed information on the University of Glasgow's policies about what is allowable, what is forbidden, and how we advise that you use AI in your studies.



Introduction to Artificial Intelligence (Al)
Artificial Intelligence (AI) is the work of computers to mimic, replicate and create the complex responses and behaviours of humans. Using machine learning, AI can produce human-like text, images and information, and it can respond to specific queries. 
The availability of a variety of AI platforms is rapidly changing. Various tools are available, but as the technology grows there will be increased competition amongst and change within sector-leading platforms. The platforms that produce text are more accurately known as Large Language Models (LLM), but 'AI' is more commonly used to describe these tools. 
For University-level study and research, AI and its many uses pose a challenge to how we prove our learning for assessment in a way that has integrity and merit. 
The key element of AI is its ability to mimic human-like responses to queries, questions and interrogations. The responses are, however, replications of human-like output and are prone to errors or misunderstandings. AI has limited ability to critique, evaluate or prioritise information, and will often present such output in a superficial way.
More significantly, AI tools have limited capability to fact-check. Some have access to the internet, while others do not. For those that do, they may be able to recognise words as being relevant, but their ability  so as a result, AI can often produce results that are factually incorrect. You should never rely on AI to produce accurate, truthful, critical or reflective information, results of analysis.   
Using any form of AI in your university work or research without acknowledging that input counts as academic misconduct.  
The information below is presented as a way of ensuring you engage with AI in an ethical, transparent manner. This guidance does not prohibit the use of AI in your research and writing process; instead, it outlines how the University of Glasgow believes you can make use of the strengths of AI while maintaining good academic practice, rigour and integrity in your submitted work. 
Academic Integrity
The University of Glasgow’s position on the inappropriate use of AI in research and writing is clear. University policy is that all students are marked and assessed 'in recognition of a student's personal achievement. All work submitted by students for assessment is accepted on the understanding that it is the student's own effort'.
Work that is therefore not your own effort – in other words, work submitted that is the result of the work of AI – does not meet this crucial requirement for our assessments.
The University Regulations on plagiarism define it as: 
'the submission or presentation of work, in any form, which is not one's own, without acknowledgement of the sources' (Plagiarism Statement - see section 32.2(""https://www.gla.ac.uk/myglasgow/apg/policies/uniregs/regulations2023-24/feesandgeneral/studentsupportandconductmatters/reg32/""))
As with all pieces of assessment submitted, then, we expect that your work is a reflection of your own effort. We discuss below some of the ways in which AI can be of benefit to the research and writing process, but it is your responsibility to ensure that the work submitted is a true reflection of your effort. 
That is to say, all your submitted work must be of your own creation, your own critical evaluation process, and your own experience. We expect your submitted work to clearly and transparently acknowledge any sources – including AI – that have helped you reach your conclusion or that have added to the work in any way.  
The fundamental rule with AI and academic integrity is this: 
If you make use of AI at any point in your research or writing process, you must acknowledge the use of that tool as you would any other piece of evidence or material in your submission.
We strongly recommend, however, that you treat AI with caution. AI tools do not 'know' the meaning of what they produce, can only simulate the act of being critical, and are prone to biases, inaccuracies and mistakes. 
As a student graduating with a University of Glasgow degree, critical analysis is a key skill that you should develop. It is a core part of what we assess in you in your final year exams, and it is a fundamental part of what future employers or research supervisors will expect you to be capable of as a graduate.
Using AI for study, research and writing – without breaking our academic integrity rules
 
If we use any form of AI, it must be with the understanding that it does not understand what things mean. This is an important first step in engaging with AI in a successful way.  
The difference between our intelligence and AI is, to put it simply: we understand meanings, contexts, what things say and do, and the connections between different pieces of information. AI cannot do this. 
AI platforms can, however, help us with some of the steps of our work process. So, what can AI do? 
AI can provide a quick summary of information. 
AI can provide details on large volumes of information in a quick time period, but there are dangers involved here around inaccuracies and made-up information. 
If using AI in this way, think of it as the first step. The second step is to check for accuracy, critique the outputs, and ensure you never rely simply on the original outputs. 
AI can identify key points in texts 
AI can produce output of key points in text by scanning the language therein. This can be a useful starting point with reading. 
If using AI in this way, again think of it as a first step. AI does not understand what the text means, and it cannot therefore critique or evaluate any of its outputs. It uses language models to predict outputs based on the highest probability of the next word. So, when identifying key points in texts, AI uses this probability method to display key points based on the words used in the text. As with abstracts for academic journal articles, be aware that a short summary loses much of the nuance, subtlety, counterpoint and critique within a whole piece of reading, so make sure to also read fully to confirm (or otherwise) what the brief summary gave you for your starting point.
AI can help you refine your wording 
Think of AI here as a kind-of conversation partner: you can ask it to rework some writing to enhance clarity. You can ask it to refine the output to make the text more simplistic, more complex, longer, shorter, and so on.
Do not enter entire essays or paragraphs; use the method to help improve the language of words, phrases or individual sentences. You must ask the tool to offer you an explanation of why it has made the suggestions that it has so that you can use this advice to learn how to improve your own writing the first time around in the future. AI tools commonly use more adjectives or adverbs than would be suitable for an academic essay, even if your prompt asks specifically for a response in an academic tone, so make sure that you are happy with any suggestions before adapting them into your own piece of work. Again: do not create entire paragraphs from individually AI-constructed sentences; the work must be your own.
Importantly, however, you must remember that AI uses predictions of the most likely next word based on what has been found in the material used to train whichever tool you are using. This is all it is doing: it simulates human responses, and it does not have the true intelligence capacity to understand why things might be right, might be wrong, might be stronger, or might be weaker.
Separately from AI, there are plenty of other digital tools that can help with your academic work. These resources and tools do not mimic human language in the way AI does, but they are powerful and useful tools. EndNote, for example, helps you catalogue your references and resources, while software like ResearchRabbit, Google Scholar, etc., can help with searching for resources.  
Use of these digital tools is a part of modern-day study. If you have questions about using digital tools for study or research, you can speak with SLD by making a one-to-one appointment(""https://www.gla.ac.uk/myglasgow/sld/"").
AI: Important Limitations, Important Problems
Current AI tools are limited in the capacity to create meaning that is true, accurate, critical and responsive. You must judge any outputs from AI tools with scepticism, suspicion and a critical eye. 
Key problems with AI include: 
AI gets things wrong.
AI will produce incorrect (and sometimes nonsensical) outputs.
AI does not know right/correct from wrong, and will present all outputs as if they are equally valid and true.
AI is biased.
AI tools reflect, prioritise and enhance biases and stereotypes.  
AI is not rational and does not understand the complexities around the information available on the internet. It therefore cannot judge inaccurate, offensive statements.
AI makes things up. 
Called 'hallucinations', some AI tools will make up false references to texts that do not exist. While these references often look to be real, a quick search will reveal that the supposed reference or data does not exist.
This is because AI tools are simply predicting the most likely next word each time – think of it like asking your phone to write a sentence based on clicking the next autocorrect word each time.
AI tools cannot access all the necessary data and information.
AI tools cannot access anything behind a paywall. For your academic work, the University Library subscribes to a massive collection of academic texts. AI cannot access these paid resources, and so it does not have the ability to reproduce any information from those texts.
Many AI tools also do not have access to the current state of the internet, and therefore will not be trained on the most recent information.
How should I reference Artificial Intelligence?
The current consensus on how to reference any use of AI is to treat it as if it were private correspondence.
The reasons for this are:
Like private correspondence, the prompts and responses you enter into and receive from AI are unique to you
Like private correspondence, AI is a problematic source as it cannot be easily replicated and verified
Like private correspondence, each prompt and response session with AI is time-bound, specific and unique to that moment in time.
The specific rules for many referencing styles are still to be finalised, but the general rules are:
Name the AI platform used (e.g. ChatGPT, Claude) 
Include details on the date of use of AI
Ideally, include details on the prompts input (and, if possible, the responses received)
Include details of the person who input the prompts
Keep records of the responses output by AI, even if you do not include these in the submission itself
Be clear, open and transparent in your use of AI
Do not present any of the responses from AI as your own writing, thought or work. This constitutes academic misconduct, which could lead to disciplinary measures being taken against you."
23,University of Aberdeen,23_Aberdeen.pdf,https://learn-eu-central-1-prod-fleet01-xythos.content.blackboardcdn.com/5a33b54d59cd9/70486558?X-Blackboard-S3-Bucket=learn-eu-central-1-prod-fleet01-xythos&X-Blackboard-Expiration=1760464800000&X-Blackboard-Signature=1ExClYgr5oV7WN2iaKfV7GbaFzXIUI5DyMPjHGSy2mM%3D&X-Blackboard-Client-Id=301884&X-Blackboard-S3-Region=eu-central-1&response-cache-control=private%2C%20max-age%3D21600&response-content-disposition=inline%3B%20filename%2A%3DUTF-8%27%27GL22_Staff%2520Guidance%2520on%2520Use%2520of%2520GenAI%2520Tools%2520in%2520Education.pdf&response-content-type=application%2Fpdf&X-Amz-Security-Token=IQoJb3JpZ2luX2VjELT%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDGV1LWNlbnRyYWwtMSJIMEYCIQDoxyulP%2F01E0efEPDCRTfqEB0Ngv%2B1qUFguunWXsuu4wIhAPm7wf%2BuLvcqNXyop8V%2Bi9LtaQK9glzyKO%2FMBzDGjNDqKr0FCF0QBBoMNjM1NTY3OTI0MTgzIgzaohisCL2loZ41kFwqmgW74etw20ohMga55bV9xDxEpNtE%2FxXd%2BWdGxvo3VREsD7tiuFAlurGCjBRxGMqAag1yKc12KI5%2BEB23Ibt9e0HX3UWKIH1%2BKfN84po9HEA4aOcdsw3lqa%2FfpFEC9HzO0G0rvSi8rrzYS3mxGzekt1FhOvbYIJtmxdYC7LahqQKuN7dg79AU9ZkEtn9dilTJZpH5exImCz0RsC27KEALaIqeMNV3I8p%2BRSbLL0M1z4t9rl9iWCjd%2F3v3c9ukRrgPduZhPqoTIEPTZtBgsE1l9nZKv5i6y46%2BJCChRMXvakxCibfIO0IlZCKVsIhkDtePHzRlSMhsxNziLonPXipveau%2BIgo1d5vN5yRdXJr99VWJN25Ee%2Be8mh9wU6i9qYqybJhScT2h49tVBvkGZUf6w%2B4NcSt8dznmI%2B6qJ0akZ21XFfWL2NJQhRj4x%2FFpjwlxUXIgKI1hyi%2F4rnYuOg71OYt3cVVw1UNdSpUljXpblbDUunwaL7PzwH5aSC1D0rKr4Q4X3TaSPn34Z%2BknSm3fUNb6aB4RLQakNU%2F%2BZmORY7RVzGFMJw78JzcTUN1uT6xn9zeipk1VZ5OWjyKKvaUr7Mbp81xPEVLeofxrUeSNIkui2N%2BcYYOcvVbdYSt3Rd96XW7eh0EzVwRaus%2BnYXIonIHOagZkqJ61wHwqpA%2BjbgASAGdNbA5CW9L83IKItd806JStGJ9VQt58URZR40nQxlsiaT4Fjp2NvUn9AG%2BUnPTXBX3ghPQjLMuXQ2jgO42gZA2t2gv6G7kCLK4qzlKtCoAn8AWcIoIzhnCpHVR4c1qrAROXhsjTDFPxBjXDCsj01d8PKHtJ0OBMFJwSLrNvG3FkFmY51bl05g5FP%2BIhkMPTFRmV54KqQTWtVl8wr%2Bi4xwY6sAHxj%2B6nZV1Sv6rQSdahj5b6zGBG99s6NPh3ljDl6YzxqCa1yRlkwvTVNwa6OyqoE1hw2Uy7yYZWxSryTHBIX2O6mv5BIGPuHgx4UjKC7sS3%2FkgkNpQyFVgGzSstc0AvGlibjuC2gYbQgH63NhFG3NFTFaYYUQppe%2FLMfby5Z2z2%2BNx2OsaeoJyXs5zOWxxZ2pXRkjdEU6KWVKNBtlBRDlry%2B7JdAp%2FdmueYBUMSu%2BEDXQ%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251014T120000Z&X-Amz-SignedHeaders=host&X-Amz-Expires=21600&X-Amz-Credential=ASIAZH6WM4PL5NRJGX2O%2F20251014%2Feu-central-1%2Fs3%2Faws4_request&X-Amz-Signature=2488ccb73f4d588fc3d37ff7bd36c04055aadda56a33377c7351cb5680b44ded,"This work is licensed under a  Creative Commons Attribution -ShareAlike  4.0 International License  1 
 
Guidance for Staff on the Use of Generative Artificial Intelligence Tools in Education  
Regularly updated: last update 1 7 September  2025 . Comments? Email cad@abdn.ac.uk.  
The University is committed to supporting staff and students to use generative artificial intelligence 
(GenAI) tools in a responsible, critical, and ethical manner.    
Background  
GenAI tools  came to prominence with the release in November 2022 of ChatGPT , a chatbot that uses 
a large language model to interact with people  in a conversational way .  GenAI tools  can be used to 
generate various types of new content, including images, text, music and videos . They include, but 
are not limited to, tools such as MS Copilot , ChatGPT, DALL -E, DeepSeek , GitHub Copilot, Google 
Gemini, Midjourney and Perplexity AI.  
Early discussions focussed on  the implications of GenAI tools  for assessment and academic integrit y. 
For example, when ChatGPT was prompted in an iterative manner by an expert, it was  shown to 
generate good answers to questions in a final exam of a typical MBA course (Terwiesch, 2023).  
However, th e ubiquity of these tools and the exponential growth in their development and 
application to all aspects of our lives has resulted in the broadening of discussion s to explor e the 
opportunities  they offer and the i mportance of supporting staff and students to become AI -literate , 
while ensuring academic standards are maintained.  
This guidance outlines the following : 
1. The limitations and ethical considerations when using GenAI tools in Education  
2. Communications to students on the use of GenAI tools  
3. Adapting assessments for an AI -enabled world  
4. Dealing with a student suspected of academic misconduct in relation to GenAI tool use  
5. Further information and resources  
1. Limitations and e thical considerations when using GenAI tools  
You need to be aware of the limitations and ethical considerations associated with GenAI tools , both 
for your own practice and  in order to support students to develop the skills to make an informed 
decision  on whether to use these tools , and where they choose to use them to do so  responsibly, 
critically and ethically.  These limitations and ethical considerations include:  
1.1 Inaccurate information and misinterpretation of users’ prompts  
GenAI tools  that generate  text will produce  text based on the probabilities of certain words or 
sequences of words appearing together, or section of programming code, based on patterns in the 
data it has been trained on. They do not capture meaning or understand ( Bender and Koller, 2020 ) 
and therefore the output can be inaccurate or reflect incorrect information or biases inherent in the 
data it was trained on.  They can confidently fabricate content, citations and references . This is a 
phenomenon known as “hallucinations” . Furthermore, w riting prompts to generate useful content 
from GenAI tools is a skilled process and therefore misleading or unclear prompts can also lead to incorrect and irrelevant information being generated.   
  
This work is licensed under a  Creative Commons Attribution -ShareAlike  4.0 International License  2 
 
It is important that all users of these tools critically evaluate the output from and use academic and 
discipline -specific sources to fact check the o utputs . 
1.2 Privacy and data considerations  
There are many risks to data privacy and intellectual property when entering prompts or data into 
GenAI tools . You should not be entering any University data , such as  student work, research data , 
lecture materials , without appropriate permissions .   
 
When using AI technologies check the terms and conditions regarding the reuse of content you input into the system to ensure this aligns with permissions you have obtained and be aware that 
attribution of ideas and outputs to the original authors and creators is problematic .  
 
If you have any queries regarding the use of personal data and AI please contact the Information 
Govern ance Team at dpa@abdn.ac.uk .  
1.3 Ethical considerations  
If you are going to be using GenAI tool s, you must take the following into consideration:  
• Perpetuating harmful stereotypes –  since GenAI models inherit biases from their training data 
it is essential to identify and correct these biases in any outputs that you then use to prevent 
the perpetuation of harmful stereotypes.  
• Equal access for all – since many GenAI tools come with subscription fees or pay -per-use 
models , which can create financial barriers, i t is essential to ensure that there is no detriment 
to students who don’t have the means to pay or choose not to use these tools . 
• Environmental impact –  since GenAI models consume significant electricity and water, often 
linked to data centres, reflect on how you use these tools to minimise your impact. For example, write clear, precise prompts to reduce repeated queries and avoid as king for the 
generation of multiple versions of the same output (image, text, video) in order to choose 
one.  
• Human impact –  use providers that share their employment practices and are committed to 
fair wages and good working conditions.  
1.4 Copyright and plagiarism  
There is no specific legislation for AI technologies; reuse of material is subject to the exceptions outlined in the Copyright, Designs and Patents Act 1988. The same is true of legislation regarding personal data and the Data Protection Act 2018  which outlines the UK’s implementation of the 
General Data Protection Regulation (GDPR) . 
However, y ou need to be aware that GenAI tools can  generate new content from content  produced 
by people  (e.g. artists, musicians, writers, scientists) without acknowledging them, which is regarded 
as plagiarism.  
You should review the data the GenAI tool has been trained on  (e.g. is it open source? Or a licenced 
dataset? ) and always reference appropriate sources even if the GenAI tool did not.  
For further advice on copyright please  consult the copyright web pages  or email library@abdn.ac.uk . 
  
This work is licensed under a  Creative Commons Attribution -ShareAlike  4.0 International License  3 
 
Important: It is essential that where s tudents or staff mak e an informed decision  to 
opt out of using GenAI t ools, this  decision does not negatively impact their ability to 
succeed academically or professionally.  
 
 
2. Communications to stu dents on the use of GenAI tools  
2.1 Designing in  conversations about the use of GenAI tools  
Consider designing in opportunities for staff and students to discuss the use of GenAI tools, within 
the context of their discipline, including the limitations and ethical considerations, as outlined in the 
Guidance for Students on the Use of GenAI Tools in Edu cation . 
2.2 Inform  students if they are permitted to use GenAI tools for assessed work  
Course Coordinators must provide clear guidance to students on what is permitted in relation to the 
use of GenAI tools  for the preparation of work that will be submitted for assessment. There is text on 
permitted levels of GenAI tool use for assessments embedded in course templates in MyAberdeen , 
which staff can refer to in assessment briefs or modify to align with staff expectations and  those of 
Professional Statutory and Regulatory Bodies (PSRBs).  
For those not using MyAberdeen, staff can use or modify the text on permitted levels of GenAI tool  
use for assessments.    
If GenAI tool(s) are not permitted to be used for assessed work , provide a rationale for this , and 
provide guidance to students on how they can demonstrate the authenticity of their work . For 
example, by making it explicit that you are assessing the process by which they arrived at the final 
product, rather than the product itself, and that you expect students to keep notes and drafts  of their 
work, to illustrate their creative process.  Consider directing students to the Guidance on assignment 
notes, drafts and document versioning .  
3. Adapting  Assessments for a GenAI -enabled world  
There are adaptations that you  can make to existing assessments,  or you can take the opportunity  to 
redesign assessments to enhance their  authentic ity and ensure students develop the knowledge, 
skills and attributes that will help them succeed in their studies and future careers in an AI -enabled 
world.  
3.1 Adaptions  you can make to your existing assessment (s) 
Review your assessment brief and consider what small changes you can make to it, without changing 
the mode of assessment  and whic h “design out” or minimise any unfair advantages GenAI tools could 
give to students.  The following examples  may help:  
• Consider phrasing your assessment in a way that that makes it explicit that it must be in their own words e.g. “In your own words ……”  
• Ask students to analyse, evaluate or synthesise information as part of the assessment brief , 
which require students to apply their knowledge and understanding rather than recall information . 

  
This work is licensed under a  Creative Commons Attribution -ShareAlike  4.0 International License  4 
 
• Require students to include current local or course -specific references in their response e.g., 
drawing on local text, reading, experiment, field trip.  
• Consider using a range of formats across their programme , such as group submissions, audio 
or video recording s, or other artefact?  
• Incorporate student reflections on the development of their assignment as part of the 
submission . 
• Ask students to create visual elements  as part of their response to a question  e.g.,  a diagram, 
mind map or flow chart , as opposed to a text answer . 
If you have other ideas or suggestions of adaptations that staff can make to their assessment,  please 
email cad@abdn.ac.uk .  
3.2 Designing a new assessment  
There are many  resources being made across the sector to inspire and suppo rt staff with designing 
their assessment in an AI -enabled world. One of the most comprehensive is Ji sc’s “Assessment ideas 
for an AI enabled world ” which is available for download .  
• Design assessments that measure creativity and o riginality. GenAI tools can provide fast, 
formulaic answers, but they struggle with truly creative work. Encourage students to propose 
new ideas, designs, or solutions to a problem that hasn’t been addressed before or in an 
unconventional way.  
• Enable personalisation  of asse ssment. G ive students more agency over their learning, 
encouraging them to pursue topics they find interesting while still adhering to the assessment criteria. It creates a sense of ownership and intrinsic motivation.  
• Make the most of group work.  Assess group work by focussing on evaluating the process of 
working in a group , such as communication, decision -making, conflict resolution, time 
management, not just the produc t of the group work.  
• Focus on the “ process ”. Assessments should emphasise the process of learning, not just the 
final outcome . This can include evaluating the steps taken to reach a conclusion, the sources 
consulted, and the methodology used. Ensuring strong alignment between formative and 
summative assessments  can aid this process . 
• Introduce interactive and s cenario -based assessments. Use simulations, scenario -based 
questions, and adaptive testing, where the assessment adjusts based on the student’s 
responses. This can make assessments more engaging and reflective of real- world situations.  
(you can use GenAI tools to support the  creati on of these)  
Discuss your assessment design with colleagues in your discipline  or contact the Centre for Academic 
Development  for advice by emailing cad@abdn.ac.uk .  
  
  
This work is licensed under a  Creative Commons Attribution -ShareAlike  4.0 International License  5 
 
4. Dealing with a student suspected of academic misconduct in relation to 
GenAI tool use  
There are no reliable detection tools for content generated by a GenAI tool. Those that are available 
can be easily manipulated .  
Important: Under no circumstances should any staff member submit student work 
into AI detection tools. Safeguarding both students' intellectual property and ensuring 
data protection is essential to maintaining trust and upholding our commitment to 
ethical conduct.  
If you suspect a student has used GenAI tools to gain an unfair advantage in an assessment, consider 
using this matrix to evaluate potential GenAI misuse  in assessments. A fter reflecting on specific areas 
that raise d suspicion if y ou fee l that there is sufficient grounds for  further investigation then follow 
your School’s procedures  for conducting a n investigation into  whether academic misconduct has 
taken plac e.  The University regulations and procedures for cases of Academic Misconduct  states that 
for unauthorised or unacknowledged GenAI tool use , these are dealt with under “Plagiarism”  (Section 
3.2 of the Code of Practice on Student Discipline (Academic) for 2023/24) .   
At a meeting of the School investigation panel , they  may  ask the student to:  
• Provi de Evidence of the Creation Process  
This evidence can include earlier drafts, notes or documentation that illustrates the 
development of ideas and writing. Guidance for students on creating assignment notes, drafts 
and document versioning  is available.  
• Describe How the y Approached their Assessment and Demonstrate their  Understanding   
Students should be prepared to discuss their work to determine if their level of knowledge 
aligns with that demonstrated in the submitted assignment, and to enable them to explain their thought processes in creating the ir assignment.  
5. Further Information and Resources  
Generative Artificial Intelligence | StaffNet | The University of Aberdeen (abdn.ac.uk)  
References:  
1. Bender, E.M. & Koller, A. (2020)  Climbing towards NLU: On Meaning, Form and Understanding in 
the Age of Data , Proceedings of the 58th Annual Meeting of the Association for Computational 
Linguistics, pages 5185- 5198. 
2. Terwiesch, C. (2023).  Would Chat GPT Get a Wharton MBA? A Prediction Based on Its 
Performance in the Operations Management Course , Mack Institute for Innovation Management 
at the Wharton School, University of Pennsylvania ."
24,University of Dundee,24_Dundee.rtf,https://www.dundee.ac.uk/corporate-information/use-generative-artificial-intelligence-students,"Code of conduct
Use of generative artificial intelligence for students
Guidelines for the appropriate use and acknowledgement of generative artificial intelligence (GAI) in assessments and assignments
Updated on 1 November 2024
12. The AI assessment scale

If you are looking for targeted help to acknowledge and use AI responsibly in your assessments, our student guide(""https://www.dundee.ac.uk/guides/get-help-using-ai-responsibly-study"") has everything you need to know. 
1. Introduction
Artificial intelligence (AI) touches our lives on a daily basis, even though we may not be fully aware of it. Facial recognition to unlock your smartphone, predictive text in messaging apps, auto-complete suggestions on Google search, online customer support chatbots, recommendations from Netflix or Amazon on what to watch or buy next, and what you see as you swipe through your social media feeds. These are all reliant on AI. 
More recently there has been significant attention given to generative AI (GAI) tools. These tools can generate writing on pretty much any topic, generate code and presentations, artwork, graphics, video, and audio. There are many GAI tools such as:
		Microsoft’s Copilot
		ChatGPT
		Google Gemini
		Claude
		Perplexity.ai
		DALL-E
These tools are developing and evolving at a rapid rate and have the potential to be transformative. It is essential that our staff and students have the skills and knowledge to navigate the world of GAI and understand how it can be applied. 
2. Purpose of guidance
It is against this backdrop of growing interest in the adoption of GAI that we have prepared this guidance to help our student community understand how it can be used appropriately. Our aim is to help students appreciate both the limitations of GAI and the ethical and data implications of using these technologies. It is not feasible for the University to impose a blanket restriction on the use of GAI, rather we seek to promote the discerning, transparent and ethical use of it. 
3. Review
As GAI is increasingly integrated into commonly used digital tools we will regularly review and update this guidance to ensure it remains up to date.
4. Using GAI to support your learning
One of the attractions of GAI technologies is their potential to support learning as they respond to specific prompts and questioning. Whilst a Google search generates a list of websites with content relevant to your search prompt, GAI will generate a written answer in response to your question that simulates natural conversation. The content it generates can help provide overviews of topics, concepts, theories etc., much as a Wikipedia article might help you develop your initial understanding of a topic. However, just as with Wikipedia it is important to appreciate the limitations of GAI as well as some of the risks associated with its use.
GAI tools should not be used to generate an essay or answers to assessments and which are then submitted as your own work. 
The University’s degrees and other academic awards are granted in recognition of a candidate’s personal achievement and assessments must contain student’s original work. Where the use of GAI is permitted in assessments and assignments this must be acknowledged and guidance on how to do this follows.
5. Limitations of GAI
It is important to appreciate that artificial intelligence is not the same as human intelligence. AI tools do not understand the content they generate and cannot validate the accuracy of it. These tools are trained on content and rely on pattern recognition to predict what strings of words and sentences should be generated next. 
Key points to be aware of include: 
		Whilst the outputs of GAI can appear to be well written and credible, AI tools do get things wrong and therefore you cannot rely on them for factual accuracy. You may see these called “hallucinations” in some discussions about AI tools. 
		It is not uncommon for AI tools to make up references and citations that are completely fictitious, that don’t exist. You won’t find these articles or texts in our Library collections or the wider internet.
		GAI tools tend to perform better in subjects which are widely written about and do worse in specialist areas. The data models on which they are trained are also not up-to-date. 
		AI can replicate human bias and discrimination, perpetuating particular stereotypes and perspectives associated with the Global West. 
		It is important to review and check the content that GAI presents. It can sound convincing and plausible, so it is essential to apply your critical thinking skills and check the accuracy of what it presents. 
Your lecturers will have curated resource lists of textbooks, journal articles, web-based articles, videos, and collections of artefacts that are accessible via your modules in My Dundee. These are all reliable and have been selected to support the learning outcomes of your programme. Our Library subject guides(""https://libguides.dundee.ac.uk/"") also provide more details of how to search and access discipline specific collections and databases.
6. Impact of overreliance on GAI tools
Relying too heavily on, or overusing, GAI will limit your own learning and the development of core skills which many employers are looking for in graduates. Skills such as problem solving, critical thinking, analytical skills, and critical reflection may be inhibited. Such concerns have already been raised by UK-based students in Jisc’s report on Student perceptions of generative AI(""https://www.jisc.ac.uk/reports/student-perceptions-of-generative-ai""): ""Students express concerns about the potential negative consequences of relying too heavily on generative AI tools, as it could impede their intellectual growth. They worry that an excessive reliance on such tools may lead to a decline in knowledge acquisition and hinder the development of critical thinking skills.""
Use GAI to support your learning and personal development, not to do your learning for you.
7. Privacy, ethics and risks of using GAI tools
There are thousands of GAI tools, and new ones are appearing every day. Before you sign up to use any of these GAI tools it is important to carefully read the terms and conditions and not blindly accept them. Take time to read and understand how these tools might use your personal data, and the data you might share with the tool to prompt answers. Think carefully about any potential risks, ethical and privacy issues, as well as benefits before you sign up. This is particularly important for free GAI tools, these tools are rarely genuinely free, they often make money by using or selling your data.
Be aware that:
		Sharing personal or sensitive data in an AI platform, just as with social media, has the potential for it become publicly available. This also applies to any research data or intellectual property that you may share. You should ensure that you do not share personal data (yours, or anyone else’s), nor confidential university material. 
		GAI does not respect copyright or credit the sources that it has been trained on. This is more apparent in relation to creative works in art and literature and in computer code, and there are a number of pending lawsuits against GAI companies for breach of copyright. Using copyrighted material in this way could land you in trouble. 
		GAI companies train their models on content that we submit, this in turn helps them generate income. 
		There are concerns that some of these platforms have adopted exploitative and unethical practices to cleanse their data of violent and hateful content by employing individuals in developing countries who have been traumatised by the content they have had to vet. 
		Concerns also prevail about the environmental impact of GAI. These technologies have high energy and water requirements. 
		You do not have to use these tools if you do not wish to. 
		Misuse of these GAI tools may result in academic misconduct.
8. Acceptable uses of GAI
Some examples of how you might use GAI to support your learning include: 
		Supporting research into a topic or concept to help develop initial understanding and insight. The answers that GAI presents are based on material which can be found on the internet. 
		Help with drafting ideas or suggesting how you might structure your own written materials. 
		Generating graphics, images, and other visual content to support a presentation, or for inclusion in a report. 
		Summarising longer texts and documents to help you check your own understanding of the key messages and concepts presented. 
		Generating questions from an article/text to help check your understanding and recall of key concepts and learning points. 
		Using it as a conversational or debating partner to develop your ideas and thinking. 
		Helping to improve your grammar or writing structure, this may be particularly helpful if English is your second language. 
		Debugging code. 
		Helping to keep you motivated and overcome writer’s block by asking it to generate initial ideas that you can reflect and build on. 
		Suggesting aspects you may have omitted. This can be particularly valuable if you prefer to start planning/writing yourself, before using AI.
9. GAI and assessment
Academic integrity is central to the University’s core values of valuing people, working together, integrity, making a difference, and excellence. 
The expectation is that the work you submit for your assessments is solely your own work, or in the case of group work, solely the work of your group. This work is a means for you to demonstrate what you have learned.
Submitting work which is not your own, and the unauthorised use of GAI, is considered academic misconduct.
Using GAI to write the text, code, or generate the designs and artwork for your assessment would not be submitting your own work. 
If your lecturers have made clear in your assessment brief that you may use GAI sources in your work then you must be transparent in acknowledging, describing, and referencing how you have used it. Contact your module leader if you are unsure whether you are permitted to use any AI tools in your submission. 
If you are unsure about evaluating the accuracy of the content that AI has generated: 
		Contact the lecturer (they are subject matter experts) 
		Contact the Academic Librarian Team (they are information evaluation and referencing experts)
10. Acknowledging the use of GAI in your work
It is important to acknowledge the use of GAI tools in your work and to be clear about how you have used them. You should therefore include a statement of acknowledgement and a description of how you have used GAI and the information generated.
Statement of acknowledgement
Please include the statement that reflects how you have used any GAI tools from one of the following:
		No content generated by AI technologies has been presented as my own work. 
		I acknowledge the use of [AI tool] to generate materials for background research and self-study in the drafting of this assessment. 
		I acknowledge the use of [AI tool] to structure or plan this assessment. 
		I acknowledge the use of [AI tool] to generate materials that were included within my final assessment in modified form. 
		I acknowledge the use of [AI tool] to generate materials that were included in my final assessment in unmodified form. An example of this would be a quote or image produced by the AI output.
Description of how information or material was generated
You must describe how the information or material was generated, what the output was and how the output was modified by you using the following format: 
		The following prompts were input into (name of AI tool: [Provide details]) 
		The output obtained was: (Paste the full output generated by the AI tool) 
		The output was changed and adapted by me in the following ways: (explain how you adapted the output for use in your work)
Keeping a record of how you have created your work
If staff have concerns that you have used AI to support you creating coursework, in ways that are not permitted, they may invite you to an interview to discuss your work. Part of this may include asking you to explain how the work was created, or about particular decisions you made. 
For all coursework we recommend: 
		Use Word/Powerpoint, saving it in OneDrive as this will ensure that all your versions are retained. (This is also a useful backup in case of your laptop failing) 
		If you use Pages, ensure you save versions on a regular basis. 
		If you’re more of a pen and paper planner, keep the plans you have made. 
		In all cases, remember to keep information about what you’ve excluded, as well as included, so that you can talk about this.
11. Referencing GAI
Not all referencing styles require you to cite GAI in your work, but most do. If you are unsure which referencing style to use, contact your tutor.  
CiteThemRight – AI guidance(""https://www-citethemrightonline-com.libezproxy.dundee.ac.uk/search-results?any=%22generative%20AI%22&su=examplesofreferencing"")
(University login required if off campus)
As content generated by GAI is non-recoverable, it cannot be retrieved or linked to in the way that other resources can. If the recommended style for your subject area has not yet got guidance, we recommend that AI generated content should be cited as a personal communication as an in-text citation.
In-text citation
This is an example using Harvard guidance: When prompted by the author, ChatGPT responded with a ‘definition of academic integrity’ (OpenAI ChatGPT, 2023). A copy of this response is in Appendix 1.
Reference list
OpenAI ChatGPT (2023) ChatGPT response to John Stephens, 2 April. 
If you are not sure about referencing AI generated content, contact the Academic Librarian Team.
12. The AI assessment scale
The AI assessment scale can be used to support both staff and students in their use of AI within assessment.
1|No AI|The assessment is completed entirely without AI assistance in a controlled environment, ensuring that students rely solely on their existing knowledge, understanding, and skills. 
You must not use AI at any point during the assessment. You must demonstrate your core skills and knowledge.|
2|AI Planning|AI may be used for pre-task activities such as brainstorming, outlining and initial research. This level focuses on the effective use of AI for planning, synthesis, and ideation, but assessments should emphasise the ability to develop and refine these ideas independently. 
You may use AI for planning, idea development, and research. Your final submission should show how you have developed and refined these ideas.|
3|AI Collaboration|AI may be used to help complete the task, including idea generation, drafting, feedback, and refinement. Students should critically evaluate and modify the AI suggested outputs, demonstrating their understanding. 
You may use AI to assist with specific tasks such as drafting text, refining and evaluating your work. You must critically evaluate and modify any AI-generated content you use.|
4|Full AI|AI may be used to complete any elements of the task, with students directing AI to achieve the assessment goals. Assessments at this level may also require engagement with AI to achieve goals and solve problems. 
You may use AI extensively throughout your work either as you wish, or as specifically directed in your assessment. Focus on directing AI to achieve your goals while demonstrating your critical thinking.|
5|AI Exploration|AI is used creatively to enhance problem-solving, generate novel insights, or develop innovative solutions to solve problems. Students and educators co-design assessments to explore unique AI applications within the field of study. 
You should use AI creatively to solve the task, potentially co-designing new approaches with your instructor.|
Creative Commons: Perkins, Furze, Roe & MacVaugh (2024) -
The AI Assessment Scale
(""https://leonfurze.com/2024/08/28/updating-the-ai-assessment-scale"")Generative Artificial Intelligence can be a very powerful tool, when used effectively. However, it has its limitations. As a student, you need to ensure that you have both the skill sets that a future employer would expect, as well as the ability to use GenAI effectively in your field. Practice and guidance in the use of GAI is evolving rapidly and is likely to change over time. 
You should regularly check back and review this guide to ensure that your practice is in line with the most up-to-date advice from the University.
Acknowledgement: This guidance is informed by and builds on guidance developed by UCL, Heriot Watt University and Napier University."
25,University of Edinburgh,25_Edinburgh.rtf,https://information-services.ed.ac.uk/computing/communication-and-collaboration/elm/generative-ai-guidance-for-students/using-generative,"Using generative AI in your studies: guidelines for students
General guidance for all students on using generative AI tools in your studies.
The University trusts you to act with integrity in your use of generative AI for your studies.
It does not ban the use of generative AI, though its use is restricted for assessment. 
Some of your courses may also restrict its use in other ways. Always check your course level guidance.
These top-level guidelines provide clarity on which uses of generative AI are strictly prohibited and constitute academic misconduct
They also explain why you should be cautious about over-reliance on generative AI for your learning.
This guidance is general and sets out the basics of the University’s position – it is essential that you also check the detailed information provided for each of your courses.
Generative AI at Edinburgh
The University recognises that developing skills in the responsible use of generative AI is important and will likely be significant for your future life and work. It also recognises that there are times when you may want – or be asked – to use it in your current studies. We want to ensure that you have the knowledge and skills to thrive in a changing world, and we recognise that generative AI can be used creatively, critically and with integrity.
These guidelines are general to the whole University. It is important that you are aware that each course will have its own, more detailed, guidance. You should always check your course documentation on this, and speak to your Course Organiser if you are unsure.
The University trusts you as students to act responsibly in relation to the use of generative AI. It also recognises that you need clarity on when its use breaches the University’s rules on academic misconduct. These guidelines provide you with this clarity.
 
Unacceptable uses of generative AI for assessment
Passing off someone – or something’s – work as your own for an assessment is academic misconduct. This could be failing to cite a source you have used in piece of assessed work, getting someone else to complete an assessment for you, claiming authorship of machine-generated content or presenting machine-translated work as your own.
If you submit a piece of work for assessment that is not your own original work you risk being investigated according to the university’s academic misconduct investigation procedures(""https://registryservices.ed.ac.uk/academic-services/students/conduct/academic-misconduct/academic-misconduct-procedure""). This could have serious implications for you and your studies.
The following uses of generative AI are not acceptable and constitute misconduct: if you use them you risk investigation and penalties.
Presenting AI outputs as your own, original work.
Use of an AI translator to convert assessments to English before submission: English is the language of teaching and assessment at Edinburgh – machine translation is treated as false authorship and is not acceptable.
Submitting an assessment which includes elements of AI-generated text without acknowledgment.
Submitting an assessment which includes AI-generated images, audio or video without acknowledgment.
Submitting an assessment which includes AI-generated mathematical formulae or reasoning, or computer code, without acknowledgment.
Citing AI-found sources without reading and verifying them.
For more detailed information about the restrictions around using AI-supported online proofing tools, please see the University’s Guidance on Proofreading of Student Assessments(""https://www.ed.ac.uk/files/atoms/files/academicmisconductproofreadingguidance.pdf"").
 
Using generative AI to support your learning
While we have these clear restrictions around the use of generative AI in your assessed work, the University understands that there are ways in which you may wish to use it to support your studies. 
This might include using it to:
brainstorm ideas
get quick definitions of concepts
overcome writer’s block through dialogue
check your grammar
organise or summarise information
re-format your references
Some courses may encourage or even require you to use it in certain ways, while others may ask you not to use it at all. Again, it is important that you check your course-level guidance on this. 
 
Reasons to be cautious about your use of generative AI
You should be aware that there are risks and disadvantages associated with over-use of generative AI to support learning.
 
Cognitive offloading
There is growing research evidence that over-use of generative AI can negatively affect your learning. You may want to look at studies which raise concern over how ‘cognitive offloading’, ‘metacognitive laziness’ and reduction in capacity for critical thinking(""https://www.microsoft.com/en-us/research/publication/the-impact-of-generative-ai-on-critical-thinking-self-reported-reductions-in-cognitive-effort-and-confidence-effects-from-a-survey-of-knowledge-workers/"") may be associated with over-reliance on this technology. 
If you routinely use generative AI for breaking down and summarising long texts, for example, you will not be developing your own critical skills in the analysis of complex documents. You will also not be practicing and learning how to bring together complex ideas using the power of your own intelligence. Similarly, if you are using it to regularly assist with mathematical reasoning or coding, you are undermining your own ability to learn and become expert at doing this yourself. To make the most of your time at university, embracing the hard work of learning is a better approach than looking for short-cuts. 
 
Bias and inaccuracy
Generative AI models are not ‘intelligent’(""https://www.theatlantic.com/culture/archive/2025/06/artificial-intelligence-illiteracy/683021/"") in the way that humans are intelligent. They have been trained on more text than a human could ever read, but have different capabilities and make different mistakes. While their output often appears convincing and reliable, their behaviour is strongly influenced by the data they are trained on, so they can perpetuate harmful biases, fabricate information and make errors. You will be held accountable for these errors and biases if you include them in assessed work. 
Higher education should help you develop advanced knowledge which is creative and rigorous, not generic and unreliable. It is best to use your time at university to develop high-level skills that are going to help you throughout life – original thought, engaging writing, critical use of evidence, creative risk-taking and innovation.
 
Using the University’s own generative AI platform (ELM)
All University of Edinburgh students have free access to ELM, which offers you a secure gateway to a range of generative AI models. 
The university encourages you to use ELM over other platforms such as GPT, DeepSeek, Grok etc for the following reasons:
In ELM your data is secure – it will not be retained by third party services to train their models or for any other purpose.
It is free to use for all staff and students, providing the same access for all and saving you money.
ELM provides access to a range of language models including a locally-hosted instance of Llama. This has an optimized architecture that can achieve faster response times and reduced power consumption. You can also choose other models such as GPT within ELM if necessary for your task.
Your lecturers do not have access to your chat history in ELM for the purposes of 'checking' your work - like your email account, it is private to you.
You can access ELM and find out about training opportunities here.(""https://information-services.ed.ac.uk/computing/comms-and-collab/elm"")
 
Acknowledging your use of AI
If you choose to use generative AI for aspects of an assessment, it is important to be transparent about how you have done so. You should include a brief acknowledgment at the end of your piece of work, for example:
I used OpenAI o4 Mini via ELM to check grammar and spelling throughout my assignment. 
I also used the Create Image function in ChatGPT to generate the image on page 2.
Again – check the detail in your course guidance if you are unsure what is required, as there may be specific things your Course Organiser would like you to cover in your acknowledgment.
 
Citing your use of generative AI
If you use content generated by AI within your work, for example an AI-generated image or text from an AI chatbot, you will need to reference it. This means including an in-text citation or footnote in the body of your work, and a corresponding reference in your reference list. 
The Library’s guide to using generative AI gives very useful guidance on this.(""https://edinburgh-uk.libguides.com/gen-AI/guidance"") 
 
Environmental and social impact of generative AI
Many in our community are concerned about the negative impacts of generative AI in areas such as:
Energy and resource use(""https://news.mit.edu/2025/explained-generative-ai-environmental-impact-0117"")
Exploitative labour practices(""https://www.noemamag.com/the-exploited-labor-behind-artificial-intelligence/"")
Intellectual property(""https://academic.oup.com/policyandsociety/article/44/1/23/7606572"")
You may wish to read more about these via the links above. 
While there are ongoing efforts to reduce the environmental impact of the datacentres that make AI models work, it is clear that use of generative AI has a higher impact than, for example, a simple web search. If you are concerned about this, consider using the locally-hosted instance of Llama in ELM (see above). It is more efficient in terms of resource use, and provides a more transparent alternative to OpenAI, meaning that it is easier for the university to measure and manage its power consumption.
You might also try to limit use of generative AI to purposeful rather than casual use.
 
Links to other sources
Principles
Edinburgh Student Assembly principles on the use of generative AI(""https://www.studentsassemblyongenai.com/principles"")
Russell Group principles on generative AI use in education(""https://www.russellgroup.ac.uk/sites/default/files/2025-01/Russell%20Group%20principles%20on%20generative%20AI%20in%20education.pdf"")
 
Further guidance
Generative AI use for Postgraduate Research students(""https://information-services.ed.ac.uk/computing/communication-and-collaboration/elm/generative-ai-guidance-for-students/generative-ai"")
Library guide to using generative AI in academic work(""https://edinburgh-uk.libguides.com/gen-AI/guidance"")
 
Training
University of Edinburgh Digital Skills Programme(""https://information-services.ed.ac.uk/help-consultancy/is-skills/classroom-based-courses-and-webinars"")
 
Academic misconduct guidance
Further guidance on academic misconduct (including plagiarism) and how to avoid it(""https://registryservices.ed.ac.uk/academic-services/students/conduct/academic-misconduct/what-is-academic-misconduct"")
University of Edinburgh Academic Misconduct Procedures(""https://registryservices.ed.ac.uk/academic-services/students/conduct/academic-misconduct/academic-misconduct-procedure"")"
26,University of Leeds,26_leeds.pdf,https://generative-ai.leeds.ac.uk/wp-content/uploads/sites/134/2023/12/UoL-GenAI-guidance-for-taught-students.pdf,"Generative AI guidance  
for taught students  
 
 
 
 
 
 
Generative AI guidance for taught students  ................................ ...... 1 
Can I use Generative Artificial Intelligence at Leeds?  .......................  1 
Introduction to Generative AI for Taught Students  .............................  1 
How does Generative AI work?   ................................ ............................  4 
Key Strengths and Weaknesses of Generative AI  .............................  5 
Key Strengths  ................................ ................................ ...........................  5 
Key Weaknesses  ................................ ................................ .....................  6 
Use of Generative AI in assessments  ................................ ..................  8 
Acknowledging the use of and referencing Generative AI  ..............  12 
Generative AI Quick Checklist  ................................ .............................  13 
 
 
 
 
 
Guidance version: 1.1  
Last updated: April 2024
1 Generative AI guidance for taught students  
 
Can I use Generative Artificial Intelligence at Leeds?  
Welcome to the University of Leeds’ latest information and guidance on using 
Artificial Intelligence (AI) in your studies. The guidance is intended to ensure that our 
use of Generative AI across Leeds is effective, ethical and transparent.  
This guidance ha s been co -produced by University of Leeds academic staff, 
professional services staff and students from different disciplines. It is in line with the 
advice given at comparable universities, particularly UCL (from whom we have 
adopted this guidance with th anks).  
This guidance will be reviewed every six months while AI discourse and capabilities 
develop. We will notify you of any major changes to the guidance.  
Please check the Generative AI website  regularly to see the latest advice and get in 
touch at AI@leeds.ac.uk  if you h ave feedback or ideas for future advice we should 
include.  
Introduction to Generative AI for Taught Students  
This section introduces Generative AI (Gen AI) and highlights the basics of how it 
works, along with its strengths and weaknesses.  
Generative AI ha s the potential to transform education and learning 
and to develop new forms of creativity. At the same time, it is full of 
biases, inaccuracies, and other issues. We need to hedge our 
moments to explore its full potential while recognising its flaws and 
issues.  
Professor  Jeff Grabill, Deputy Vice -Chancellor: Student Education  
What is Generative AI (Gen AI)?  
Gen AI is an Artificial Intelligence (AI) technology that automatically generates 
content in response to written prompts. The generate d content includes texts, 
software code, images, videos and music.  
Gen AI is usually trained using data from webpages, social media conversations, 
survey data, private datasets and other online content. It generates its outputs by 
identifying and repeating  common patterns (for example, which words typically follow 
which words, or which pixels of images should come after which pixels). This is 
usually done by ingesting large datasets and statistically analysing the distribution of 
words or pixels or other el ements in the data.  This guidance is for all taught students at the University of Leeds. Guidance for 
Postgraduate Research students is being developed separately and will be published 
soon.  
2 There are many other types of AI applications, that do not involve Gen AI, that are 
having an impact on teaching and learning. These will be explored in more detail as 
the guidance further develops.  
Remember:  
• While Gen AI is often accur ate, even in complex conversations, it is not 
reliable and can make simple mistakes.  
• Gen AI can simulate intelligent conversation, but it doesn't possess true 
consciousness or human -like thinking.  
• Though Gen AI responses might seem insightful, it doesn't g enuinely 
understand or comprehend topics as humans do.  
This means that while many of us will be using Gen AI in creative ways in our work, 
we always need to verify that its outputs are accurate and appropriate for our needs.  
Text Gen AI  
In response to a human -written prompt, text Gen AI generates text that usually 
appears as if a human has written it.  
 
Despite appearances, text Gen AI does not understand either the prompt written by 
the human or the text that it generates. You may have encountered this if you have 
ever tried to have a conversation with a text Gen AI tool and seen it contradicting 
itself. You may  also have seen a text Gen AI tool choosing words that are not quite 
right for the context or intended meaning of the output. It is just providing the words 
that would statistically be most likely to appear in a response to the prompt you 
provided.  
Every t ime that we use a text Gen AI tool, we need to consider its output from a 
critical perspective.  
Examples of text Gen AI tools  
There are many tools that provide text Gen AI functionality. The following list provide 
examples of some of the most popular ones.  Please note that the University of 
Leeds is not endorsing any of the tools in this list.  
• Bard  (Google)  
• ChatGPT  (OpenAI)  
• Claude  (Anthropic)  
• Hugging Chat  (HuggingFace)  
• Llama  (Meta)  Yet, just like human -written texts, text Gen AI outputs can be superficial, inaccurate, 
untrustworthy and full of errors.  
3 Examples of other Gen AI tools built on top of Gen AI tools  
There are many tools that provide additional Gen AI functionality. The following list 
provides examples of some of the most popular ones. Please note tha t the 
University of Leeds is not endorsing any of the tools in this list.  
• ChatPDF  (summarises and answers questions about submitted PDF 
documents)  
• Elicit (aims to automate parts of researchers’ workflows, identifying  relevant 
papers and summarising key information)  
• WebChatGPT  (Googl e Chrome extension that gives ChatGPT Internet 
access, to enable more accurate and up -to-date conversations)  
• Microsoft has incorporated AI Chat into its Bing search engine and is 
implementing AI Chat across its Office portfolio with Copilot. You may have 
already seen this if you have used the Edge browser  on a University PC.  
Image, video, music Gen AI  
Like Text Gen AI, image, video or music Gen AI can generate outputs based on 
human -written prompts. Some can also respond to visual or audio prompts.  
Again, the appearance of image, video and music Gen AI outputs might appear 
novel. However, usually, they are only complex combinations of the millions of 
images, videos or music that they have ingested during their training.  
Gen AI uses earlier works in i ts outputs and this creates substantial challenges in 
copyright, intellectual property and the ownership of content. You may have heard of 
the 2023 Writers Guild of America (WGA) strike in Hollywood on this topic, or the 
issues with a song created by AI mi micking the work of Drake and The Weeknd, 
which highlight deep issues with ethics and ownership when it comes to AI 
generated works.  
Examples of image, video and music Gen AI tools  
There are many tools that provide image, video or music Gen AI functionalit y. The 
following list provide examples of some of the most popular ones. Please note that 
the University of Leeds is not endorsing any of the tools in this list.  
• DALL•E  (OpenAI’s image Gen AI tool)  
• DreamStudio  (Stable Diffusion’s image Gen AI tool)  
• Midjourney  (Image Gen AI tool)  
• Runway  (Video Gen AI tool)  
• Boomy  (Music Gen AI to ol) 
• Voicemod  (Music Gen AI tool).  
4 How does Generative AI work?   
Both text and image Gen AI are based on a set of AI techniques that have been 
available to researchers fo r several years and have been built one on top of another.  
Text Gen AI  
While it isn’t necessary to understand exactly what each of the terms below means 
and exactly how the technologies work, it is helpful to have a basic understanding of 
their definitions  and how they form a hierarchy of specificity. The following flow chart 
should provide a quick understanding of ChatGPT (and other text Gen AI) and that 
they are types of the following:  
 
Image 1 – a flow chart highlighting the hierarchy of technologies used for a tool like ChatGPT.  
Text description of image: ChatGPT is an example of a Generative Pre -trained 
Transformer (GPT), which is an advanced type of a large language model. A large 
language model uses deep learning and large datasets to understand, summarise, 
generate and predict new content. Large language models are a type of general 
purpose transformer. A transformer is an artificial neural network that learns context 
and meaning by tracking relationships in sequential data. An artificial neural network 
is a machine learning method that teaches computers to process data in ways 
inspired by the human brain. Machine learning is a type of artificial intelligence that 
uses statistical alg orithms to generalise and perform tasks without explicit 
instructions  

5 Key Strengths and Weaknesses of Generative AI  
To understand the strengths and weaknesses of Gen AI, let’s have a look at what’s 
involved in training it. The training process involves the  tool being provided with and 
processing huge amounts of data scraped from the internet and elsewhere. 
Processing this data involves identifying patterns, such as which words typically go 
together (eg “Happy” is often followed by “Birthday”). This leads to  several strengths 
and weaknesses, with the key ones described below.  
Key Strengths  
Diverse outputs  
Gen AI can produce diverse and seemingly original outputs. It can create content 
and outputs through capturing nuances in language, based on the patterns which 
may not have otherwise been seen before in the data they were trained on. This 
helps open different perspectives and can give ideas on how to explore topics from a 
varied set of viewpoints.  
Levelling the playing field  
Gen AI can process and interpret human language in a conversational style, allowing 
it to generate contextually relevant responses to user prompts. It can also 
reformulate text to simplify or summarise it, which can help people start to 
understand more complex ideas. In addition , Gen AI can process and generate text 
in multiple languages. If used appropriately, Gen AI can be a great leveller for those 
who do not speak English as their first language or may not have the same literacy 
or language skills as others.  
Organisational pr oductivity  
Gen AI can be fine -tuned for various tasks and domains, making them widely 
applicable (eg, chatbots, content generation and language translation). This can help 
boost organisational productivity, eg through answering questions in a human -like 
style, in reducing effort on tedious and monotonous tasks, in providing accessible 
summaries of complex topics, in doing automatic translations and transcriptions, etc.  
Personalisation  
Gen AI models can remember previous interactions, which results in more c oherent 
and relevant conversation experiences for users. You can also ask some models to 
remember the style in which you write, in which you want your data to be presented 
and even ask it to test your knowledge against any piece of content. Gen AI can 
gene rate responses quickly, allowing for rapid interactions and real -time applications.  
Industry applications  
It is anticipated that most industry and workplaces will be using a form of Generative 
AI in the future to enhance and optimise their work. As Gen AI integrates into our 
6 daily learning and work tools (such as Copilot and Microsoft Office, or the AI content 
generator in Grammarly, etc), it is important to develop your skills in using Gen AI 
effectively and ethically.  
Key Weaknesses  
Lack of trust and auth enticity  
Gen AI can generate information that appears factual but is often inaccurate. This is 
often called AI hallucinations. It is important to note that while Gen AI models appear 
to understand the content that they use and generate, they do not underst and it. The 
data that they use for training have lots of inaccuracies and biases in them already. 
In addition, Gen AI can be used to create fake news, misinformation and ‘deep fakes’ 
easily. This could lead users to have misplaced trust in the Gen AI outpu t. 
Copyright and ownership  
Gen AI output imitates or summarises existing content – mostly without the 
permission of the original content owners – but can give the appearance of creativity 
and originality. This generates challenges and issues of copyright, ownership, 
intellectual property and lack of authoritative legislation in this rapidly evolving area. 
It is important to keep this in mind when using Gen AI tools. You should not copy and 
paste any copyrighted text, or other sensitive or personal data, int o an AI tool for it to 
use, as this data could be added into the AI tool’s training dataset and could then be 
used illegally or unethically.  
Carbon footprint  
Training Gen AI requires huge amounts of power and indirectly generates huge 
amounts of carbon, wi th important consequences for climate change. For example, it 
is estimated that the training of GPT4 consumed between 51,772 and 62,318 
megawatt hours of electricity and generated between 1,035 and 14,994 metric tons 
of carbon dioxide emissions, depending on the global location of the training. As an 
example, a 3000 -mile roundtrip via air (such as London to Boston) emits 1 metric ton 
of carbon dioxide.  
Feedback loop  
The output of Gen AI is flooding the internet. This poses an interesting risk for future 
GPT models. These models themselves will be trained on online content that earlier 
GPT models have created (including all its biases and errors). This self -referential 
loop compounds the mistakes in data, might contaminate the training data and lead 
to the co ncept of model collapse. A model collapse occurs where the models quickly 
forget most of the original data that they learnt from.  
Ethical, Social and Human costs  
After the Gen AI model is trained, it is often checked and refined in a process known 
as Reinf orcement Learning from Human Feedback (RLHF). In RLHF, Gen AI 
7 responses are reviewed and validated by human reviewers. These human reviewers 
ensure that the Gen AI responses are appropriate, accurate and align with the 
intended purpose.  
In the development of ChatGPT, the RLHF reviewers mostly were workers in global 
south countries such as Kenya. Workers were paid less than $3 per hour to review 
the outputs of ChatGPT and identify any objectionable or toxic materials. This work 
has had a massive negative imp act on many of those who were involved, including 
issues of exploitation and trauma.  
Gen AI also tends to output standard answers that replicate the values and biases of 
the creators of the data used to train the models. This may constrain the 
development of plural opinions and further marginalise already marginalised voices.  
 
  It is important to reflect that Generative AI can help us achieve great things, but that it 
also comes at an ethical, social, environmental and human cost. Thus, it is i mportant to 
consider these factors in our approach and support ethical frameworks around use of 
generative and other forms of AI. It is also very important to always check if the content 
produced is accurate and not an AI hallucination.  
8 Use of Gen erative  AI in assessments  
The University of Leeds use a three -tiered traffic light system of Gen AI use in 
assessments. Staff and students should be aware of the categories and discuss in 
class whether an assignment falls wholly or partially within each.  
As a student, you should always make sure that the Academic Integrity principles  are 
followed in any work that you do, and when in doubt, always ask your tutor about 
appropriate use of Gen AI.  
Introduction  
As a general principle, you can use Gen AI to help you learn but cannot use AI to 
generate or falsify work. You may use Gen AI in ways that support your learning, 
enhance your ability to achieve your  Programme Learning Outcomes and prepare 
you to succeed in your future careers. Using Gen AI to falsify work or breach 
guidelines for an assessment will undermine all these benefits and damage your 
learning. This is explained further in the Academic Misconduct  procedure.  
Categories of use of Gen AI in Assessment  
There is a three -tier traffic light categorisation for using Gen AI in assessme nts: red, 
amber and green. This categorisation may be used by teaching staff to design and 
set assessments and for you to complete assessments in ways that will optimise – 
rather than damage – your learning. The three categories are not defined rigidly; 
rather they are a tool for ensuring that for each piece of assessment, staff and 
students have a shared understanding of whether generative AI tools can be used 
and, if they can, how, how much and where in the assessment process.  
Regardless of the category, you should always take a critical approach to the use of 
any output from a generative AI tool, as these tools can generate superficial, 
inaccurate and unhelpful outputs. Gen AI tools can create content that is not peer 
reviewed or academically rigorous, of ten without any academic sources 
underpinning that content. Therefore, you should always analyse and verify the 
information Gen AI tools provide, rather than accepting it at face value. As a 
reminder, please review the Strengths and Weaknesses section abov e to understand 
more on why this is vital for your success.  
  
9 RED category: AI tools cannot be used  
 
As an example, assessments under these categories may include demonstrating 
foundation level skills such as remembering, understanding, independently 
developing critical thinking skills and applying knowledge or demons trating 
fundamental skills that will be required throughout the programme.  
Such assessments are likely to be designed to support the development of 
knowledge and skills that you will require to be able to study successfully and 
effectively, including with the use of Gen AI tools in other contexts and in future 
assessments. There will be strong rationale for this category (for example, pedagogy, 
employability, etc) . Your lecturer or module materials should explain this, but you can 
also ask for clarification  on it.  
Students believed to have ignored the categorisation will undergo the standard 
Academic Misconduct procedure . 
In an assessment in  this category, you would still be permitted to use dictionaries, 
thesauri and spelling – and grammar -checking software, some of which are powered 
by AI, to help identify and correct spelling mistakes and grammatical errors. 
However, you should not use any  software to rewrite sentences or make substantive 
changes to your original text, as this would be against the rules of this category.  
We are currently working on what it means to provide reasonable adjustments while 
maintaining competence standards. If th e meantime, if you have any questions or 
comments, please get in touch with us using AI@leeds.ac.uk  
Red category examples  
Examples of assessments where Gen AI is not allowed could include:  
• In-person unseen examinations  
• Class tests  
• Some online tests  
• Vivas  
• Some laboratories and practicals  
• Discussion -based assessments  
• Where spoken and written language skills need to be assessed.  
  
RED CATEGORY  
Under this category, you must not use Gen AI tools. 
The purpose and format of the assessments makes it 
inappropriate or impractical for AI tools to be used.  
10 AMBER category: AI tools can be used in an assistive role  
 
Gen AI tools can be utilised to enhance and support the development of specific 
skills in specific ways, as specified by the tutor and required by the assessment . 
For instance, you might use Gen AI for tasks such as data analysis, pattern 
recognition, or generating insights.  
It is anticipated that your tutor will be able to provide support and guidance to you in 
the use of Gen AI to ensure equity of experience. In these situations, the use of Gen 
AI is not in itself a learning outcome. Ther e may still be parts of your assessment 
where use of Gen AI is inappropriate and this will be made clear to you in discussion 
with your tutor.  
 
Amber category examples  
Exampl es of where Gen AI might be used in an assistive category include:  
• drafting and structuring content  
• as a support tutor  
• supporting a particular process such as testing and debugging code or 
translating content  
• providing ideas or inspiration to help you over come a creative block.  
 
  
AMBER CATEGORY  
Under this category, you  are permitted to use AI tools 
in an assistive role as specified b y the module tutor 
and required b y the assessment . 
You should never provide any Gen AI tool sensitive or personal data in any prompt or 
content. For more informa tion, please read the key information on IT Security 
Considerations on the use of ChatGPT and AI LLM Engines . 
It is also important to note that your tutors are also learning how to best design 
assessments that allow the use Gen AI to enhance your learning and development. Thus, 
an open discussion on this topic is encouraged at an early st age. Support guidance and 
case studies are also being created to support your tutors.  
11 GREEN category: AI has an integral role and should be used as part of 
the assessment  
 
In these assessments, you will demonstrate your ability to use Gen AI tools 
effectively and critically to tackle complex problems, make informed judgments and 
generate creative solutions. Here, the use of Gen AI and crit ical appraisal of its 
output will explicitly form part of the task and learning outcomes. The assessment 
will provide an opportunity to demonstrate effective and responsible use of Gen AI. 
The tutor should support and guide you in the use of Gen AI to ensu re equity of 
experience.  
Green category examples  
Examples of where Gen AI tools could be used as an integral part of the assessment 
include:  
• drafting and structuring content  
• generating ideas  
• comparing content (AI generated and human generated)  
• creating con tent in particular styles  
• producing summaries  
• analysing content  
• reframing content  
• researching and seeking answers  
• creating artwork (images, audio and videos)  
• playing a supportive role and engaging in a conversational discussion  
• developing code  
• translating content  
• generating initial content to be critiqued by students.  
Note that the green category only applies to assessments where using Gen AI is 
explicitly part of the task. Assessments that do not specify this are not in the green 
category. Please check with your tutor if you are at all unsure. You can assume that 
unless the assessment is specified as one where Gen AI can explicitly be used, it will 
be in the red or amber category.  
 
  
GREEN CATEGORY  
Under this category, you can use Gen AI as a primary 
tool and it should be used as part of the assessmen t. 
When using Gen AI tools to support your work, you should always s ave copies of the 
outputs that the Gen AI tool has produced for you. You may be asked to provide this 
information as part of your assessment or in any academic misconduct process.  
12 Acknowledging the use of and referencing Gen erative  AI 
Gen AI is evolving rapidly and there is not yet consensus on how to acknowledge 
and reference it. In all cases, you are required to acknowledge truthfully what 
elements of any assignment are your own work or ideas and what has come from 
other sources – including Gen  AI. You should make clear in your assignment where 
you have used Gen AI (eg for support with writing style but not for content).  
The use of Gen AI must  be acknowledged in an ‘Acknowledgements’ section of any 
piece of academic work where it has been used a s a functional tool to assist in the 
process of creating academic work. If it is suspected that you have used a Gen AI 
tool to produce part of your work, but you have not acknowledged this use, this could 
be investigated under the Academic Misconduct proce dure.  
The minimum requirement to include in acknowledgement:  
• Name and version of the generative AI system used eg ChatGPT -4.0 
• Publisher (company that made the AI system) eg OpenAI  
• URL of the AI system  
• Brief description (single sentence) of context in which  the tool was used.  
For example:  
“I acknowledge the use of ChatGPT -3.5 (Open AI, https://chat.openai.com/ ) to 
summarise my initial notes and to proofread my final draft.”  
Further requirements may be stipulated by a department, academic programme, or 
individual teaching staff, or for a particular assignment, and will be made clear when 
an assignment is set. Details of such requirements will usually be provided in the 
assess ment brief.  
 
  We are currently working on developing the referencing guidance further in 
collaboration with the sector and encourage you to keep checking the Library’s 
Referencing Pages  and the official guide for your School’s referencing style for more 
information.  
13 Generative  AI Quick Checklist  
If you are deciding on whether and how to use Gen AI tools, you may find the quick 
checklist below helpful.  
 I have checked the assessment brief or have spoken to my tutor and can 
confirm that use of Gen AI is not prohibited for my assessment type.  
 I have reviewed the Academic Integrity principles to help me avoid 
unintentional plagiarism.  
 I have understood the risks an d limitations of using Gen AI, including a 
recognition of issues of bias, sensitivity, accuracy, appropriate content and 
ethical issues.  
 I have checked and critically reviewed any quotations, citations, or outputs 
that the Gen AI tool has generated.  
 I have  not submitted any Personally Identifiable Information (PII) to a Gen AI 
tool.  
 I have ensured that no part of my assessment copies or paraphrases Gen AI 
outputs with out acknowledgement.  
 I have ensured that my assignment / research remains my own work.  
 I have appropriately referenced the use of Gen AI tools in my work.  
 I have saved copies of Gen AI outputs used in preparing my assessment. 
These copies may be asked to be provided as an appendix to my assessment 
or as part of any misconduct process.  
 I have so ught help from my tutors or the Library’s Learning Development team 
when I was unsure about use of Gen AI or needed further guidance.  
Please note that this checklist is not exhaustive and provides a framework for 
ensuring good academic practice is followed  when using Gen AI tools."
27,University of Manchester,27_manchester.rtf,https://elearning.bmh.manchester.ac.uk/ai-guidance-for-learners/,"The University of Manchester supports students to use AI responsibly for learning.
Generative AI (GenAI) is transforming the way we learn, work, and create. As university students, understanding how to use GenAI effectively is crucial; it can help you brainstorm ideas, refine writing, analyse data, and solve complex problems. Many industries are integrating AI into their workflows, meaning that graduates with AI literacy will have a competitive edge in the job market. Employers are looking for individuals who can critically assess AI-generated content, use AI tools ethically, and apply them to real-world challenges.
By developing AI literacy, you will not only enhance your academic work but also prepare yourself for a workforce where AI is an essential tool rather than a replacement for human skills.
The following sections consider practical ways you can begin to use GenAI responsibly…

Our University’s position is that when used appropriately AI tools have the potential to enhance teaching and learning, and can support inclusivity and accessibility. Output from AI systems must be treated in the same manner by staff and students as work created by another person or persons, i.e. used critically and with permitted license, and cited and acknowledged appropriately.
Practical Ways to Use AI Now
To use GenAI responsibly…
Treat it as a tool to support your study; it should not replace your own thinking.
Cross check any AI-generated content to verify accuracy and credibility.
Follow our University guidelines on AI use in coursework.
Be transparent about your use of AI when required.
Remember that GenAI comes with risks. It can produce inaccurate or biased information, and relying on it too heavily may hinder your own critical thinking and creativity. Submitting work which utilised GenAI tools without proper citation can lead to plagiarism and academic misconduct concerns.
If you directly include AI-generated text or images in your assignments, you must cite the AI tool.
For example, using the Harvard Manchester referencing style, cite AI-generated content following the ‘Software’ format on the Library’s Harvard referencing guide.
There are some examples in the “Referencing Examples” tab on this page.

Use AI Responsibly
Privacy Issues – Be aware that using AI can involve handing over personal information. Ensure you don’t include personal or private information, and don’t enter personal or confidential information about others (including patient data).
Generative AI isn’t perfect – it can occasionally misunderstand instructions or give subtly or even wildly incorrect answers. Always double-check its information independently, and never share copyrighted materials or personal details like your name or institution specifics with AI tools.
If your assignment guidelines explicitly forbid AI use, avoid it completely. If they encourage or allow it, then clearly state how you used AI in your work.
Getting the Most from AI
Stay focused when interacting with AI. Clearly define what you need – like summarising complex concepts, practising specific skills, or experimenting with coding and creative visuals. AI is most effective and most valuable when it complements your own thinking rather than replacing it entirely.
Regularly using AI in your studies will not only save you time but also build essential skills for your future career. Employers predict AI skills will be among the most valuable by 2030.
Looking Ahead
AI in education is continually evolving. Universities across the UK are actively shaping their approaches and carefully considering how students like you can best benefit from AI tools.  There are documents further down this page that can help keep you up to date with the latest advice from official channels; we’ll endeavour to keep the collection of those documents up to date, so please check back from time to time.
Embrace AI as a helpful companion – use it responsibly, reference it properly, and you’ll be setting yourself up for success both now and in your future career.

Please be mindful of the environment
Students should be mindful that using GenAI tools has an environmental impact due to the significant energy consumption required. Each prompt may seem small, but collectively they contribute to increased carbon emissions. To reduce this impact, you can plan questions in advance and combine multiple queries into one well-thought-out prompt. This not only helps reduce the energy footprint but also encourages clearer thinking and more effective learning.

Researching for Your Studies  Can you think of a few different ways you might use AI to research a topic?
Engage in dialogue / Brainstorm or mind map / Gain alternative insight / Develop new questions / Consolidate understanding.

Using Prompts to Aid Learning  How should you use prompts with AI?
When researching a topic, don’t just put an essay title or course materials in to Gen AI. Just getting the answer is NOT LEARNING. Think about the gaps in your understanding of a subject. What do you want to know? Be specific with your prompt. Don’t breach copyright laws. – lecture transcripts, slides, library resources, etc are for your personal study. The University owns the copyright of all learning materials produced.

Simplifying Complex Concepts  Explain to a 1st year Biological Sciences university student how haemoglobin binds and releases oxygen. Use a maximum of 50 words.
Haemoglobin binds oxygen in the lungs where oxygen levels are high, thanks to its iron-containing heme groups. In tissues with low oxygen, haemoglobin releases oxygen due to decreased affinity, aided by carbon dioxide and acidity. This reversible binding ensures oxygen transport and delivery to cells efficiently.

Simplifying Complex Concepts  Explain to a final-year Biological Sciences university student how haemoglobin binds and releases oxygen. Use a maximum of 50 words.
Haemoglobin binds oxygen via cooperative binding; oxygen binding to one heme group increases haemoglobin’s affinity for oxygen. In tissues, lower pH (Bohr effect), higher CO₂, and temperature reduce affinity, promoting oxygen release. This reversible conformational change ensures efficient oxygen loading in lungs and unloading in tissues.

Verify Responses  How would you check responses are valid and accurate?
Cross-check with course materials, recommended reading and established trusted sources. Always use books, credible web resources, peer-reviewed publications, library resources.

Always Check Your Understanding  Can you think of a few ways you can check your understanding?
Test yourself / Explain verbally to your friends / Draw mind maps / NEVER just accept what Gen AI produces – always cross-check and verify your own understanding / NEVER rely on a single source

Reading  How can you use Gen AI for reading?
Think about ways you can use Gen AI to develop your critical reading skills for learning. Gen AI can be useful as a starting point for browsing and skimming. Go on to read original sources, read widely, and read your recommended unit texts. Develop specific prompts first; what do you want to know? Be focused – conclusion, methods, results….? Many platforms now create summaries but remember to verify, crosscheck and question. ALWAYS write your own summary in your own words.

Writing: Make Your Own Notes  Can you think of three ways of making study notes effectively?
Take notes “Actively” using your own words – this is learning! Avoid cut and paste. Gen AI can help summarise articles, webpages, etc – to get started and understand difficult concepts/mechanisms etc. Collate and cross-reference different resources.

Writing: Make Your Own Notes  Can you think of a few ways you can use Gen AI to help you to develop your writing skills further?
Develop ideas further with specific prompts; ask focused questions. Create structure and templates to help you develop your own writing. Challenge and question the responses. Always write in your own words. Be prepared to defend your writing – never pass GenAI writing off as your own – that’s plagiarism.

What Do You Think the 3 Key Messages Are?  What do YOU think?
1. Use Gen AI critically to aid your learning and help you become a better researcher, reader and writer. 2. Learn through thinking deeply, regardless of the source, crosscheck sources, discuss and apply knowledge and skills. 3. Don’t use Gen AI to bypass your brain. Learning is sometimes difficult"
28,Cardiff University,28_cardiff.rtf,https://sites.cardiff.ac.uk/ilrb/using-gen-ai-to-support-your-literature-searching/,"Using Gen AI to support your literature searching
Alexis Constantinou(""https://sites.cardiff.ac.uk/ilrb/author/sisac14/"")
28 November 2024(""https://sites.cardiff.ac.uk/ilrb/2024/11/28/"")

Welcome to the Library’s guide to using Generative Artificial Intelligence (Gen AI) to support your literature searching. This resource aims to help you understand the benefits and limitations of using generative AI for finding literature to reference in your academic work.
Before you use any AI tool to support your assessed work, please check the guidance from your module or course and read the University’s guidance for students on using artificial intelligence in your learning(""https://intranet.cardiff.ac.uk/students/study/exams-and-assessment/academic-integrity/artificial-intelligence-ai-in-education"").
Generative AI tools such as Microsoft Copilot can be helpful when you need to identify a topic to research and/or define a research question.
Perhaps you have an area of interest you’d like to research but need to refine into a research question or statement. Or maybe you want to get to know a little more about a topic, to give you ideas for themes or topics to research more deeply in the published literature.
You can generate prompts which will direct the Gen AI tool to help you with these tasks."
29,University of Leicester,29_Leicester.pdf,https://le.ac.uk/-/media/uol/docs/policies/quality/ai-policy.pdf,"1 
Policy on Generative Artificial Intelligence in Learning, 
Teaching and Assessment  
Document control table  
1. Prepared by (lead responsibility)  
 R Blackburn and A Petersen  
2. Approved by        
 Education Committee  
 
Policy development steps  
3. Legal implications of this policy area.  
 Supports compliance with OFS B Conditions of 
Registration  
4. Consultation for this policy  
 Colleges, Senior Education Leadership Team, 
Curriculum and Quality Committee, Education 
Services , Students, Campus Trade Unions  
5. Related procedures/guidance  
 Guidance published on Sharepoint  
6. Version history   
 V1.0  
7. Monitoring  
 Curriculum and Quality Sub -Group  
8. Date of issue  
 tbc 
9. Review date  
 January 2026  
 
1. Introduction  
1.1 The University of Leicester recognises that the opportunities afforded by the development of 
Generative Artificial Intelligence (AI) tools such as, but not limited to,  Microsoft Co -pilot,  
ChatGPT and Gemini will profoundly impact the way in which our programmes are developed, 
delivered and assessed.  
1.2 The University is committed to the ethical and responsible use of AI, and to preparing our staff 
and students to engage effectively with the r apidly developing role of AI in Higher Education 
and the wider world.  
Policy on  Generative  Artificial Intelligence in Learning, Teaching and Assessment  
2 1.3 This policy provides a university -level framework, for staff and students for how and where it 
is appropriate to utilise AI for learning, teaching and assessment activities.  
2. Scope  
2.1 This p olicy applies to all award bearing programmes at the University of Leicester at all levels 
(undergraduate and taught postgraduate) and modes of study (full time and part time, 
campus based and distance learning). It applies to all modules which award credi t of the 
University of Leicester, including those delivered through partnership arrangements.   
2.2 This policy  also applies to taught modules studied within research degrees  such as PhD or a 
Professional Doctorate. The research components of these degrees are governed by the 
Research Code of Conduct.  
2.3 This policy also applies to all members of staff of the University responsible for designing or 
delivering teaching or assessment. This includes members of staff directly employed by the 
University, honorary staff and staff who may be employed through Unitemps.  
2.4 This policy does not apply to staff research , which  is governed by the requirements of the 
research Code of Conduct.  
2.5 This Policy works alongside the Senate Regulations governing Student Conduct, which include  
the University’s requirements regarding academic misconduct such as plagiarism or the use of 
AI generated content where not permitted. These regulations apply to all students of the 
University, at all levels.  
3. Definitions  
3.1. Generative Artificial Intelligence is defined as a form of AI that utilises machine learning 
models to perform tasks including (but not limited to) the creation of new content, such as 
images, text, video,  translations,  code or audio based on patterns and structures learned from  
large amounts of existing data, and in response to user -provided prompts.  
3.2. The University recognises AI underpins many core digital resources such as search engines , 
spelling checkers  or technology supporting disabled students  to perform tasks  they might 
otherwise find difficult . These are defined as Assistive Technologies , and include tools such as 
(but not limited to) Grammarly  and Quillbot.   This policy recognises that it may be 
appropriate for different forms of assistive technology to be used in different disciplinary 
contexts , depending on the nature of the support that they provide .  
3.3. Section s 4 and 9  below reference where elements of Assistive Technology may be considered 
Generative AI, and should be treated in line with the wider requirements o f this Policy.  
4. University expectations on AI in learning, teaching and assessment  
4.1 The University believes that a balanced approach to the use of AI in learning, teaching and 
assessment is essential.  It does not seek to outright forbid its use, but rather provide a 
supportive and common -sense approach to outlining safe , responsible and appropriate use . 
Policy on  Generative  Artificial Intelligence in Learning, Teaching and Assessment  
3 4.2 The University recognises that different disciplines will have different views of the impact of  AI 
on their  field. To this end, this policy provides a robust yet flexible framework that makes 
allowances for discipline -specific consideratio ns, allowing staff to tailor their teaching and use 
of generative AI to be consistent with their views and established academic practices . 
4.3 AI can be both transformative and disruptive and both staff and students must consider this in 
their engagement with AI. Typical uses of AI include (but are not limited to):  
- Collating , summarising , and translating  information from a wide range of internet 
sources  or uploaded material ; 
- Assisting with drafting ideas, planning or structuring assessments;  
- Creating quizzes and flashcards for the purposes of study or revision;  
- Helping to improve spelling, punctuation, grammar and writing skills;  
- Performing calculations, creating and optimising code;  
- Performing/assisting with data analysis, within the principles of ethics and data 
protection set out in this policy;  
- Providing case studies for consideration and critique ; 
- Simulating conversations and role -playing to enhance practical skills;  
- Creating visual, audio or video content for educational purposes.  
4.4 However, G enerative AI tools cannot yet  always  be trusted to be factually accurate or up to 
date. Such tools  are limited in their critical  thinking or  insight,  often lack access to the  wider 
context and can raise ethical or equalities concerns depending on the data  that they have 
been trained upon.  
4.5 An overreliance on Generative AI can negatively impact a student’s learning as this can reduce 
engagement with the criticality and reflection that is essential for meaningful learning. 
Students who rely on AI will not dev elop their own critical thinking, evaluation or wider 
academic and professional skills , which are essential parts of university education and future 
employability.  It is essential that students continue to engage with existing academic skills 
development p rovision as well as  learning to engage critically with Generative AI.  
4.6 Programmes  of study  at the University of Leicester will have due regard to the benefits and 
risks of Generative AI within the framework presented by this policy, the University’s Senate 
Regulations regarding Academic Misconduct, and the specific disciplinary requirements of 
each subject area, including any set by Professional Bodies.  
4.7 Assistive Technology may or may not contain Generative AI features. The use of Assistive 
Technology may be  specific to individual disciplines or , in specific cases , to individual students 
depending on their individual reasonable adjustments. Schools should determine whether the 
use of non Generative AI based assistive technology is appropriate within their dis cipline  in 
general.  The specific use of any form of assistive technology as a reasonable adjustment for 
individual students will be considered by the AccessAbility Centre.  
Policy on  Generative  Artificial Intelligence in Learning, Teaching and Assessment  
4 4.8 Unless specifically mandated within individual reasonable adjustments, Generative AI features 
embedded within  Assistive Technologies are considered  to be  Generative AI and therefore  
covered by th e requirements of this  policy, specifically the traffic light  categorisation under 
section 9 below.  
5 Principles of the Policy on AI in Learning, Teaching and Assessment  
5.1 Students at the University of Leicester can expect to be taught and assessed by trained, 
human experts in their chosen academic discipline rather tha n AI tools. Under the following 
policy AI will not usually have  a role in generating marks and feedback . However , where the 
use of AI to generate  marks and feedback  provides a clear benefit, staff may request 
exemption from this point. Where AI has been us ed, the marks and feedback  for each student 
will be reviewed by the relevant expert member of staff.   
5.2 Staff and students will receive the support that they need to be confident in the ethical, 
responsible and effective use of AI in learning, teaching and assessment.  
5.3 There should be clear expectations set for students and effective communication as to 
whether Generative AI or Assistive Technology can or cannot be used for individual 
assessments. Where it is allowed, clear guidance should be in place on how it should be used.  
5.4 The University will ensure that academic rigour and standards are upheld throughout the 
assessment and feedback process.  
5.5 The University will work with relevant Professional, Statutory and Regulatory Bodies (PSRBs) 
to ensure that their requirements with respect to the use of Generative AI or Assistive 
Technology  in learning, teaching and assessments are met.  
5.6 The opportunities  and challenges presented by AI will vary between disciplines and academic 
staff should be empowered to design and amend learning resources appropriately within the 
overall framework of this policy.  
5.7 Academic integrity is at the heart of higher education.  The use of Generative AI and/or 
Assistive Technology  does not equate automatically  to academic misconduct. Assessments will 
clearly articulate where the use of Generative AI and/or Assistive Tools  is or is not permitted. 
Use of  Generative  AI and/or Assistive Tools  where not permitted  (Red Category) or to 
generate content for submission where not permitted (Amber Category)  will be considered a 
breach of academic integrity and sanctions under Senate Regulation 11 may be applied.  
5.8 Where academic misconduct is proven this may indicate a student in need of additional 
support, and Schools should be ready to signpost to relevant support services.   
5.9 Generative AI has an increasingly important role in researc h and industry. The University will 
ensure that its students are cognisant of the use of such tools through evolving curricula and 
authentic assessment strategies.  
6 Responsibilities  
6.1 Heads of School are ultimately responsible for the secure operation of the assessment process 
within their School.  Within the context of this policy, Heads of School are responsible for 
Policy on  Generative  Artificial Intelligence in Learning, Teaching and Assessment  
5 ensuring that the requirements of the policy are communicated to all members of the School 
and that there are appropriate processes in place for  their implementation.  
6.2 Directors of Education working with Programme Directors and other educational leadership 
roles as appropriate are responsible for managing the implementation of this policy for all 
programmes within the school. This includes:  
- ensurin g that all new programme design and existing programme review mechanisms 
take due account of the principles set out in the policy;  
- ensuring that all programmes feature dedicated AI training for students  addressing both 
academic integrity , environmental and  ethical matters,  and also the wider disciplinary 
context ; 
- ensuring that the School Education Committee and other relevant governance bodies 
have clear oversight of the discipline specific approaches to the opportunities and 
challenges presented by AI;  
- ensuring that relevant staff are aware and make appropriate use of resources available 
to support them in working with AI in learning, teaching and assessment;  
- ensuring a coherent and consistent approach to assessment.  
6.3 Module Convenors, with the support/overs ight of the Director of Education, are responsible 
for reviewing learning, teaching and assessment methods on their modules to ensure that 
they meet the requirements set out in this policy and that they are clearly communicated to 
students. Module Convenor s are responsible for ensuring that amendments to their modules 
through the usual process of review and curriculum planning consider the requirements of 
this policy. Module Convenors must ensure that all assessments are clearly designated  with 
the relevant  AI category from section 9 below and provide relevant guidelines to students on 
the appropriate use of AI within the module.  
6.4 Students are responsible for engaging with their programmes to learn about the appropriate 
and ethical use of AI within their own discipline. Students are responsible for ensuring that 
they observe published requirements regarding the use of Generative AI in learning and 
assessments and complying with any rubrics associated with individual assessments or 
overarching professional requ irements.  
6.5 The School Education Committee is responsible for oversight of learning, teaching and 
assessment methods across the programmes within the school. This includes approving the 
local approach to AI in learning, teaching and assessment and specifical ly approving where 
individual assessments or forms of assessment may or may not utilise Generative AI and/or 
Assistive Tools . School Education Committees should ensure that a list of the AI status of all 
assessments is maintained.  
6.6 School Academic Conduct  Officers are responsible for investigating potential cases of 
inappropriate use of AI in line with the relevant assessment rubric and the processes set out in 
Senate Regulation 11.  
Policy on  Generative  Artificial Intelligence in Learning, Teaching and Assessment  
6 6.7 The Student Conduct and Complaints Team is responsible for providing procedu ral advice and 
guidance to School Academic Conduct  Officers in implementing the requirements of Senate 
Regulation 11 regarding academic misconduct which incorporates the inappropriate use of AI.  
The Student Conduct and Complaints Team is also responsible for managing the process of 
student appeals against the decisions of School Academic Conduct Officers.  
6.8 Education Services is responsible for the provision of advice and guidance to academic schools 
to support the development and delivery of programmes to m eet the aims of this policy.  
7 Data Protection  
7.1 Use of Generative AI in any educational activity should take due account of data protection 
(GDPR) considerations . 
7.2 Staff and students must not use Generative AI for any purpose that would result in personal 
data being collected, stored, accessed, and shared without the explicit consent of the people 
whose data is being processed.  This includes data generated by others.  
7.3 Staff are not permitted to upload student  authored  assessment to AI tools without explicit written 
University approval. Where approval is given, student work may only be uploaded, to University 
approved AI tools.  
7.4 Students may  normally  upload their own work to AI tools for the purposes of feedback , 
subject to the limitations in 9.11 rega rding the generation of content for assessment . Care 
must be taken to ensure that students only upload their own work and observe the 
requirements set out in 7.2 above in relation to any data involving others , or data that is not 
of their own collection  without consent .  
7.5 Staff or students will not use AI detection tools, other than those that are approved by the 
University, to check for AI generated content.  Where detection tools are exceptionally used, this 
will be communicated to students.  
8 Learning and Te aching  
8.1 Whilst it is a requirement for each programme to have an assessment that uses Generative AI, 
individual a cademic staff are free to  choose whether to  use appropriate AI tools within their 
teaching in line with the framework in this policy. Where AI is used, academic staff are 
responsible for preparing any tools the y wish to use, undertaking appropriate tests for 
content and considering their output within t he context of the learning aims for the session(s) 
or module . Where there is a concern that a GenAI tool may be unpredictable despite testing a 
disclaimer or, where appropriate, content warning  may be provided.  
8.2 All programmes should introduce students to t he various opportunities and issues associated 
with the role of AI in higher education (and research) at an early stage. This should include at 
the point of induction and, for programmes with multiple levels, this message should be re -
iterated through re -induction/welcome -back events.  
8.3 Initial induction processes should, as a minimum, include:  
Policy on  Generative  Artificial Intelligence in Learning, Teaching and Assessment  
7 - general expectations about the use of  Generative or Assistive  AI in assessment, 
including where and how students are told whether AI is allowed/prohibited for specific  
assessment types;  
- the support available in other areas of the University to avoid academic misconduct, 
such as the Centre for Academic Achievement;  
- the potential sanctions available under Senate Regulation 11 where a student is found 
to have breached regu lations about academic integrity.  
8.4 Training  for students  on the appropriate use of Generative AI should be included within the 
standard Academic Integrity training delivered to students . The Centre for Academic 
Achievement provides tutorials for this purpos e, and Academic Integrity training should 
include  references to the ethical considerations within AI outputs, the environmental impact 
and the need to  engage critically with the output of Generative AI.  
8.5 All programmes are already required to include acade mic integrity training within a module in 
the first semester of study. This training  must include specific reference to AI, and should 
expand upon the information provided at induction by addressing:  
- Acknowledgement of ideas and the importance of evidence -based statements . 
- Ethical considerations, within the context of the discipline . 
- Any legal and copyright implications which may be relevant within the context of the 
discipline . 
8.6 Re-induction/welcome -back processes should clearly remind students of the Unive rsity’s 
policy on AI and should also consider any additional content appropriate to the level of study. 
This could include addressing any new forms of assessment that students may encounter in 
the next year or any new ways in which students may be required  to engage with  Generative 
or Assistive  AI in their learning.  
8.7 Student handbooks will include information for students on all the above considerations.  
8.8 The Centre for Academic Achievement offers support to students seeking to develop their 
skills and learn more about the appropriate use of AI.  
8.9 Where a student is required to engage with Generative AI through  the learning and teaching 
for a module, for example within a teaching session or formative exercising exploring the 
process of giving prompts , modu le convenors must ensure that the Generative AI tools 
required to complete the tasks are freely available to all students.  
9 Assessment  
9.1 Generative AI can be an important tool to support the process of assessment. Schools will 
make clear to students what, if any, role generative AI can play for each assessment it 
conducts.  
9.2 The University will provide written advice and guidance to staff for the purpose of designing 
assessments.  Staff will also have access to  a range of  training workshops  and supporting 
Policy on  Generative  Artificial Intelligence in Learning, Teaching and Assessment  
8 resources  offered at University level. Where required, School level training and support can be 
provided by Education Services.  
9.3 When designing assessments teaching staff should consider the following principles:  
- The ultimate responsibility for ensuring the  academic standards and reliability of the 
assessment rests with the academic staff of the University .  
- Generative AI can be useful to assist development of assessment tools, but the final 
assessment that is set to students must be reviewed and validated b y appropriate 
academic staff.   
- All assessments must fall into one of the three categories set out below, and the 
category clearly published to students.  
- All assessments must be designed in line with the University’s Assessment Strategy.  
9.4 The University has  identified three broad categories of assessment for the purposes of 
determining whether  students may use Generative  AI in the process of completing the 
assessment . Students will be informed which assessments fall into which categories.  
In order to support  students s chools  should  operate a consistent approach to the 
categorisation of assessment  types. Similar assessment types should not be in different 
categories for different modules.   
9.5 To support students to become knowledgeable, effective, and ethical use rs of AI, from 
2025/26 there should be at least one assessment on every undergraduate programme where 
students are required to use Generative AI as part of an assessment. This assignment could 
require students to use AI to produce a submission  (Green)  or could require students to 
critique AI -generated content  provided to them (Amber) .  Where possible, this should be early 
in the programme.  
Red Category: Generative AI m ust not be used  in assessment  
9.6 Generative AI will not be permitted in certain forms of asse ssment . This may relate to the 
pedagogic or professional requirements of the assessment, or to the requirements of 
accrediting bodies.  
9.7 Generative AI and , unless required for an individual student’s reasonable adjustment, 
Assistive Technology, is not permit ted to be used in any capacity for Red category 
assessments.  
9.8 Red category assessments will be invigilated assessments , which will typically be on -campus 
but may include activities such as vivas/presentations/interviews  conducted remotely via MS  
Teams  or other distance learning assessments  where the assessor can clearly observe the 
student(s).  
9.9 Campus -based asse ssments, notably examinations , will be considered by default in the red 
category, unless indicated otherwise.  
Amber Category: Generative AI may support  assessment  but not generate content  
Policy on  Generative  Artificial Intelligence in Learning, Teaching and Assessment  
9 9.10 Staff must set clear expectations and guidance for students in terms of the acceptable 
contribution that Generative or Assistive AI can have for each assignment/type of assignment, 
and the balance of this contribution against that of the student’s creative contribution.  
9.11 Within the Amber Category students may use Generative AI to support the development  and 
review  of an assessment submission , but not to create the text/media of the actual 
submission itself .   
9.12 AI may be used to conduct preparatory activities  ahead of the writing and submission of the 
assessment  in ways set out in the module guidance.  Certain AI tools may be prohibited for 
Amber assessments in individual modules depending on the learning outco mes for the 
module.  AI may not be used to generate text  or media  that is included within the assessment 
submission itself.  
9.13 Staff should consider and where appropriate clearly signpost particular AI tools relevant to 
their discipline  which may be appropriate for students to use in support of developing their 
submission.  
9.14 Schools may determine whether assistive technology may be used for amber assessments 
depending on the context of the discipline  and the intended learning outcomes and 
assessment cri teria of the assessments in question.  
9.15 Unless specifically permitted as a result of individual reasonable adjustments, Generative AI 
features of Assistive Technologie s are considered Generative AI for the purposes of this policy.  
9.11 – 9.14 apply to these features with respect to amber assessments.  
Green Category: Generative AI is a permitted  to generate content for assessment  
9.16 In green assessments  students are permitted to use AI to generate content for an assessment, 
within the framework set out in the re levant assessment brief.  
9.17 In assignments where students are using Generative AI to create text/media for their 
submission, they should be advised of any need to  cite/report  their use of Generative AI  
and/or Assistive Tools  in line with the University’s refe rencing guidelines .  
Communication with Students  
9.18 Clear communication with students is critical to developing their assessment literacy regarding 
the role of Generative AI. In addition to the induction processes set out in section 8 above, 
Schools should ensure that students are provided with clear inform ation on the categorisation 
of AI use for individual assessments. This could be set out in different ways  by each school  in 
question but could include one or more of the following:  
- in the relevant module descriptor or site on Blackboard;  
- in a document set ting out the role of AI by assessment type (for example all open book 
exams within the programme, level or school);  
- in a published assessment map for students;  
- in individual or collective assessment rubrics;  
Policy on  Generative  Artificial Intelligence in Learning, Teaching and Assessment  
10 - at the top of the assessment brief/problem set a nd/or as a part of the assessment's 
instructions.  
For any assessment where AI use is permitted or required  such as in the amber and green 
categories , schools may wish to provide  students with a declaration document to be included 
with the completed submiss ion.  This declaration may  request that , in addition to the normal 
citation of AI use, that students provide extra information such as how Generative  or Assistive 
AI tools used and/ or the prompts given.  
Marking and Feedback  
9.19 The marking and moderation proce ss for all assessments will ultimately be owned by the 
appropriate module convenor, who is responsible for the academic standard of assessment, 
marking and feedback on the module. As standard , no marking may be undertaken using AI .  
Assessments where marki ng can be automated without the active application of academic 
judgement  (for example multiple choice tests)  are excluded from this rule , although it is a 
requirement of the University Marking and Moderation guidelines that the marking output of 
such syste ms is checked for accuracy .   
9.20 Where a school wishes to request that the marking for an assessment could be supported by 
AI, this will be reviewed  and subject to approval  by the University. In all cases, any Generative 
AI supported marking must be subject to review and  validation  by members of academic staff.  
9.21 AI will not be used to generate  feedback to students on assessment as standard. Where a 
school wishes to request to use AI to support this activity , this will be reviewed and subject to 
approva l by the University. In all cases, any GenAI supported feedback  must be subject to 
review and confirmation by members of academic staff.  Staff are responsible for ensuring that 
feedback generated by any approved University tool is reviewed to ensure that i t is accurate 
and appropriate in content and tone.  
9.22 Approved University Generative AI tools may be used to inform the development of an 
assessment rubric but academic staff will not use AI to fully create these rubrics. Published 
assessment rubrics, and the feedback they generate, must be instructor -led. 
9.23 Students may elect to use AI to provide developmental  feedback on their work in the drafting 
stage, but it must be noted that this can only ever be advisory and is not a substitute for 
formal academic fee dback. Feedback obtained locally via AI that differs from that received 
from staff will not be accepted as grounds for appeal, and challenges to academic judgement 
arising from AI feedback will not be accepted, in line with Senate Regulation 10.  
10 Academic I ntegrity and Student Conduct  
10.1 Failure by any student registered on a University of Leicester programme or module to abide 
by the requirements of this policy may represent a breach of the University’s regulations and 
Student Code of Conduct and consequently be  considered under student conduct processes 
set out in Senate Regulation 11.  
10.2 Guidance will be provided to individual markers  and School Academic Conduct Officers  for 
how to  potentially  identify the use of Generative AI.  
Policy on  Generative  Artificial Intelligence in Learning, Teaching and Assessment  
11 10.3 In line with the processes set o ut in Senate Regulation 11, students may be required to attend 
a meeting with the School Academic Conduct Officer with regard to any submitted assessment 
in which inappropriate use of AI is suspected. The purpose of such a meeting is to explore the 
process  via which the student completed the assessment.  
10.4 Academic vivas are not currently approved within University Regulations as a means of 
investigating potential academic misconduct.  
10.5 Where the use of Generative AI is permitted, any text, figures, graphs or charts, images and 
other media generate d by AI should be correctly cited.  
10.6 Unless it has been clearly articulated as appropriate for that assignment, text, figures, graphs 
or charts, images or other media generated by AI should not be submitted as  a student’s own 
work.  A student will be in breach of Senate Regulation 11  (SR11.105)  where they submit AI 
generated content for either:  
- an assessment w here use of AI is prohibited, or  
- an assessment where AI is permitted but has not been correctly cited . 
10.7 Use of the  Generative AI components of Assistive Technology  in assessments where this is not 
permitted will be considered as academic misconduct.  
10.8 Where non GenAI based assistive technology is  not specifically permitted within an 
assessment , with the exception of reasonable adjustments  (see section 9  above)  the use of 
assistive AI will be considered as academic miscon duct.  
10.9 In addition to a potential breac h of Senate Regulation 11, inappropriate, unsanctioned or un -
attributed use of AI by a student in an assessment may represent an issue under fitness to 
practise regulations in certain disciplines such as medicine, other healthcare related 
disciplines or te aching.  Where this is the case students may also be subject to processes 
under the relevant fitness to practice regulations for the discipline in question."
30,University of Nottingham,30_nottingham.rtf,https://www.nottingham.ac.uk/studyingeffectively/studying/ai.aspx,"Using generative AI
Understand where to use artificial intelligence (AI) appropriately for your studies and in preparation for your future.
Study resource: Generative AI(""https://xerte.nottingham.ac.uk/play_46905#page1"")
 

Go to: What is AI?  |  Generative AI and your studies  |  University of Nottingham policy  |  Acknowledging and referencing the use of AI(""https://www.nottingham.ac.uk/studyingeffectively/studying/ai.aspx#acknowledge"")
It is important to understanding how to use generative AI responsibly in your studies, and where this is and is not appropriate. Always check with your course tutors before using generative AI. 
 

What is AI?
 “Artificial intelligence, or AI, is technology that enables computers and machines to simulate human intelligence and problem-solving capabilities.” (IBM, 2024(""https://www.ibm.com/topics/artificial-intelligence""))
 
Increasingly, the use of AI tools is becoming common practice in a variety of industries, which means that understanding how to use generative AI effectively and responsibly will be a key skill for future employment.
 
Back to the top (""https://www.nottingham.ac.uk/studyingeffectively/studying/ai.aspx#TopOfPage"")
Generative AI and your studies
Generative AI (GenAI) tools, like ChatGPT or Copilot, are not true or 'general' AI (AGI). Generative AI only mimics intelligence through prediction and pattern recognition. Based on neural networks trained on enormous quantities of data, these tools create outputs based on probability.
Text generators use large language models (LLMs) to generate text in response to prompts, and an increasing number of generative AI tools now work across text, images, and video.
Support with your academic writing is available on Studying effectively or from the Learning Development (Academic Skills) team(""https://www.nottingham.ac.uk/library/studying/student-academic-skills/student-academic-skills-team.aspx"").
 
Back to the top (""https://www.nottingham.ac.uk/studyingeffectively/studying/ai.aspx#TopOfPage"")
University of Nottingham policy
Your module tutor and/or assessment documents should specify which uses of AI are essential, optional, and/or prohibited for each assessed piece of work. The information should also tell you how to acknowledge and provide evidence of any AI use. If you can't find this information, check with your module convenor. Do not make any assumptions about uses of AI in your assessments.
False Authorship includes the submission of work that is generated and/or improved by software that is not permitted for that assessment.  This may include the use of Generative Artificial Intelligence (AI) software to produce text, images or data or other work (e.g., Copilot, ChatGPT, DeepSeek, BARD, Wordtune, Quillbot, DALL-E, chatbots and similar).
Assessment specific information on the permitted use of Generative AI tools will be available for each assessment and it is the student’s responsibility to check this and ask for clarification where necessary.  
Key points to remember: 
Content created or significantly modified by generative AI, whether text, code, images, or video, should only be used if permitted for the specific assessment, and should always be acknowledged. 
		Always consult your tutor or assessment documents on acceptable use
		Always fact-check any information generated using AI
		Always be transparent in acknowledging your use of generative AI
 

AI at Nottingham learning resource
To learn more about generative AI, the issues surrounding it, the university’s policy and approach, and its implications for your studies, you should work through the following resource:
Study resource: Generative Artificial Intelligence guidance for students(""https://xerte.nottingham.ac.uk/play_46905#page1"")
 
Back to the top (""https://www.nottingham.ac.uk/studyingeffectively/studying/ai.aspx#TopOfPage"")
Acknowledging and referencing the use of GenAI
Acknowledging the use of AI
If you are permitted to use generative AI to help develop your ideas, to research, or to plan your writing, this must be acknowledged appropriately, even if you do not include any generated content in your assessment. Your tutors should provide guidance on how to do this.
Generally, you should acknowledge the use of generative AI tools by including a:
		statement of acknowledgment
		description of use
Acknowledgement statements 
See the examples below of statements that you can use to do this. You may also include a chat transcript as an appendix. You can save your interactions with the AI tool by right clicking on the webpage and selecting ‘Save as’, or by taking a screenshot.
Used AI to enhance background understanding
 
Used AI to generate content (e.g., a plan or outline)
 
 

Used AI to improve your writing or grammar
 

 
 

Referencing the use of generative AI
There are many referencing styles used across the university. You should always follow the guidance given by your school or department (e.g., in an assessment handbook) or by your tutor when referencing the use of generative AI.
 Specific examples of how to cite AI-generated content can be viewed in Cite Them Right, and in the University of Nottingham Referencing Styles Guide(""https://xerte.nottingham.ac.uk/play_46684"").  
The typical information required when referencing the use of generative AI is as follows: 
		Name of the AI tool
		Date generated
		Short description of information generated
You should also save a transcript of your chat with the AI tool, in case this is required in future. 
 
Back to the top (""https://www.nottingham.ac.uk/studyingeffectively/studying/ai.aspx#TopOfPage"")
Continue your journey
You may also be interested in:
		Search skills(""https://www.nottingham.ac.uk/studyingeffectively/searching/searchskills.aspx"")
		Academic writing(""https://www.nottingham.ac.uk/studyingeffectively/writing/index.aspx"")
		Referencing(""https://www.nottingham.ac.uk/studyingeffectively/referencing/index.aspx"")"
32,"Royal Holloway, University of London",32_RoyalHolloway.rtf,https://intranet.royalholloway.ac.uk/students/study/generative-ai/generative-ai-opportunities-for-education-and-academic-integrity.aspx,"GENERATIVE AI : OPPORTUNITIES FOR EDUCATION, AND ACADEMIC INTEGRITY
Generative AI tools, like Copilot, ChatGPT, Claude or Bard, are widely used now. They draft written material and create visual images, access online resources to answer questions and generate computer code. It’s important that your education at Royal Holloway helps you to use these tools because they will be important in your future employment, and other activities.
Generative AI use has to be appropriate and critical. These tools have potential benefits but also several shortcomings. Their outputs can be factually incorrect. They may replicate and multiply the biases and prejudices that are present in internet material. They may not correctly reference the source(s) of their content. Inappropriate use of generative AI also undermines fairness in awarding marks to your work.  The computing power needed for AI has a very high energy requirement and, therefore, a very a large carbon footprint with associated issues for sustainability in the future. A good discussion, albeit from the perspective of a small group of researchers, on the potential positive and negative impacts of AI on the UN sustainable development goals can be found here(""https://www.nature.com/articles/s41467-019-14108-y""). You will need to take a critical approach to the outputs of generative AI tools: this critical approach is key to all facets of a good university education, and to your future work.
Whether the use of generative AI is required, encouraged, permitted or prohibited in your studies at Royal Holloway, particularly in the preparation of assessments, will depend on the subject you are studying. You must check this in the information about each of your assessments and, if you are uncertain, please check with the member of staff who is responsible for running the assessment.

AI TOOLS

 
From the many generative AI tools, Royal Holloway recommends that you use Microsoft Copilot (https://copilot.microsoft.com/) , logging in with your Royal Holloway account details. There are online materials describing how you might use Microsoft Copilot (How to study smarter with Microsoft Copilot | Learn at Microsoft Create(""https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fcreate.microsoft.com%2Fen-us%2Flearn%2Farticles%2Fhow-to-study-smarter-with-microsoft-copilot&data=05%7C02%7CM.Crompton%40rhul.ac.uk%7C88bb867f7a55411ae59f08dcc36b6c4b%7C2efd699a19224e69b601108008d28a2e%7C0%7C0%7C638600113369895004%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&sdata=%2FyGy78QosXkC209taiUCEWAQ27qvdVAknrymPBkuIrM%3D&reserved=0"")). Please be extremely careful when entering data into a generative AI tool: this is particularly important if you are using one other than MS Copilot and your RHUL login. You cannot be certain how the data might be used or misused. Academic staff will also provide guidance on the use of other tools where necessary.
Microsoft Copilot:
Microsoft CoPilot is a AI powered tool (like ChatGPT) that can generate answers to questions (prompts). Copilot can help you learn and make you more efficient by using generative AI to reduce the time it takes for you to find information or create content.  It has previously been called Bing Chat Enterprise.
How to use Copilot
IMPORTANT: When accessing Copilot you must be logged into your Royal Holloway account using your university email address and password - this protects the data that you enter into Copilot. 
You can access Copilot by browsing to: https://copilot.microsoft.com/(""https://copilot.microsoft.com/"")
It can also be accessed directly in Microsoft Edge Browser or via mobile app found on the App store. 
Sign in with your Royal Holloway email address and password (you may not need to do this step if you are already signed in):

Then select the ‘Work’ experience:
Make sure the green shield is displayed in the top right of the screen:
You are now ready to use CoPilot!
Reasons to use Copilot and not another generative AI tool
References:
Just like when you Google for something, you need to check that the source that you get the information from is reputable and one you trust.  When Copilot generates an answer, it will provide the sources that it used at the end of the response so that you can use it to help determine the validity of the response. Not everything generated by AI is accurate so you need to check every response, looking at the sources helps with this check:
Security:
Once you sign in to Microsoft Copilot using your Royal Holloway account any data that you enter into Copilot will be securely processed and removed when it is no longer needed. Data entered will not be shared with unnecessary third parties. This is very important in helping to comply with regulatory requirements such as GDPR. 
This protection is referred to by Microsoft as Commercial Data Protection, you can read more about it here: Copilot Privacy and Protections | Microsoft Learn(""https://learn.microsoft.com/en-us/copilot/privacy-and-protections"")
 AI USE & ASSESSMENT

 
Your learning activities will often use the advantages conferred by generative AI, and your assignments will have briefs that clearly explain the extent to which generative AI use is required, encouraged, permitted or prohibited.
If an assignment does not specifically prohibit the use of generative AI in its preparation, and you have used such a tool, you must as a minimum include in your submission:
Name, version (if available), and provider of the generative AI tool used (e.g. Copilot, Microsoft).
URL of the tool used (e.g. https://copilot.microsoft.com(""https://copilot.microsoft.com/"")).
A short description of how the generative AI tool was used in the assignment.
For further guidance on how to ethically and effectively use generative AI in your research, please go to the resources produced by Library Services(""https://libguides.rhul.ac.uk/GenAIforResearch"").
REFERENCING THE USE OF AI

 
Declaration and Acknowledgement Statements, Citing and Referencing
When using Al language models or other Al tools for assistance with writing, research, or analysis, it is important that you disclose and properly reference the use of these tools. This transparency helps maintain academic integrity and ensures that the work is evaluated fairly. 
  
The Requirement of Declaration Statements
 Explicit acknowledgment of use of generative Al tools such as Large Language Models like Microsoft Copilot, Google Gemini or ChatGPT or any other media generated through similar tools is required.  Declaration statements need to be selected, completed, and appended to the references or somewhere prominent in the submission.  If you have not used any such tools in any way a declaration statement is still required:
 
1. I declare that no part of this submission has been generated by Al software. These are my own words.
 
Otherwise, declaration statement 2 with accompanying acknowledgements i, ii, and iii is required:
 
2. I declare that parts of this submission have contributions from Al software and that it aligns with acceptable use as specified as part of the assignment brief/guidance and is consistent with good academic practice. The content can still be considered as my own words. I understand that as long as my use falls within the scope of appropriate use as defined in the assessment brief/guidance then this declaration will not have any direct impact on the grades awarded.  Below are details of the generative AI tool(s) and how I have used them.
 I acknowledge use of [generative AI tool]: 
Provide information for each of the bullets and provide information from (i,ii,iii) as applicable.
In the acknowledgement statement 2, use the format below to identify what tool and how you used it.
Name, version (if available), and provider of the generative AI I tool used (e.g. Copilot, Microsoft)
URL of the tool used (e.g. https://copilot.microsoft.com(""https://copilot.microsoft.com/"")).
A short description of how the generative AI tool was used in the assignment.  Below are three broad ways (i,ii,iii) to describe stages in the assignment process.  Use as many as are applicable.
                                       i.        Generate ideas or structure suggestions, for assistance with understanding core concepts, or other substantial foundational and preparatory activity.
                                      ii.        Write, rewrite, rephrase and/or paraphrase part of this essay.
                                     iii.        Generate some other aspect of the submitted assessment. 
Note: Using software for English grammar and spell checking is consistent with Declaration Statement 1, however rephrasing and rewriting are considered ii acknowledgement statements.  Please also note that so long as acknowledged use falls within the scope of appropriate use as defined in the assessment brief/guidance then such acknowledgement statements will not have any direct impact on the grades awarded.
 
Declaration statements should be selected, completed, and appended to the references or somewhere prominent in the submission.
 Prompt List: A list of all prompts entered into any large language model must be provided.  We suggest these are included as an appendix.
 
Citing Al Use
By including in-text citations and reference list entries, you acknowledge the use of Al tools in your work, allowing for proper evaluation and attribution.
Additionally, it is essential that you follow any specific guidelines or requirements provided by your institution or course instructors regarding the use and referencing of Al tools in academic work.  
The examples below are only applicable to a limited number of referencing styles at Royal Holloway.  RHUL Library recommends consulting Cite Them Right for your department’s referencing style.
In-Text Citation: If you have used an Al language model or tool for a specific section or part of your work, you can include an in-text citation.  Below are a few examples:
 
""The following paragraph was generated with the assistance of [Al Tool Name]:""
 
[Al-generated orAl-assisted content]
 
You can replace ""[AI Tool Name]"" with the actual name of the Al language model or tool you used, such as ""ChatGPT"" or ""GPT-3"".
 
Reference List Entry: Additionally, you should include a reference entry for the Al tool(s) you used in the reference list or bibliography section of your work. Below are examples of how such a reference may be formatted:
 
Al Tool Name. (Year). [Description of the Al tool]. Retrieved from [URL or source information]
 
For instance, if you used ChatGPT, your reference entry might look like this:
 
ChatGPT. (2023). Language model for natural language processing tasks. Retrieved from https://chat.openai.com/(""https://chat.openai.com/"")
 
For guidance on how to reference generative Al tools in specific referencing styles, visit how to reference a generative Al output on 'Cite Them Right’. To access ‘Cite Them Right’, click ‘Log in’ at the top right side of the webpage and select ‘Log in via your institution’ and choose ‘Royal Holloway’. Then follow the usual login process. 

ACADEMIC MISCONDUCT AND USING AI RESPONSIBLY

 
Academic Misconduct
If you present content generated by artificial intelligence tools as your own, unless specifically authorised in writing as part of the assessment brief, and/or fail to appropriately acknowledge the use of an artificial intelligence tool, this can be treated as an academic offence. Should you unfortunately be involved in an investigation of an alleged academic offence, the Students’ Union can provide support and advice(""https://www.su.rhul.ac.uk/advice/""). You are encouraged therefore to consult your Module Leaders if you have any questions about ethical and acceptable AI usage for assignments. See Appendix 1. For guidance on acceptable and unacceptable use.
Generative AI tools/services will not be used to check/mark/grade your work.
Using AI Responsibly
Examples of Acceptable Use
Educational and Research Purposes: Students may use AI technologies for legitimate educational and research purposes, such as data analysis, natural language processing, or machine learning projects, under the guidance and supervision of faculty members.
Collaborative Learning: Students can leverage AI tools for collaborative learning, such as virtual study groups, peer-to-peer knowledge sharing, or group project collaborations.
Personal Productivity: Students may use AI-powered assistants or tools for personal productivity purposes, such as task management, note-taking, or time management, provided they do not infringe on intellectual property rights or violate privacy regulations.
Accessibility Support: AI technologies can be used to enhance accessibility and support students with disabilities, such as text-to-speech or speech-to-text tools, provided they comply with relevant laws and regulations.
Idea Generation and Brainstorming: Students can use AI language models to generate ideas or structure suggestions for their assignments, as long as they apply their own original thinking and analysis to refine and develop the content.
Code Generation and Data Analysis: Students may use AI tools to assist with code generation or data analysis tasks, but they must understand the underlying logic and decision-making processes and ensure that the outputs are accurate and aligned with their understanding of the concepts. Whether such use of generative AI is permissible in a specific assignment must be clarified through careful reading of the assessment brief and/or consultation with the member of staff/Module leader responsible for the assignment.
Examples of Unacceptable Use
Academic Dishonesty: Using AI tools to generate assignments, essays, or other academic work without proper attribution or with the intent to misrepresent authorship is strictly prohibited and considered academic dishonesty.
Plagiarism: Students must not use AI tools to plagiarize copyrighted materials or pass off generated content as their own original work.
Harassment or Discrimination: AI technologies must not be used to harass, threaten, or discriminate against individuals or groups based on race, gender, religion, or other protected characteristics.
Excessive Resource Consumption: Students should use AI resources responsibly and avoid excessive or unauthorized consumption of computing resources that may impact the availability of these resources for others"
33,University of Reading,33_reading.rtf,https://www.reading.ac.uk/digital-technology-services/ai-guidance,"Generative AI & AI Meeting Assistants
Best Practices & Privacy Guidance for Staff

This guidance(""https://www.reading.ac.uk/digital-technology-services/-/media/project/functions/digital-technology-services/documents/general-use-of-ai-tools-staff-guidance.pdf?la=en&hash=77BAC95FBD7FBDE8D69B7AB4DD2B3123"") aims to provide clarity on the University's expectations for staff when using Artificial Intelligence (AI) tools in day-to-day general working practice. It is in addition to the University's specific Data Protection and AI policies(""https://www.reading.ac.uk/imps/data-protection/data-protection-and-ai""), and complementary to the use of GenAI tools guidance(""https://www.reading.ac.uk/cqsd/artificial-intelligence/ai-guidance-for-staff"") in teaching, learning and study.
It is essential that staff are aware of and apply this guidance when considering using such tools to ensure relevant University data is kept safe.
Read the full document here: Generative AI and AI meeting assistants guidance(""https://www.reading.ac.uk/digital-technology-services/-/media/project/functions/digital-technology-services/documents/general-use-of-ai-tools-staff-guidance.pdf?la=en&hash=77BAC95FBD7FBDE8D69B7AB4DD2B3123"")
Summary of advice
The main pieces of advice in the Generative AI and AI meeting assistants guidance(""https://www.reading.ac.uk/digital-technology-services/-/media/project/functions/digital-technology-services/documents/general-use-of-ai-tools-staff-guidance.pdf?la=en&hash=77BAC95FBD7FBDE8D69B7AB4DD2B3123"") document are:
		The University acknowledges the benefits of AI and supports the use of AI tools.
		Personal or personal sensitive University data should not be used with Generative AI models. This means information related to an identified individual, and confidential information or intellectual property related to the University or third parties. If you have a particular need to use AI with data like this, please speak to DTS for advice.
		Microsoft Copilot Chat is recommended for day-to-day use at work. It can be used for tasks such as getting answers to queries, enhancing productivity and creativity, and DTS will provide basic support to colleagues with using it, as with our other Microsoft products. Although Copilot has better data protection arrangements in place, it should still not be used for personal or personal sensitive data.
		Researchers thinking of using Generative AI to assist with funding applications should check if this is permitted in the funder’s policies. The Research, Engagement and Innovation Office (REIO) can be contacted with further questions on this.
		AI meeting assistants should not be used for work meetings without prior approval. Colleagues have reported seeing these tools used in meetings in recent months, but there are privacy and data protection implications. Please speak to DTS for advice if you have a particular need for this technology.
Due to the constantly shifting landscape around AI, this guidance is a point in time position and the University will monitor and adapt in line with the technology.

Data Protection and AI
This page is subject to change and updates - please revisit this page when seeking advice and do not make local copies which may become out of date.
Artificial Intelligence (AI) and Data Protection
Use of Artificial Intelligence (AI) may have benefits to the University when it comes to finding new ways of working with these tools. We should always ask ‘what are we using it for?’, ‘does it do the job well?’ and ‘what problem does it solve?’.
The University must also ensure it meets its legal obligations under data protection laws.
Restrictions on use of AI
Currently, due to risks of non-compliance with these laws, any information classified as restricted or highly restricted must not be submitted to generative AI tools (such as ChatGPT). Detail on what Information falls into these classifications can be found within the University Classification Policy.(""https://www.reading.ac.uk/imps/information-compliance-policies"") 
This includes the personal data of our staff, students, visitors, research participants and others.
This also includes sensitive non personal information, which includes commercially sensitive data.
What are the risks of AI when it comes to personal data?
Data protection laws require all organisations to comply with a set of principles. The most pertinent to uses of AI are summarised below, along with the issues presented.
Personal data must be:
		processed lawfully, fairly and in a transparent manner
People must be made aware of how their data is being used, for what purposes, and to who it is being disclosed. It can be difficult (and in some cases, may be impossible) to know or communicate how personal data will be processed within AI tools and who may have access to it. A disclosure of information to a third party will likely be made when submitting personal data to providers of these tools, even if the provider advises it will be deleted post query. Data protection laws also contain rights for individuals, including the right to know who is controlling their data, the right to access it, and the right to seek erasure and object to its use in some cases. Where personal data is processed within AI tools, these rights can become very difficult to exercise, particularly if a person has no way of knowing where or how their personal data is being used. This can be of particular concern where an individual is subject to bias or unfair outcomes as a result of use of their data in AI tools and where they have a lack of ability to challenge these, or a way to exercise these rights.
		collected for specified, explicit and legitimate purposes and not used for incompatible purposes.
Those that trust the University with their personal data expect the University to use if for the purposes it was provided or collected and we are required to limit use to these purposes in many cases unless limited exemptions apply. Use of AI tools may involve a differing purpose and in many cases, this information will be used by the tool to further train AI which can be without the users knowledge or agreement. What further purposes it may be used for beyond our use may not be known, even to the user of the tool.
		accurate and kept up to date.
AI can pose considerable issues when it comes to accuracy of data. When this poses risks to information concerning individuals being inaccurate this principle may not be met. AI can also run risks of machine learned bias that could have detrimental effects on individuals. This is particularly a concern where use of AI results in the generating of information that could be used to make decisions about individuals or provide them with advice where accuracy is important.
Accountability is also a key requirement of data protection laws. Senior responsible owners should be in place for uses of AI who will be accountable for ensuring the security and governance of its use.
Limited and qualified exemptions from some principles exist with the law, such as those connected to research in the public interest.
How can these risks be addressed? What if I want to use AI?
The below must be considered:
		Does the use of AI have a clear purpose? Do you need to use it? What do you expect it to achieve? Can the objectives be met without it?
		Are you aware of the restrictions on use for sensitive and personal data? How will you ensure these are met?
		How will you address risks of inaccuracy? Is it important that the outputs are accurate? What impacts could inaccurate data have?
		Could AI outputs lead to detrimental effects on individuals? How will you monitor, prevent and address this?
		How will you be alert to unexpected outcomes?
		Are there ethical considerations? Is it important whether the AI tool you wish to use was trained with data that was sourced ethically or in compliance with data protection laws?
		How will you ensure you are alert to inherent bias? How will you identify and address it? 
		How will you know where your inputted data will end up? Will it be exposed to others? Does it matter?
What else do I need to know and what actions should I take?
If you are considering using AI for personal and sensitive data you must seek prior advice from IMPS or DTS.
There must be a senior accountable owner for AI projects the University undertakes.
You may be required to undertake a Data Protection Impact Assessment. These can take time so ensure that you factor this into the time and resources you need.
Risks of non compliance may be referred to a senior risk owner who must be identified and accountable for the data and those risks.
If using a generative AI account for personal use not connected to your role at the University, do not use your University email as your username.
If using a generative AI account for work connected to your role do not use your University password. Choose strong and unique passwords.
Where available, use settings within the tool to disable or opt out of the data you input being used for training or machine learning. This will sometimes be worded as 'help us make this better for others' or similar. Understand how it works. Read the user guidance.
University training on the use of generative AI tools should not be taken to be authorisation to use the tools for any data that is restricted.
Be aware that some of these tools have terms and conditions that restrict what they can be used for. In many cases, these terms will also require you have the authorisation of the University to accept those terms (bind the organisation to a legal contract). Read the terms and conditions and the small print so you fully understand what you are agreeing to.
Should the University make available access to enterprise or organisational licensed AI tools, it is the expectation that these will be used as opposed to individual accounts.
Where can I go for advice?
For questions relating to personal data and AI you can contact imps@reading.ac.uk or call us on 0118 378 8981.
DTS can be contacted at dts@reading.ac.uk or by calling 0118 378 6262.
More information is available from CQSD(""https://www.reading.ac.uk/cqsd/artificial-intelligence"").
Additional Resources
The UK regulatory authority for the protection of personal data (the ICO) has guidance(""https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/guidance-on-ai-and-data-protection/"") available.
More information on Data Protection Impact Assessments can be found at::Data Protection by Design(""https://www.reading.ac.uk/imps/data-protection/data-protection-by-design"")
The Government have produced guidance for the Civil Service(""https://www.gov.uk/government/publications/guidance-to-civil-servants-on-use-of-generative-ai/guidance-to-civil-servants-on-use-of-generative-ai"") which may also be helpful.
Whilst the UK currently has no specific AI laws (or clear plans for such) there are plans for legislation within the European Union. Whilst the UK is no longer a member of the EU, the territorial reach of any EU Act passed may include the UK where involving the data of EU residents. See more information on the progress of the EU Artificial Intelligence Act(""https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence"")."
34,Newcastle University,34_newcastle.rtf,https://www.ncl.ac.uk/academic-skills-kit/good-academic-practice/artificial-intelligence/,"Artificial Intelligence and Your Learning
Guidance to help you responsibly engage with AI for your education by maintaining academic integrity.

At Newcastle University we are committed to supporting you to develop good academic practice and your critical awareness of generative AI. These pages aim to support you in:
thinking critically about how to generative AI tools responsibly and ethically
understanding when use of generative AI is inappropriate and when it could be considered academic misconduct
maintaining good academic practice by appropriately acknowledging your use of AI tools in the development of your work
providing accurate references when using AI outputs as a source of information in your work
AI and your education
As University students you need to be aware of the potential uses of AI, how it can enhance your learning, while being cautious about becoming over reliant on AI to the detriment of your own academic development. It is important to be familiar with the limitations of the tools and the potential to slip into poor academic practice. Developing your Artificial Intelligence Literacy is going to be vital to successfully engage with these tools critically.
We've put together an AI for Learning Canvas course that provides practical advice, examples and resources to allow you to use generative AI productively and responsibly as part of your learning journey. It is a good place to start to learn more about AI and how you can use the tools in a way that supports good academic practice. 

AI and academic integrity
The Student Charter(""https://www.ncl.ac.uk/student-progress/policies/student-charter/"") sets out the rights and responsibilities of all our students, regardless of location, level, mode or programme of study. The Charter describes your responsibility to maintain high standards of academic integrity, honesty and good academic practice throughout your studies and in your work. This includes the expectation that anything you submit for assessment will be wholly your own work, or that of your group where it is collaborative work.
What is academic integrity?
Academic integrity is an underlying principle of research and academic practice. Through your work and approach to learning you are expected to demonstrate your development as an independent learner, researcher and critical thinker, including maintaining good academic practice. This involves completing your studies honestly and ethically, having respect for the work of others and recognising your responsibility to ensure fair assessment.
Poor research and academic practice or misconduct such as plagiarism, collusion, fabrication, or falsification, undermine the advancement of knowledge and innovation that are at the core of the University’s vision.
In thinking about how you will use AI tools there is an important distinction to make between learning and assessment. What may be a valuable application of AI for your own learning, knowledge or academic development may be poor academic practice or misconduct in assessment. It's vital that when approaching any assignment you ensure that the work is your own or that you have followed any guidelines or expectations about the use of AI set by your module leader. 
AI and assessment
The purpose of assessment is to measure your progress against the intended learning outcomes for your programme and allow you to demonstrate your understanding and ability to analyse and apply the knowledge and skills gained through your learning. Assessments can take many forms, including examinations, essays, group tasks, written exercises, observation of practice, portfolios, performances and presentations. Assessments play a key role in supporting your learning by providing opportunities to reflect on your progress in developing the required skills and knowledge for your programme. Passing off someone or something's work as your own, whether this is copying in an exam, getting someone else to write an assignment on your behalf or claiming authorship of machine generated content (including text, code and creative works) means that you are not demonstrating your own skills and learning. As well as limiting your opportunities to develop as a learner, it is highly unethical.
When using AI tools to support your learning and in the development of your work you must maintain good academic practice. This will include:
abiding by any expectations set by your academics about how AI can be used within the study of a module or specific assessment
acknowledging AI sources through appropriate referencing where you have used content as an information source alongside your other reading
ensuring the work you submit represents your own effort and has not been extensively edited or enhanced by AI technology or another person
demonstrating critical use of AI tools be acknowledging how, why, and when you used AI as part

Acknowledging your use of AI
Generally speaking, if you are using generative AI to support you learning and academic development, you are unlikely to need to acknowledge it. However, if you are using it to support the preparation of an assessed piece of work, you will need to acknowledge in an open and transparent way how and why you have used AI for the development of your work.
If there is a suspicion that work you have submitted for assessment is not your own, including text, images or code, partially or wholly generated by AI, your work will be considered within the Academic Misconduct Procedure(""https://www.ncl.ac.uk/student-progress/policies/procedures/#d.en.297041"") and the Student Progress Service reserves the right to run work through an AI checker as part of an investigation into academic misconduct.

Referencing AI generated sources
As with all sources of information you use in your work, you will need to critically evaluate any content generated using AI. In addition to acknowledging how you have used AI more broadly in your work, if you think it is appropriate for the task you have been given to use this material directly in your work, perhaps as a verbatim quotation, embedded image or figure, or by summarising and paraphrasing the materials, you must include an in text citation and reference.


Explore further help with referencing
Citing generative AI guide
An overview guide to citing ChatGPT and other generative AI tools within your work using different referencing styles.
PDF DOWNLOAD
Referencing Help
Explore further guidance on how to cite sources in your academic work.
WEBPAGE
Library Referencing Guide
Find further information on different referencing styles used in your Schools alongside referencing examples and tips.
WEBPAGE"
35,Queen Mary University of London,35_QueenMary.rtf,https://www.qmul.ac.uk/library/academic-skills/student-guide-to-generative-ai/,"Student Guide to Generative AI
Generative Artificial Intelligence (GenAI) technologies present significant opportunities to enhance learning, research, and professional practice. However, these tools also pose academic, ethical, and employability risks if engaged with uncritically or inappropriately.
AI has, of course, been around for some time and we often use it without realising. However, it is becoming an increasingly important part of modern society and has begun to revolutionise the way we work, communicate, and learn.
This guide provides an overview of some of the strengths and limitations of Generative AI, as well as considering ethical, privacy and other factors to help support you in using this technology effectively and in a way that aligns with Queen Mary's regulations and values.
What is Generative AI and how does it work?
Generative AI tools create content based on patterns, generating reasonably accurate, plausible-sounding (or looking) responses to prompts on a wide range of topics. However, GenAI does not ‘think’ or create original ideas.
Limitations of Generative AI
		Generative AI tools are unable to access information specific to your particular course or module at Queen Mary, nor do they have access to journals and resources that are available to you via Queen Mary Library Services(""https://www.qmul.ac.uk/library/""), so they will only make use of openly available information.
		Generative AI can create ‘hallucinations’ or fake data or information that is convincing but not based on reality or evidence. Furthermore, it can produce fake references or citations
Using AI critically
When engaging with AI:
		Interrogate outputs – Ask: How reliable is this response? What is it based on?
		Corroborate – Validate claims against scholarly and other reputable sources (which you can reference).
		Contextualise – Ensure the prompts you use are adapted to your disciplinary, cultural, and methodological contexts
		Identify gaps - Which perspectives are missing, and why might they be absent? How does this align or conflict with established literature in my field?
		Incorporate – Your OWN interpretation, analysis, synthesis, and evaluation must remain at the core of your work. Generative AI can complement, but is not a substitute, for academic thought.
The attributes gained by studying at university include your ability to critically interrogate information, generate original insights, and act with integrity. These are qualities that will help you to succeed in a world where AI is inevitable.
Academic integrity
Any use of Generative AI must align with Queen Mary’s Academic Integrity and Misconduct Policy(""https://www.qmul.ac.uk/governance-and-legal-services/media/dgls-media/policy/current-policies/Academic-Integrity-&-Misconduct-Policy.pdf""). AI use may be acceptable in some scenarios, but not all. For more detail, see the FAQs below.
		
Ethical issues
		There is concern about the environmental impacts of AI, particularly in regards to waste, energy and water usage.
		Generative AI systems are informed by existing texts or other datasets and they, like other algorithm-based tools such as internet search engines, reproduce the biases contained within the source material.
		There are important considerations around data privacy. What are AI tools doing with the data you input? Are they using this to train their models? Are you uploading someone else’s work (eg lecture notes or published articles) without permission?
		Issues around AI generated content go beyond text. The growth in ‘deep fake’ images and videos require you to develop your information literacy skills to evaluate the authenticity of all sources.
Linking AI use to Queen Mary graduate attributes
The Queen Mary Graduate Attributes(""https://www.qmul.ac.uk/queenmaryacademy/educators/resources/graduate-attributes/"") have been created to equip QM students to become active global citizens. Knowing how to use AI appropriately is inescapably part of these now. Some examples of where AI knowledge is useful include:


Be Al and Digitally Literate
Applying it to AI use
Understanding AI’s capabilities, limitations, and ethical implications.
An example
Identifying potential bias in an AI-generated literature summary and adjusting the scope of your research accordingly.



Take responsibility
Applying it to AI use
Making honest and informed decisions about whether GenAI supports, rather than replaces, your own work.
An example
Only use AI when it adds genuine value and helps with your learning or development.


Act Ethically
\Applying it to AI use
Use GenAI in line with QM guidelines, thereby contributing to the shared culture of academic integrity, which is integral value of your degree.
An example
Acknowledging and referencing any GenAI assistance in your assessment after checking whether or how AI can be used in that particular assignment.
 

Engage critically
Applying it to AI use
Evaluate and work critically with Generative AI outputs
An example

Critically evaluate output from GenAI tools and ensure this is backed up with reliable sources and your own intepretation.
Frequently asked questions
So, can you use Generative AI in your assignments at university? See the FAQ's below for more information:  

Some schools have their own specific guidance, so the first thing to do is check with your school or institute.

Some scenarios when it is acceptable to use AI tools to help with learning or preparation include:
		exploring general ideas on a topic
		helping you to understand a challenging concept or reading more clearly by generating a plain English explanation or providing examples
		identifying search terms and keywords for your search strategy using the Library databases
		using AI to revise by preparing summaries of your own notes
		producing practice questions or revision schedules to prepare for exams
Think of AI as a critical friend, to discuss, advise, question, prepare, or work through problems. Just as you wouldn’t use your friend as a source in your essay, or get them to do your work for you, the same is true of AI.

Some students are already being instructed to use AI for specific assignments, with tasks such as creating an AI-generated report and then critiquing it. Being asked to do this does not mean you can use AI throughout your course though.

You need to take a critical approach to AI output. Is it accurate? Does it tell the full story? What are the gaps, inconsistencies, or irrelevant pieces of information? What happens if you ask the question again? Look at similarities, differences and patterns in the outputs and think about what they could tell you.

No. Use multiple sources. Don’t just rely on whatever is generated by an AI tools. They can’t always access the most current information and can only use open source materials, meaning that to get information from many journals and books you still need to go via the Queen Mary University Library. To learn more about finding information, see the ‘How to research’ section on the Academic Skills Centre on QMplus(""https://qmplus.qmul.ac.uk/course/view.php?id=24311#section-3"").  

Be very specific with your prompts. Experiment with different ways of asking AI for information, including asking follow up questions.

What personal information are you sharing with the company behind the tool? Will the company own or be able to share anything you submit? Does the tool use any data you input to train their models? What biases are demonstrated by the tool? Are there any ethical concerns about the tool that you’re thinking about using? If someone is making the tool available apparently for free, what’s in it for them?

Yes. It is important to explain where you got your information from. Debates are still ongoing about how to cite generative AI tools, but we have put together a Queen Mary guide on how to reference AI within our Referencing Hub(""https://www.qmul.ac.uk/library/academic-skills/referencing-hub/referencing-guides-and-resources/""), including information on how to do so using different referencing systems.

AI has already been here for a long time, with features such as predictive text, and more tools are incorporating generative AI so seamlessly that you may not realise you’re using it. This brings us back to the key question – always ask yourself, honestly, ‘Am I sure this is this my own work I’m submitting?’

AI has long been incorporated into tools such as text to speech software. Students with disabilities should be assured that any assistive software and other technology that they utilise to access teaching and learning is permissible, even though it may use artificial intelligence.
New students at Queen Mary are enrolled on a QMplus resource on AI for student learning and research(""https://qmplus.qmul.ac.uk/course/view.php?id=21898""), which aims to introduce you to AI, what it can do, and how you can use it constructively and ethically to support your learning and research. Returning students can self-enrol if they wish to take the course.
Postgraduate researchers (PGRs)
For research students, there is specific guidance provided by the Doctoral College: AI Guidance for PGRs(""https://www.qmul.ac.uk/doctoralcollege/skills-training/doctoral-college-training-tools/ai-guidance-for-pgrs/"")
 
This guide has been created in partnership with Queen Mary Students’ Union and colleagues from across Queen Mary, including the Centre for Excellence in AI in Education. It is a companion to the Queen Mary staff guide to the use of Generative AI.(""https://www.qmul.ac.uk/queenmaryacademy/educators/resources/assessment-and-feedback/resources/generative-ai-and-chat-gpt/"")"
36,Glasgow Caledonian University,36_GlasgowCaledonian.pdf,https://www.gcu.ac.uk/__data/assets/pdf_file/0018/173007/Appropriate-use-of-AI_November-2023.pdf,"GCU g uidance on appropriate  use of generative AI  by students for 
Education purposes , November 2023 
Purpose  
The purpose of this paper  is to provide guidance for students on appropriate  and inappropriate  use of 
artificial intelligence (AI) during their studies, in the context of the University’s existing policies and 
procedures1. 
Principles  
Glasgow Caledonian University has accepted and ad opted the Russell Group Principles on the use of 
generative AI tools in  Education.  These state that:  
1. Universities will support students and staff to become AI -literate.  
2. Staff should be equipped to support students to use generative AI tools effectively and 
appropriately in their learning experience.  
3. Universities will adapt teaching and assessment to incorporate the ethical use of generative AI 
and support equal access.  
4. Universities will ensure academic rigour and integrity is upheld.  
5. Universities will work collaboratively to share best practice as the technology and its application 
in education evolves.  
To contextualise these to our specific learning and teaching environ ment, we have also approved 
following principles:  
• Inappropriate  use of AI is  a breach of the Student Code of Conduct . 
• Appropriate  use of AI is likely to be contextual to programmes of study and specific modules . 
• AI detection tools are unreliable and unlikely  to be effective . 
• AI is a sectoral / societal opportunity and challenge , with best practice emerging over time . 
This paper  aims to provide guidance on what, in general, will be seen as appropriate and inappropriate 
use of AI  by students – both in terms of general learning and teaching , and in terms of assessment. This 
is a non-exhaustive  guide, rather than a stipulation , to help  support students and staff navigate the 
effective and appropriate use of AI.  
AI in  Learning & Teaching  
Generative AI has transform ative potential in learning and teaching . Students and staff are therefore 
encouraged to experiment with, and learn from , the use of these tools to support active and 
collaborative learning as identified in the Strategy for Learning. Students may wish to use AI for 
formative purposes, to enhance their understanding in conjunction wit h traditional learning practices. In 
general terms, it is legitimate for students to use AI in ways that are akin to existing support already 
provided by the University and  use of existing  tools such as web -based search engines etc. Examples of 
appropriate and inappropriate student use are  provided  below in Table 1 .  
                                                           
1 Policies and procedures | Glasgow Caledonian University | Scotland, UK (gcu.ac.uk)  
   
 
   
  
Example  Appropriate Use  Inappropriate Use  
Lectures  Using AI as a formative tool to 
augment and develop understanding 
from lectures.  Relying solely on AI  for information. This is 
because AI may provide inaccurate  and out of 
date  information . 
Written work  Generating ideas, such as a list of 
topics.  
 
Providing  feedba ck on written wor k. 
 Experimenting with different tones of 
voice . 
 
Provid ing examples of how to 
structure a piece of written work e.g. 
report.  
 Submitting AI generated content as own work.  
 Trusting AI-generated lists of publications and 
other sources . Often these may be inaccurate 
or simply not exist.  AI may provide useful 
pointers but should be used in conjunction with established literature search tools.  
Problem -based 
learning  Providing t echnical assistance, such as 
instructions on how to use R, Ex cel, 
PowerPoint, etc.  
 Providing feedback on whether all aspects of data interpretation were explored . 
 Accepting AI generated answers without 
verification.  
 Copy and past ing AI  questions and answers.  
Quizzes and 
Exams  Generat ing practice questions for self -
assessment.  Using AI to generate answers  for submission.  
Seminars / 
Tutorials  Creat ing scenarios to help  student s 
contextualise or  augment their  
understanding.  
 
Gaining  insight into topics  by using AI 
as a critical friend.  Copying answers instead of students 
attempting problems themselves.  
 AI replacing student active participation in discussions.  
Practicals / Labs  Assist ing in troubleshooting.  
 
Understanding protocols and 
experimental design  Using AI to answer questions without 
understanding or reflecting  
Planning  and 
Self-directed 
study  Using AI to assist in project planning  
and timings.  
 
Using an AI tool to restructure  or 
change the format of  existing learning 
resources to aid personal study. This 
can be beneficial for accessibility Relying uncritically on AI to structure planning.  
 
Using a generative AI tool to restructure  or 
change the format of  existing learning 
   
 
   
 reasons and to suit personal 
preferences.  resources and sharing them with others 
without permission from the creator2. 
Table 1 : Summary of appropriate and inappropriate use of AI for students  
AI in Assessment  
It is not appropriate  for students to submit work which passes knowledge, argument, or content of 
another off as their own work. This is akin to the use of a ghost writer or an essay mill, as articulated 
within the Student Code of Conduct. Beyond this, the following guidance applies  for students : 
Appropriate  Not Appropriate  
Using  AI as a resource , like a search engine,  to 
explore a topic or question.  Trusting  AI to provide  factual content.  Always 
cross check with other search tools to establish 
validity.  
 
Including AI generated content without 
appropriate acknowledgement and 
contextualisation  
Using AI as a cr itical friend  to discuss ideas.  Not acknowledging the use of AI as a co -creator / 
collaborator  
Using AI to augment knowledge and  information  
from class.  Using AI as the main source of information.  
Table 2: Specific student guidance on AI and Assessment  
Data Protection  
Students must  comply with  data protection legislation  when using generative AI tools . The university 
provides comprehensive information on its data protection web pages , including specific student 
guidance on data protection and processing personal data . Students should not, for example, upload 
intellectual property to be used to train generative AI tools without appropriate consent from the 
creator or exemption to copyright . It is important that students are aware that when subscribing to use 
generative AI tools, it will be necessary  to provide personal data for account registration purposes and 
for more general use of the technology. Prior to sharing personal data, it is recommended that all 
students review the privacy notices and policies provided by generative AI tool providers to understand 
how personal data may be used and protected when shared with the provider.  
References  
Hough, D. (2023) Examples of using AI to support student learning & assessment in 1st year Life 
Sciences. University of Glasgow. https://sway.office.com/iNhP49DMrhOep2Uc   
                                                           
2 Learning resources may only be used in  accordance with the University’s existing Code of Student 
Conduct , Copyright guidelines  and guidance on recording lectures and other events ."
37,Swansea University,37_swansea.rtf,https://hwb.swansea.ac.uk/academic-life/academic-regulations/taught-guidance/assessment-and-progress-taught/artificial-intelligence-guidance/,"ARTIFICIAL INTELLIGENCE GUIDANCE

ARTIFICIAL INTELLIGENCE TOOLS
Generative AI
Your University and tutors are engaging with the emergence of Artificial Intelligence tools and adapting to the changing environment to ensure that you are equipped with the knowledge and skills to safely use these tools. We have produced some initial guidance regarding the emergence of generative artificial intelligence (in the form apps like Chat GPT (open AI/Microsoft) and Bard (Google)) and how and when it can be used safely, and what to watch out for. This guidance IS NOT intended to address existing tools such as Grammarly and Google Translate.
AI use guidelines in non-assessment conditions
Not intended to address use in assessments
How to cite AI
APA Style Blog 'How to cite ChatGPT'
SALT & FMHLS 'AI in Education' Seminar Series
Applications of AI in Quality Assurance and Enhancement in UK Higher Education
Guidance for students
Your module tutors and University staff will guide you in the use of technologies including the benefits, risks and ethical considerations of use.
Please engage in open conversations with your module tutors and staff about AI tools and the quality of the work that the tools produce: often repetitive and lacking in detail and analysis.
Ensure that the tools are used by you appropriately (as guided by your tutors), openly (declared use), and honestly and ethically (complying with assessment rules and guidance).
AI tools should not be relied upon as a substitute for learning or developing employability skills e.g. do not miss the experience of fact checking, evaluating evidence along with the opportunity to practice writing and communication skills.
Continue to develop your own core foundational knowledge to assess the accuracy of generated text and references. The tools do not understand what they produce. Despite their name they are not intelligent. AI tools should not be relied upon for factual accuracy as they can fabricate i.e. ‘hallucinate’ facts and references.
Follow guidance, support and advice relating to Academic Integrity literacy, learn the value of integrity and avoid an investigation of academic misconduct into your work.
Work generated by AI tools and submitted for assessment when not expressly authorised and declared could be investigated for academic misconduct. Please refer to the University’s Academic Misconduct Procedure(""https://hwb.swansea.ac.uk/academic-life/academic-regulations/assessment-and-progress/academic-misconduct-procedure/"") for further information.
Ask. Always seek knowledge and clarification (ASK) from your module tutors if you don’t understand assessment requirements and guidance.
Avoid inputting personal information or data when using AI tools.
Please see the Artificial Intelligence and Academic Skills on CAS webpage(""https://myuni.swansea.ac.uk/academic-success/whats-on/"") for further guidance."
38,Manchester Metropolitan University,38_ManchesterMet.rtf,https://www.mmu.ac.uk/about-us/professional-services/uta/teaching/embracing-generative-ai-responsibly,"Artificial intelligence (AI) is a broad term that can refer to many different technologies. Generative AI is a specific set of tools that can generate content such as text, images, videos or music. The University’s approved generative AI tool that can be used to generate text and images is Microsoft Copilot(""https://copilot.microsoft.com/""). Staff and students can use the tool for free with their university credentials.
There has been much debate about generative AI, largely focused on assessment. At Manchester Met, we are proactively tackling the potential issues these tools bring by embracing generative AI responsibly.  This means that we are: 
developing students’ AI literacy so that they are aware of the capabilities and limitations of generative AI tools. 
providing opportunities for students to gain practical experience in using and evaluating generative AI tools as part of teaching and learning experiences.   
using authentic assessments that are resilient to the misuse of generative AI. 
explaining to students our expectations about the use of generative AI in assessment with a default position and assessment-specific guidance.  
implementing our academic misconduct procedures when there is clear evidence of students passing the work of generative AI off as their own. 

Developing AI Literacy
Developing AI literacy is more than learning how to use tools. It’s about:  
understanding the basic concepts and terminology related to AI.  
using AI tools and platforms responsibly and productively. 
recognising the potential applications and limitations of AI in various domains.  
evaluating the ethical implications and potential biases in AI systems.  
		 Support with using Microsoft Copilot
		 Rise AI Literacy Study Pack
		 Digital skills in AI and generative AI self-assessment
Recognising concerns
Just as we cannot avoid generative AI, we also cannot ignore the potential issues it raises. We are all feeling the impact of these tools, making it important to respect all perspectives with empathy and kindness.  
Much like making conscious choices when purchasing products, we want to enable informed decision-making. That way, the use of these technologies will align with our values and goals, such as inclusivity, reducing awarding gaps, decolonising the curriculum, and promoting sustainability.
The Rise AI Literacy study pack helps get started exploring points such as: 
Generative AI outputs are based on statistics, not intelligence. See Capabilities and Limitations of AI(""https://rise.mmu.ac.uk/topic/capabilities-and-limitations-of-ai/"").
AI text generators are only trained to predict sequences of words. They do not have the functionality to check the accuracy. See Capabilities and Limitations of AI(""https://rise.mmu.ac.uk/topic/capabilities-and-limitations-of-ai/"").
Generative AI is not a reliable source of information. See Verifying Information(""https://rise.mmu.ac.uk/topic/verifying-information/"").
The output of generative AI tools is often biased.  See Bias(""https://rise.mmu.ac.uk/topic/bias-4/"").
The pricing of generative AI tools makes access to them inequitable. Free versions have less functionality and use older models. See Choosing an AI tool(""https://rise.mmu.ac.uk/topic/choosing-an-ai-tool/"").
The data used to train generative AI tools has been scraped from the internet, often without consent. This raises concerns about copyright and intellectual property. See Copyright(""https://rise.mmu.ac.uk/topic/copyright/"").  
The data you input into generative AI tools might be used to train future models. See Choosing an AI tool(""https://rise.mmu.ac.uk/topic/choosing-an-ai-tool/"") .
The training and use of generative AI tools require tremendous amounts of energy, water and earth metals. This has a significant environmental impact. See Human and Environmental Impact(""https://rise.mmu.ac.uk/topic/human-and-environments-impact/"").
The ethics of some of the companies that develop and deploy generative AI tools have been questioned. See Human and Environmental Impact(""https://rise.mmu.ac.uk/topic/human-and-environments-impact/"").
Legislation and regulation often lag behind the rapid advancements in technology, including generative AI. See Legislation(""https://rise.mmu.ac.uk/topic/legislation-3/"").
Using generative AI to support teaching and learning
Generative AI can be incredibly helpful for both students and teachers. We encourage all staff and students to explore how generative AI can be used responsibly to improve learning experiences and to support our students to be career-ready.   
Here are some examples of starting points for integrating generative AI into teaching and learning. When using generative AI, always make sure to check all outputs are accurate and free of bias. 

Generate activity ideas
If you want to make your sessions more interactive, but are not sure how, Microsoft Copilot can generate some initial ideas.

Generate polling questions
Vevox have an AI Quiz Tool that you can use to generate some draft polling questions.

Starting point for Padlet activities
The Create with AI option in Padlet gives you a starting point for setting up a Padlet for collaborative work.

Starting point for presentations
The Menti AI presentation maker can create a first draft of your presentation.

Critique AI outputs for accuracy
Generating some example text can be a useful prompt for discussion. Ask students to appraise the output and verify the information within them using more reliable sources.

Critique AI outputs for bias
Images created by generative AI can be a helpful prompt for discussions about bias. A simple activity is to ask Copilot to create a picture of someone in the industry the students are working towards

Authentic assessments
Authentic assessment approaches can reduce the risk of academic misconduct resulting from students attempting to pass off work created by generative AI as their own.   

Authentic assessment refers to the assessment of learning that is conducted through real-world tasks requiring students to demonstrate their knowledge and skills in meaningful contexts (Swaffield, 2011). Authentic assessments are designed to measure a learner’s ability to apply learning to real-world contexts.  

An authentic assessment draws upon many of the features of active learning. Our resources on resources on active learning might be a useful starting point for assessment design.  Features of authentic assessment include: 

clear links to the module learning outcomes 
a clear and transparent marking process
an accessible and understandable assessment brief 
a consideration of active learning strategies 
Assessment design may adopt an authentic approach by incorporating elements of real-world contexts, professional standards, reflections on practice and other personalised and bespoke content. For example:  

Using activities related to real-world tasks or scenarios. 
Providing an opportunity for collaboration and co-production.  
Encouraging opportunities for reflection on lived experiences.  
Adopting problem-solving techniques and activities. 
Assessment activities
Collection of assessment types to support course planning.

""""
Assessment design toolkit
Guidance on designing assessment at Manchester Met.

Assessment ideas on Jisc
A postcard set to invoke discussion around assessment approaches.

Explaining expectations to students
Our default position on the use of generative AI and broader AI tools is explained in detail to students in the Are you allowed to use AI in assessments? section of the AI Literacy Rise Study Pack.

The two key principles that we want our students to work to are:   

Your work should always authentically represent your capabilities.  
You should never trust the outputs of generative AI uncritically.  

At a high level, the position is that students can use generative AI:  

to help them understand content, but they must check this against other sources
as part of the planning process (for example to get ideas, to break down tasks, to explore different structures)  
to find information but should not consider it a reliable source
to provide feedback on work, but must maintain authorship by making a decision about each change suggested
They cannot use it to create the assessment itself. 

Our Academic Misconduct Policy states that it is not an offence to use generative AI when it has been “has been expressly authorised as part of the assessment component”.

The extent to which students are permitted to use generative AI is clearly explained in all assessment briefs. 

Most assessments will take the default position, but students are advised to check each assessment brief for specific instructions. There may be instances where the use of generative AI is not permitted, but this will only be where there is a clear reason, such as meeting the requirements of a professional, statutory and regulatory body.

Where an assessment is categorised as permitted, students must follow the guidance set out in the default position and retain authorship of the work so that it does not constitute academic misconduct. Module teams can adjust the default position where there is a pedagogical reason, but this must be clearly explained in the assignment brief.

Our approach to managing submitted work
A reliable detector for AI-generated text is not available 
There currently is no suitable technology for detecting AI-generated text.

Turnitin announced it was launching an AI detector in April 2023, which it claimed to have a false positive rate of less than 1%, but has since revised this figure to 4% in June 2023. This means that for every 100 submissions submitted to Turnitin, 4 will be flagged incorrectly as written by AI.

Concerns have also been raised about these tools showing bias against non-native English writers. Like the overwhelming majority of UK higher education institutions, Manchester Met has opted out of enabling this software as a means of detecting generative AI for the foreseeable future. 

Colleagues must not upload student work into an online AI detection service. These are not reliable and the data uploaded is not secure."
39,Heriot-Watt University,39_heriotWatt.pdf,https://lta.hw.ac.uk/wp-content/uploads/Student-guidance-on-Artificial-Intelligence-in-Learning-and-Teaching-AY23-24.pdf,"Student guidance on Artificial Intelligence in Learning and Teaching 
AY23 -24 
 
HW General principles  
1. Students should use HW supported technology as this has been reviewed to ensure that it 
protects their privacy,  is cyber secure and is safe to use.  
2. Students should think critically about any choice to use technology.  
3. Students must be confident that they have made informed decisions about using 
technology, and that it is in keeping with academic integrity.  
4. HW will support students to develop the digital capabilities needed to participate effectively 
in the university and wider society.  
Artificial intelligence  
Heriot -Watt University recognises the opportunities and challenges that developments in artificial 
intelligence (AI), in particular generative AI, offer to learning, teaching and assessment. We will 
encourage and support students and staff to engage with a rtificial intelligence in keeping with the 
HW general principles on use of technology.  
How AI may be used at HW  
1. Use of generative artificial intelligence ( GAI) is permitted provided that such use is clearly 
identified and referenced. Generative AI spelling and grammar checking (e.g. MS Word, 
Grammarly) does not need to be referenced unless specifically indicated within the course.  
2. The use of generative AI should be referenced using the appropriate referencing format for 
the piece of work.  
3. Any use of artificial intelligence must align with the principles of academic integrity as 
outlined by the International Centre for Academic Integrity . 
4. Courses and programmes within HW may make use of generative AI where it is appropriate 
to support the learning outcomes, however there is no requirement for a course or 
programme to utilise generative AI.  
5. If generative AI is to be used, course staff will provide clear guidance to students on how 
and when generative AI may be used within the course. Any use of generative AI within a 
course will be in keeping with HW general principles on use of technology. H W will keep 
under review developments on generative AI detection tools.  
6. HW will not be utilising any generative AI detection tools for the period of AY23 -24. 
However the existing measures to identify and address academic misconduct are still in use 
and will apply to any misuse of generative artificial intelligence.  
7. HW will also ensure that staff have the appropriate digital capabilities and the appropriate 
technologies to provide effective teaching, learning and assessment. This will support 
Page 2 of 4 
 Caution : Using artificial intelligence to complete a whole assignment for you would 
not be acting with academic integrity, as you would be presenting work that is not 
your own. This is plagiarism and would be considered academic misconduct.  
 students to develop the appropriate digital capabilities to enable them to enter society with 
the attributes to thrive in this technology -enabled era.  
 
How to choose whether to use generative AI  
1. If you are thinking about using generative AI (GAI)  to support your learning check whether 
its use is permitted on your course. Only use GAI if it is permitted on your course and only 
use if for the purposes it is permitted e.g. you might be permitted to use it to research a 
topic but not to help you write it up. Remember that whether it is permitted or not may be 
different on each course and will be different from other institutions in which you have 
studied.  
2. If use of generative AI is permitted on your course, then consider carefully which technology 
is most appropriate to use. Different technologies have different intended purposes e.g. 
media generation, text generation, conversational Q&A . 
3. If it is a requirement of your course, and you have concerns about using AI, you should raise 
this with your course leader clearly explaining your concerns. The HW general principles of 
use of technology may help you with this decision.  
 
How to write a generative AI prompt  
The ‘prompt’ provides the instruction to the generative AI of what you want it to do. It is therefore 
important that your prompt is as specific and clear as possible. As with any technology, if you 
provide unclear or poor instructions you will get unclear and poor results.   
It is not good practice to use the whole assessment question or brief as a promp t. It is better to 
break down the question into the key aspects that you need to focus on and tailor your prompts to 
these.   
When writing the prompt be specific about the parameters to be considered and the output you 
require. Using terms such as ‘and’, ‘or’ and ‘not’ can be useful to ensure information is included or 
excluded as required.  
In the example below you can see how refining the prompt can provide more specific and useful 
output.  
• What i s the impact of climate change ? 
• What  is the impact of climate change in my country ? 
• What  is the impact of climate change in my country on farming ? 
• Write an essay plan for a critical evaluation of the impact of climate change in my country 
on food production by farmers . 
Think carefully about the type of output you require. For example, do you need a research plan, an 
essay plan, some ideas about the topic, a review or sense check of your current understanding etc.  
 
 
Page 3 of 4 
   
Top tips :  
1. As you develop your prompts, reflect on what changes you are making to them and how this 
is helping you to refine your understanding of the topic.  
2. Keep copies of your prompts and outputs for future reference. You may need to provide 
copies of them in your assignments.  
3. Use generative AI that identifies where information is sourced from so that you can check 
that it has used a real source , them make sure that you do check the source and make your 
own assessment as to whether the source is appropriate and reliable.  
 
 
How to interpret the output  from generative AI 
There are key factors to bear in mind when using output from generative AI: 
1. Critically evaluate the content and cross -check it with trusted academic sources. (You can 
get help with critical evaluation from the Skills Hub ). 
2. AI generated content may not be accurate (even where it includes references), the outputs 
are predictions, they are not facts, and the content may be based on biased or stereotypical 
perspectives.  
3. Double check the accuracy of the content and the references using trusted academic 
sources e.g. via the University Library to access peer -reviewed journals.  
4. As you cross -check the content, look for sources that are Accurate, Current, Objective, 
Relevant and Named. (Find out more about this ACORN  approach from Cite Them  Right  
Online ).  
5. The output may draw on copyright information as generative AI operates by scraping 
information from the internet without checking the owners’ permission. Copying this output 
may be a breach of copyright, so try to identify and use the original source , ensuring you 
comply with copyright as you do so.  
 
How you use the output  from generative AI 
How you use the output will depend on what is permitted within your course , check with your 
course leader to find out what is permitted . Note that what is permitted may be different for 
different courses.  
Key point  
You must ensure that you act with academic integrity at all times.  Academic 
integrity is the umbrella term used to describe 6 fundamental values of academia - 
honesty, fairness, responsibility, trust, respect and courage.  
 
Page 4 of 4 
  It may be that the output is formative only, helping you to develop and refine your thinking. If this 
is the case, check your course guidance or speak to your course team on whether you need to 
reference this use.  
Where the output contributes to summative assessment, you must ensure that you reference this 
following the referencing style and any specific guidance from your course.  
Top tip :  
If you are using generative AI, take very careful notes of any prompts and outputs so that you can 
clearly identify what work was generated by AI and you do not unintentionally plagiarise by 
presenting AI generated work as if it were your own.  
 
Referencing  your use of AI  
Different referencing styles take different approaches to how generative AI should be referenced. 
You should ensure that you follow the guidance for the referencing style used on your course.  
You can find guidance and examples of how to reference AI in many standard referencing styles via 
Cite Them  Right  Online . If you cannot find guidance there you should consult the library and your 
Course Leader.  
You should check whether your course requires you to provide copies of the prompts you used or 
the output generated by the AI.  
 
Summary  
• Use of generative artificial intelligence (GAI) is permitted provided that such use is clearly 
identified and referenced . 
• You should check with your course leader what is permitted on your course and  what 
guidance they have on how it might be used and should be referenced.  
• You must act with academic integrity at all times.  
 
Resources  
Student Skills Hub  
HW Academic Integrity website  (public -facing)  
HW Academic Integrity hub  (students and staff only)  
HW Student Academic Conduct policy  
HW guidance on plagiarism"
40,University of East Anglia,40_EastAnglia.pdf,https://assets.uea.ac.uk/f/185167/x/5558a0f812/generative-ai-policy-for-teaching-and-learning.pdf,"- 1 -  
Generative AI Policy for Teaching and Learning   
Authors:  Professor Kay Yeoman (APVC -LTE) , Dr Eloise Ellis , Prof Fabio 
Arico   
 
 
1. Scope 
 
1.1 This document  sets out the U niversity’s policy for  the use of Generative AI in 
Teaching and Learning for taught programmes  and for taught components of 
professional doctorates . The policy will be regularly reviewed by the University’s 
Learning and Teaching Committee.  The use of Generative AI in the research work of 
postgraduate research programmes is covered by the University Policy for the use of Generative AI in Research.  
1.2 The policy does not prohibit  the use of Generative AI  for teaching and learning but 
aims to add clarity around appropriate use for both staff and students  and positions 
the requirement for ongoing training across the whole community to influence 
behaviour and surface best practice.  
1.3 The policy allows for differential  use across the institution according to discipline 
area.  This policy should be read in conjunction with the following U niversity policies ; 
 
• Plagiarism and Collusion Policy ; 
• Inclusive Education Policy ; and  
• Blended Learning Policy . 
1.4 Staff should complete training in the following areas;  
• Data protection 
• Copyright  
  
2. Introduction  
 2.1 Generative Artificial Intelligence (AI) is a sub -area of Artificial Intelligence where 
Large Language Models (LLMs) are trained using huge amounts of data, and then used to generate new content, such as text, code, diagrams and images, prompted 
by human input.  It should be noted that GPTs are not strictly AI but  represent travel 
towards it. GPTs are covered under this policy.  
2.2 Machine learning has been in existence for a number of  years, and it is common in 
software such as spelling and grammar checking. However , the rapid and ongoing 
development of G enerative AI tools which are able to replicate natural language and 
generate content  has had a disrupting effect in the education sec tor.  
3. Governance  
3.1 The University’s Plagiarism , Collusion and Contract Cheating Policy will be under regular 
review to ensure that it remains  current  and reflects practice in line with what is developing 
understanding within this area of academic integrity.  
 - 2 - 3.1 The UEA Generative AI working group will continue to meet and surface emerging 
technologies , opportunities and challenges.  
 
4. Institutional  
4.1 The use of Generative AI is likely to be different across the institution by subject area  
and across disciplines . Thus , each School of Study should meet at least  once per academic 
year to discuss t he impact of generative AI on their assessment design and set School -level 
expectations around the appropriate use of AI for students within their discipline.   
4.2 Expectations should be understood by all academic staff  within that School, clearly 
communicated to students at appropriate points and, where there is a School approach or 
practice which differs from the general University guidance (as set out in this policy) , 
explicitly explained in the assessment briefs .  
4.3 The use of computer assistance to give the impression that a student has learned more 
than they have is academic misconduct .  
 
5. Pedagogy  
Computers and AI can be useful in many contexts,  but they can produce incomplete, 
inaccurate, misleading and/or biased information. Therefore, it is important students develop 
skills in using computers and Ge nerative AI tools  effectively to support their studies, 
including an awareness of their strengths and limitations  and learn how to challenge the 
outputs . These should also be considered skill s they will need in the workplace.  
5.1 Student Practice  
5.1.1 There are a number of ‘green light’ approaches which can be used  by students  
• Generative AI as mentor  - timely feedback is crucial for students , and generative AI 
can be used to gain ongoing feedback  on tasks and assignments . It can also be used 
as a tool to help support effective study.  Students should reflect on AI  feedback  and 
other outputs  against their own knowledge and understanding and report on the 
guidance which has been provided and how they may or may not include it in their work.  This is to complement and not substitute for engagement with formative tasks, 
and guidance from teaching staff, Learning Enhancement Tutors, Academic 
Librarians and others and the University.  
• Generative AI as tutor  - explanations can be provided to gain understanding. 
Inspiration and ideas can be provided. AI can help develop thinking by checking responses, providing counterarguments and generating questions. Students should 
always check AI output against their own  knowledge and understanding , and other 
sources,  as content can be inaccurate  biased and misleading.  
• Generative AI as a team member  - team working is an important workplace skill, 
and Generative AI can be used by a team  of students  to act as a virtual member , 
maybe playing a role which other students might find awkward or difficult , e.g. asking 
for a counterargument or acting as a disrupter.  Students do not need to take the 
advice of the AI and must be critical and evaluate the output before it is used.  
• Generative  AI as researcher -doing a literature  search is a crucial  part of starting 
most items  of assessment. Generative  AI can be used to surface relevant literature, 
however students  should be aware that references can be fictional , not current  and 
 - 3 - non-exhaustive . There are certainly  better and more accurate  tools to surface 
research papers.   
5.1.2 There  are a number of ‘red light’ activities wh ere students should not use Generative 
AI 
• UEA aims to encourage, develop and assess written English; unless specifically 
required to use AI as part of the assessment submitted work must always be the student’s own writing  therefore they must not copy and paste computer generated 
text directly.  
• Students should be aware that the ou tput from Generative AI can contain errors, 
bias, misinformation, missing information, and hallucinations  (false information) . 
Students should always check the content against their own knowledge and 
understanding.  
• Students should not use Generative AI as the first step in their  thinking (i.e. to 
immediately ask the computer the exact question that they  have been asked) . 
• Students should no t circumvent  their learning, e.g. when asked to reflect  on a task or 
output from a task . 
• Students should not rely on Generative AI when working in an important context where the student  is reliant on the generated output being correct (e.g. legal contexts 
such as placement risk assessments) . 
• Students should not use content or ideas from Generative AI without  appropriate 
citation . 
• Students should be aware of privacy  and GDPR and not input  personal and private 
information about themselves or others . This is because the software will store data 
and information and potentially use it for other content.  
• Students should not input confidential research data, both quantitative and qualitative 
or copyright ed data/ text into an AI tool without approval.  If personal data is to be put 
into an AI tool this must be part of the ethics application process.  
 
5.2 Staff Practice  
5.2.1 There are a number of ‘green light’ approaches which can be used by staff . These 
have been grouped as design, content creation and assessment , but more information can 
be found in the Staff Guidance document .  
• Generative AI for teaching design- ideas for teaching often come through speaking 
with colleagues and investigating the pedagogical literature. Generative AI can be 
used to generate lesson plans, surface new ideas and approaches.  
• Generative AI for content creation -this could involve the generation of templates, 
for example letters , case examples to illustrate concepts  or scenarios which can be 
discussed in teaching sessions.  Diagrams and images can also be created, but the 
AI tools here are often paid for, and run the risk of copyright issues.  
• Generation AI  for assessment - answers to example assessment questions to be 
shared with students to evaluate the strengths and weakness of generative AI 
content . Grouping and marking responses to short answer questions or multiple 
choice where AI  functionality is part of a software package used to deliver an 
assessme nt and where there remains human oversight.   
• Generative AI as mentor -support students to explore way s of using Generative AI 
for ongoing feedback on assignments  and tasks  and as a tool to help support 
effective study. This includes helping students to reflect  on AI feedback  and other 
 - 4 - outputs  against their own knowledge and understanding and report on the guidance 
which has been provided  and how they may or may not include it in their work.  
 
5.2.2 There  are a number of ‘red light’ activities where staff should not use Generative AI   
• Generation of letters  to students or other staff  using personal data  and information.  
This is because the software will store data and information and potentially use it for 
other content.  
• Generation of personalised student feedback on formative and summative 
assessment . Students can be encouraged to seek ongoing feedback on tasks and 
assignments, but the justification of a mark should be a human judgement. 
 
6. Technology  
 
6.1 As with all technologies UEA will monitor the AI tools on offer on a regular basis and 
make the decision if and when to obtain a license for specific tools.  
6.2 UEA has approved the use of the TurnitIn AI detection software  for taught programmes , 
but this must be used with caution by Plagiarism Officers  only due to reported inaccuracy  
and, as with other screening tools, merely one factor in potentially identifying submissions 
which warrant further investigation.  The tool will not be able to differentiate legitimate use of 
Generati ve AI.  
 
7. Support , Training  and Professional Development  for St aff 
7.1 Support will be given to staff through self -access materials, in person training sessions 
and opportunities  for discussion. This training will be offered through CHERPPS  and CTEL.  
7.2 Training will be given to Plagiarism Officers  on the available detection tools and their 
limitations.  
 8. Support and Training for Students  
8.1 Support should be given to students by their Schools on the use of Generative AI, the 
policy should be translated into guidelines t o support students with when they can and 
cannot use the tools.  
8.2 Module organisers should make it clear within assessment briefs how Generative A I can 
be used, ensuring that the p olicy is adhered to, or where it differs explain why.  
8.3 Support is also available in the Learning Enhancement Team and  the Library.  
 
9.0 Supporting Resources 
UK Government White Paper
 
JISC -AI  a Primer  
Generative AI Guidance for Staff V0 2 
 
 1 Generative AI Guidance for Staff in Teaching and Learning  
 
Who is this guide for?  
 
Any member of staff involved in teaching and learning as it relates to undergraduate, 
postgraduate and apprenticeship programmes. UEA has a Generative AI Policy which 
should be read in conjunction with this guidance document. Partner institutions can use and 
adapt this guide as required.  
 
Introduction  
 
Generative Artificial Intelligence (AI) is a sub -area of Artificial Intelligence where Large 
Language Models (LLMs) are trained using huge amounts of data, and then used to 
generate new content, such as text , code, diagrams and images, prompted by human input. 
The models articulate from pattern- prediction processes, and being aware and critical of the 
kind of data fed to these processes is more important than disentangling how predictions are 
being generated.  Generative AI software companies do not disclose the origin of such data 
in a transparent matter.  
 Machine learning has been in existence for a number of years, and it is common in software 
such as spelling and grammar checking. However, the rapid and ongoing development of 
generative AI tools which are able to replicate natural language and generate content has had 
a disrupting effect in the education sector.  It is neither possible to avoid, n or outrun AI.  
 
 
It is clear that most  HEIs consider that simply prohibiting AI is neither a viable strategy nor an 
appropriate response to these developments - students will inevitably come across such 
technologies in their future and will need an understanding of their strengths and limitati ons.    
 
There are a number of perceived opportunities and challenges on the use of AI in higher 
education.    
 
Opportunities   
• Developing awareness of and skills around academic integrity.   
• Articulating the attributes of our students which are independent of AI, e.g. 
critical thinking, self -reflection, tolerance, thought and action.   
• Diversifying assessment to focus on core competencies (however, need to 
ensure that students have an understanding of the potential uses  of AI in their 
specific  disciplines).   
• Providing students with advice and tools that can support/accelerate their 
learning and achievement of (existing and future) learning outcomes.   
• Providing new opportunities for judgement -free tailored instruction for students 
from disadvantaged backgrounds or with lower starting skill levels to level up 
their learning.   
• Speeding up analysis of data. Automating repetitive processes. Researching 
into the use of AI.   
 
 Challenges  
• Understanding the different types of AI which currently exist and monitoring 
new and evolving developments.   
Generative AI Guidance for Staff V0 2 
 
 2 • Student use of AI inappropriately to generate complete  responses to 
assessment items.  This would make it seem that students have achieved more 
learning that is actually the case.  
• Ensure that assessment is meeting the right learning outcomes to provide our 
students with skills which are independent of AI, or where AI is not intended to replace.   
• Where developing AI skills are themselves a learning outcome ensure that it is appropriate.   
• The use of AI may become paid for (advanced features already are) - therefore 
if the use of AI is a learning outcome there may be financial liability for st udents 
and/or the institution.   
• Current language models (that are free of charge) are not 100% accurate in the content generated or the references provided, and their accuracy may depend on subject. This will improve in time and with premium  (paid for)  versions.   
• Potential adverse effects from teaching students how to use AI in terms of overreliance on generative AI for assessments.   
• Unequal opportunities for students with disabilities and SPLDs if there is an overreliance on Generative AI tools and no support on specialist software such 
as voice recognition etc.   
 
 
The Technology Available  
 
Machine learning has been in existence for a number of years, and it is common in software 
such as spelling and grammar checking. However, the rapid and ongoing development of generative AI tools which are able to replicate natural language and generate content has 
had a disrupting effect in the education sec tor.   
 Generative AI is a sub -group of AI which creates new content, including images and 
diagrams  rather than analysing existing data. Examples include Generative Pre -Trained 
Transformers (GPT). It should be noted that GPTs are not strictly AI but represent travel towards it.   They work on text based prediction algorithms  and are trained on databases and 
then with human interaction. GPTs still fall under the policy.  
 The output from Generative AI can contain errors, bias, misinformation, missing information, 
and hallucinations (false information). Everyone who uses Generative AI should always 
check the content against their own knowledge and understanding. This is an essential part 
of the development of critical thinking skills. One way to get better information out of the AI 
tool is to under stand more about hallucinations, why they occu r and  how to mitigate. In this 
short clip
 an IBM representative covers hallucinations.   
 
Generative AI technology continues to develop rapidly. Tools such as ChatGPT, Google 
Bard, Wordtune and Quilbot  are becoming widely known. Not all services are free, and some 
products have premium paid for functionality  (freemium) .  
 Microsoft will be launching Copilot into its core software (Word, PowerPoint etc ). Microsoft 
states that Copilot “ combines the power of large language models (LLMs) with your data in 
the Microsoft Graph and the Microsoft 365 apps to turn your words into the most powerful 
productivity tool on the planet .” 
 
There is a useful AI Tools Directory  where you can find details of the available tools and a 
description of how they can be used  and whether they are free or freemium.  
 
Generative AI Guidance for Staff V0 2 
 
 3 Exploring ChatGPT  as an example tool 
 
ChatGPT  is probably the tool which has received the most attention since January 2023. 
ChatGPT only has access to data up to 2021 and  does not ‘scour’ the internet. It cannot 
access anything which is behind a paywall. Experiences of those who have used it to 
generate answers to essays have shown that it can produce reasonable answers to level 3 
and 4 higher education written assessments. However , there are limitations:  
 
1. The narrative while clear, is often unsophisticated  
2. The question is referred to often within the response 
3. The main ideas lack nuance 
4. The insights are superficial  
5. References are dated, or they are hallucinations  (false in formation)  
6. Key references are often missing  
 
Detection of AI generated content 
 
You can sometimes detect ChatGPT  generated text by experience of looking at the outputs. 
There is often a superficial narrative, the essay question is often referred to throughout. 
Often points are made several times but re- worded. References are often false, or key 
sources for your subject area are often missing.  
 There are detection tools available. You can use ZeroGPT
, there are also tools available 
from TurnitIn , but Blackboard has recently stopped developing detection tools as they are 
unreliable. Detection tools should be used with caution due to reported inaccuracy and, as 
with other screening tools, merely one factor in potentially identifying submissions which 
warrant further investigation.  The tool will not be able to differentiate legitimate use of 
Generative AI.  
 By far the best way to limit the inappropriate use of generative AI  in your students  is training.  
The Library  and Learning Enhancement Team  have produced a training guide for students
, 
but there are activities  you can do to support this.  
• Show ChatGPT to students and run question and example assessment though it. 
• Ask the students to criticise the outputs and uncover the flaws  
• Make sure that students know that if they use it within their work, that they must reference the contribution made. 
• Make s ure that students know that they cannot copy and paste AI generated content 
(when it is not part of the assessment design itself) .  
• Remind students of the Plagiarism  and Collusion Policy which states “ While you are 
permitted to use artificial intelligence software to help you understand material and how that can be expressed, you are not allowed to use that software to complete the 
assessment (or any part of it) for you. If you use artificial intelligence software to 
complete the work for you, that will be plagiarism. In some cases, it will reach the 
level of contract cheating Policy point 5 pg 3 ” 
 
Referencing AI Contribution  
 
A general overview use declaration (in the submission declaration) in which you explain in general how technology assistance was used e.g. “I have used word processing and spell 
check as well as the reference sources cited in the reference list and …)  
 
Generative AI Guidance for Staff V0 2 
 
 4 Specifically, when you would cite a human (for the idea, exact or general wording) then cite 
the technology:  
 Author of AI model used. (Year of AI model used). Name of AI model used (Version of AI 
model used) [Type or description of AI model used]. Web address of AI model used 
§ E.g., OpenAI. (2022). ChatGPT (Dec 20 vers ion) [Large language model]. 
https://chat.openai.com/  
 And a screenshot of the full thread of the cited AI interactions pasted to an Appendix . 
 
Student s might also go to Cite Them Right , which UEA has a license for to get further 
guidance.  
Staff Practice and Usage   
There are a number of ‘green light’ approaches which can be used by staff. These have 
been grouped as teaching design, content creation and assessment .   
  
Generative AI for teaching design  
Ideas for teaching design often come through speaking with colleagues and investigating the 
pedagogical literature. Generative AI can be used to generate lesson plans, surface new ideas and approaches.   An example creation is in Box 1 taken from biology.  
  
Box 1 
I asked ChatGPT the following question “create a discussion scenario for a seminar for 
higher education students in the area of single cell protein” .
 
 Discussion Points:  
1. Understanding Single- Cell Protein:  
• What exactly is single- cell protein (SCP), and how is it produced?  
• How does SCP compare nutritionally to traditional protein sources like meat, soy, and 
legumes?  
• What are the potential environmental benefits of SCP production, such as reduced land and water usage?  
2. Technological Advancements in SCP Production:  
• How has biotechnology and fermentation played a role in advancing SCP production?  
• Are there specific microorganisms that are more efficient at producing high- quali ty 
SCP?  
• What are the challenges associated with scaling up SCP production to meet global demand?  
3. Food Security and SCP:  
• How can SCP contribute to addressing food shortages in regions with limited resources?  
• Are there cultural or social barriers to adopting SCP as a protein source in different parts of the world?  
• What role can SCP play in sustainable diets and reducing malnutrition?  
4. Economic and Societal Impacts:  
• What is the economic feasibility of incorporating SCP into the food supply chain? 
• How migh t the growth of the SCP industry impact traditional livestock and agriculture 
sectors? 
Generative AI Guidance for Staff V0 2 
 
 5 • Are there potential job opportunities and challenges related to SCP production and 
distribution?  
5. Consumer Acceptance and Perception:  
• How can consumers be educated and  encouraged to embrace SCP as a viable 
protein source?  
• What are the psychological factors influencing consumer perceptions of SCP? 
• Are there lessons to be learned from the introduction of other alternative protein 
sources, like plant -based meats?  
6. Regula tory and Ethical Considerations:  
• What regulatory hurdles or standards need to be established for SCP production and 
marketing?  
• Are there ethical concerns regarding the use of microorganisms for mass protein 
production?  
• How might SCP intersect with debates about genetically modified organisms (GMOs) 
and bioengineering? 
7. Future Outlook for Single- Cell Protein:  
• What are the potential breakthroughs and innovations that could shape the future of 
SCP?  
• How can interdisciplinary collaboration drive resear ch and development in this field? 
• Can SCP play a pivotal role in achieving the United Nations' Sustainable 
Development Goals related to food security and sustainability? 
 My evaluation: The response was well considered, but it was more a discussion plan, t han 
a scenario.  There were interesting questions which I could use to frame a 50 minute 
discussion , using pair and share techniques or stakeholder role play.  
 
Generative AI for content creation  
Generative AI can support you in creating content for teaching. T his could involve generating 
case examples to illustrate concepts or problem -based scenarios which can be discussed in 
teaching sessions.  You could also use it to generate templates, for example letters.  
Diagrams and images can also be created, but the AI tools here are often paid for, and run 
the risk of copyright issues.  There are also tools which will generate online content, but they 
are not free, and unsupported by UEA.  
 
Assessment Creation  
Generative AI can be used to create assessment questions, e.g.  multiple choice questions , 
but these must be evaluated.  An example is shown in Box 2.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Box 2  
 
I asked the question “write a multiple choice question with 5 responses to test 
knowledge on lichen symbiosis and indicate the correct response”  
 
Question: Lichens are formed through a symbiotic association between fungi and which 
other type of organism?  
A) Algae  
B) Bacteria  
C) Proto zoa  
D) Ferns  
E) Mosses  
 Correct Response: A) Algae 
 
My evaluation: In this case the multiple choice question was wrong, as lichens can 
form associations with both algae and bacteria, but the incidences of the latter  are quite  
rare. The actual question was basic.  
 
Generative AI Guidance for Staff V0 2 
 
 6  
Another  example:  
 I asked ChatGPT to: ’write a multiple choice question with 4 responses to test knowledge on 
role played by the principle of separation of powers in the British constitution and indicate the correct response’  
 
Question: What role does the principle of separation of powers play in the British 
constitu tion? 
A) It ensures that the Prime Minister has absolute authority over the judiciary.  
B) It prevents the monarch from having any influence over the legislative process.  
C) It helps maintain a balance of power between the executive, legislative, and judicial 
branches.  
D) It grants the House of Commons the power to overrule decisions of the House of Lords.  
 
Correct Response: C) It helps maintain a balance of power between the executive, 
legislative, and judicial branches.  
 
My evaluation:  This was a fairly straightforward question and the incorrect answers were 
well chosen.  Whi lst ‘C’ was the closest to a correct answer it is not wholly accurate as it fails 
to acknowledge t he more nuanced balance of powers or partial separation which exists in 
the British constitution.  So whilst acceptable could also be used as a teaching tool to prompt 
a more in depth evaluation by the students.   
 
I then asked ChatGPT the question ‘To what extent is there separation of powers in the 
British constitution?’    
 
The concept of separation of powers, as traditionally seen in other constitutional systems like 
that of the United States, is not as rigidly defined in the British constitution. The British 
constitution is characterized by a fusion of powers, where the executive (Prime Minister and 
Cabinet), legislative (Parliament), and judicial (courts) branches are interconnected to some 
degree. Here's an overview of the extent of  separation of powers in the British constitution:  
 
• Executive and Legislative Branches:  Unlike some systems, the Prime Minister and 
Cabinet are drawn from the majority party in the House of Commons, which blurs the 
separation between the executive and legislative branches. This enables the 
executive to have significant influence and control over the legislative process.  
• Parliamentary Sovereignty:  The British Parliament is supreme and can make or 
change laws without significant limitations from other branches. While this provides 
some degree of separation, it also means that the executive (gov ernment) is 
accountable to the legislature, blurring the lines further.  
• Judiciary and Legislature:  The British judiciary is independent and can review laws 
and government actions for their legality and constitutionality. However, the judiciary's role in re viewing legislation passed by Parliament is limited compared to 
systems with a more robust separation of powers.  
• Cabinet Members in Parliament:  Members of the Cabinet are drawn from the 
Parliament, and this dual role further integrates the executive and legislative 
branches.  
• Constitutional Conventions and Royal Prerogatives:  The Crown still possesses 
certain prerogative powers that are exercised by the executive, which can influence 
the legislative process. However, many of these powers are now exercised by  
ministers in the government.  
 
Generative AI Guidance for Staff V0 2 
 
 7 In summary, while the British constitution lacks the strict separation of powers seen in some 
other systems, there are mechanisms in place to maintain a balance between the branches. 
The British tradition relies heavily on conventions, practices, and historical arrangements 
that have evolved over centuries. This fusion of powers is based on a delicate balance that 
seeks to prevent any one branch from becoming too dominant and to ensure accountability.  
 
My Evaluation: This answer was accurate, in so far as it relatively superficially correctly 
identified key elements of the principle as it operates in the UK.  It did not, however, provide 
any authority or specific examples to support so whilst correct would be insufficiently det ailed 
and too descriptive to obtain a good mark.  Again, this could work as a discussion exercise or a formative assessment task requiring students to improve upon the starting point 
provided below.   
 
 
Marking using Generative AI  
 Staff can use AI to do some aspects of marking for example:  
 
• Grouping and marking responses to short answer questions or multiple choice where 
AI functionality is part of a software package used to deliver an assessment and where there remains human oversight.   
 
However : 
 
• Gener ative AI cannot be used to obtain personalised student feedback on formative 
and summative assessment. Students can be encouraged to seek ongoing feedback on tasks and assignments, but the justification of a mark should be a human judgement.   
 
Assessment Design  
 There is no going back from this point. AI tools are only going to get better and we cannot 
outrun the pace of change. We need to re -think assessment design.  In the first instance staff 
should consider using Blooms Taxonomy within assessment design and use assessment to 
evidence higher order thinking skills around creation and evaluation where it is harder for AI 
to respond appropriately at this time. 
 
 
Generative AI Guidance for Staff V0 2 
 
 8  
  
There are two strategies for re -thinking assessment design:  
 
1. Designing out  
2. Designing in  
 
 
Designing out  
 
Alternative formats for assessment  
Summative assessment which solely focuses on writing down information is the most easily replicated by AI. Students could be asked to write podcasts or have assignments which 
require video or recorded speech. These approaches could be combined together in a 
multimedia project or portfolio.  
 
Oral/in person assessments 
Assessments which have an oral component, for example presentations, vivas, poster 
sessions and in class competency testing are not as easily replicated by AI. However it 
should be noted that there are some Generative A I tools which do produces images, 
diagrams and posters. Students could be asked to upload video of them talking t hrough a 
poster or an infographic.  
 Viva-voce assessments can be scalable with 5- 15-20 minute slots, feedback can be instant. 
A detailed marking rubric can be shared with students in advance. The sessions can be 
recorded and moderated. If you use this approach then you should consider ways to  scaffold 
the approach and train students progressively in this skill. You will also need to be aware of students with reasonable adjustments where a viva could not be an appropriate method of 
assessment.  
 

Generative AI Guidance for Staff V0 2 
 
 9 Object and data reflections  
Students can be asked to critically analyse  and reflect on pieces of data, they could interpret 
physical objects or artefacts. This could be in person, or it could be recorded.  
 
Experiential learning  
Students can be asked to work on case studies or problem based learning  activities  which 
require the generation of new knowledge, creative design or the development of products  or 
resources.  
 
Proctored assessments  
These are the use of invigilated exams or a test in class. However we would discourage the 
use of these unless there are str ong pedagogical reasons and are delivered as part of a 
suite of assessments to diversify experience.  
 
Designing In  
 
This is where we embrace generative AI within assessment tasks.  We must prepare our 
students for when they encounter AI in the workplace.  
 
Think of a task where s tudents are tasked to use generative AI to obtain a piece of writing on 
a specific topic  then:  
• Get the students to critique the output  in terms of structure  
• Ask the students to identify  the flaws  in the content for examples , hallucinations 
(false information) and bias  
• Ask the students to assess the content in the light of their own knowledge and understanding  
• Ask the students to follow up the references, see if they are genuine and if they reflect the key sources.  
 
You can also obtain answers to example test in class or exam questions to be shared with 
students to evaluate the strengths and weakness of generative AI content.  
 
If you would like more support in assessment design visit the CHERPPS  
PebblePad Training 
Page . 
 
Generative AI as mentor  
Encourage students to get ongoing feedback on assignments and tasks and get them to 
reflect on the feedback against their own knowledge and understanding and report on the 
guidance which has been provided and how they may or may not include it in their work.     
Where Generative AI should not be used  
 
There are a number of ‘red light’ activities where staff should not use Generative AI  
   
• Generation of letters to students or other staff including personal data and 
information.  This is because the software will store data and information and 
potentially use it for other content.   
• Generation of personalised student feedback on formative and summative 
assessment. Students can be encouraged to seek ongoing feedback on tasks and assignments, but the justification of a mark should be a human judgement.   
Generative AI Guidance for Staff V0 2 
 
 10  
 
Generative AI in Research  Projects  
 
Our students on taught programmes will be conducting research, especially in their final year 
of study.  
  
1. Students should not input  research data into an AI tool unless it is an agreed part of 
the research project.  
2. Students are required to obtain ethics approval before entering personal data into an 
AI tool  
3. Students  will need instruction on the difference between feeding a 
transcript/observation notes/participant diary into e.g. NVivo, and feeding it into AI 
which could use it to generate further material.  
 
 
Developing Graduate Attributes  as Relates to AI  
 When designing content and assessment we must consider learning outcomes and graduate 
attributes  as they related specifically to the use of AI.  
 
Critical thinking -thought and action  
Students should be able to take a piece of Generative AI text, diagram , image or code and 
check this against their own knowledge and understanding of a topic or area. They need to 
critically assess the origins  and the authenticity of the content.  
Self reflection  
Support students to  explore ways of using generative AI to identify ways that they could 
improve areas of feedback on previous assignments. Students can also use Generative AI to 
provide feedback on their work and identify areas for improvement at the editing stage.  
 
Digital literacy  
The use of AI in the workplace is going to expand and We should develop confidence in our students to be able to use AI tools, how to generate input questions to get the best outputs  
and evaluate what they do well, and where there are limitations.  
 
Integrity  
We should discuss with our students the ‘authorised green light’ activity when it comes to 
use of AI in assessment. Students should be encouraged to look at assessment briefs for specific assignments  and engage with discipline specific uses.  
 
Ethical awareness  
Students should be aware of issues such as job displacement, exploitation, authorship, bias 
and misinformation.  
 
Research skills  
Help students develop skills in identifying research questions, and assessing the outputs  
Problem solving. Students can generate outlines that are then used as the basis for deeper 
research and investigation. Encourage synthesis of sources by getting students to integrate 
other sources to support or refute generated output.  
 
Generative AI Guidance for Staff V0 2 
 
 11 Organisation  
Generative AI can be used to create study and work schedules allowing students to create 
personalised study plans or group work schedules. 
 
 
 
Acknowledgements  
 
We acknowledge the kind contribution which the University of St Andrews have 
made in allowing us to replicate some of the content fr om their staff guide.  
 
Further Resources  
  
 
There are plenty of ideas in the community on how to effectively use AI for teaching and 
learning, 101 creative ideas to use AI in education- a crowdsourced collection  is one 
example.  
 
Should AI be used to assess research?   
ChatGPT listed as author on re search papers   
Introduction to ChatGPT and ChatBots   
AI Tools Directory   
Trusted Research   
https://beta.jisc.ac.uk/blog/researchs -ai-future -is-nearly -here -are-we-ready ?"
41,Aston University,41_aston.rtf,https://www.aston.ac.uk/sites/default/files/AI%20Briefing%20notes%20for%20staff%20July%202024%20V2.0.docx,"Briefing notes: The application and use of AI in learning, teaching, and assessment
This document summarises Aston’s strategic position regarding AI (Artificial Intelligence) in learning, teaching, and assessment, and outlines guidance for staff including adaptable boiler-plate text for use in assessment guidance for students.
Key notes
Aston embraces the constructive application and use of generative AI, where relevant to programme and/or module learning outcomes.
Programme teams / module leaders are not compelled to permit use of generative AI in assessments if it is not deemed appropriate for learning outcomes and/or disciplinary norms/values.
Locus of control remains with programme teams / module tutors, through established QA/E processes, to determine effective approaches subject to and noting:
An overarching set of principles for assessment and a general AI code of conduct (See Appendix 1).
An overarching set of guidance for students (revised for September 2024 – See Appendix 2)
That “Misuse of AI” in assessment is already prohibited in the Academic Misconduct regulations.
It is the responsibility of those who design and set assessments to define what appropriate use and misuse of AI means for specific summative assessment tasks.
It is essential that, for every assessment, students clearly understand whether or not they are permitted to use generative AI, and if so, in what way(s). For every assessment, without exception, the status of the assessment regarding permitted/prohibited use of generative AI must be explicitly indicated to students in the assessment brief. This will always require messaging and guidance aligned with one of the following positions:
For this assessment, use of generative AI is essential. You must use AI, and here’s how (e.g., using a specific AI tool to fulfil a learning outcome)
For this assessment, use of generative AI is optional. You can use AI, but only in clearly specified ways (e.g., AI can be applied as a study aid)
For this assessment, use of generative AI is prohibited. You must not use AI, and here’s why (e.g., use of AI would contradict learning outcomes or disciplinary norms/values, or be incompatible with the assessment type)
It is the student’s responsibility to:
Ask if they are uncertain about the requirements of a learning activity or assessment.
Use AI critically and constructively in learning, but not to copy text generated from prompts into assessed work unless specifically required to.
Fully acknowledge use of generative AI when the use is permitted.  Note that guidance about citation and referencing is available via Cite Them Right.
Examples of constructive use include:
Generating a study plan or revision tests.
Summarising, reformatting, or translating text and notes.
Generating images and/or reformatting diagrams.
Generating feedback on ideas or work in progress.
Identifying spelling, grammar, and punctuation errors for editorial development. 
Engagement with educational platforms based on AI that you are directed to in a course of study (e.g., SimConverse). 
Example assessment brief texts
Essential:
For this assessment, use of generative AI is essential, as defined in this assessment brief. Any application or use of AI must always be acknowledged.
Optional:
For this assessment, use of generative AI is optional. It is appropriate, but not essential, to make constructive use of generative AI tools for this assignment. This should not include using AI to create the content of the assessment submission, but may, for example, include generating initial ideas, summarising notes or research articles, for translation, or creating a study plan. 
Any application or use of AI should always be acknowledged. Misuse of generative AI, as defined in Aston’s assessment regulations, will be treated as an academic offence and may be subject to disciplinary action.
Prohibited:
This assessment has been designed to support your learning. Use of AI could undermine this. Therefore, for this assessment, use of generative AI is prohibited. 
Reasons why AI should not be used may include:
Risk of undermining the intended learning (e.g., critical thinking, problem solving, creativity).
Negative impact on other related assessment activities where access to AI will not be possible and/or where specific application of AI is a planned ‘next step’. 
Known/potential unreliability of AI in the area of study.
You must not use generative AI technology to support your work on this assessment in any way. Misuse of generative AI, as defined in Aston’s assessment regulations, will be treated as an academic offence and may be subject to disciplinary action.


Appendix 1 – Principles and code of conduct for AI at Aston
Principles of engagement with AI in assessment
Aston should be actively engaged with the implications and applications of AI through leadership by disciplinary experts and partnership with students.
AI should be an active consideration in the promotion of good academic practice and as part of an assessment for learning approach. 
AI should form a key point of focus in information and guidance for students in developing assessment literacy.
AI should inform approaches to formative and summative assessment design through a focus on authentic assessment. 
AI should be utilised in supporting consistency of approach to underpinning monitoring and assurance of academic integrity/malpractice.
Code of conduct for AI at Aston
Application and use of AI in learning, research, and assessment at Aston should be:
Transparent
Use of AI tools should be disclosed – especially when applied in the generation of content. 
Appropriate application and use of AI tools should be clearly specified for learners and researchers. 
Collegiate
Use of AI tools should be discussed and shared with colleagues.
Experiences of AI and relevant insights should be shared with colleagues. 
Constructive and discipline situated
Developmental approaches to use of AI tools should be clearly specified for learners and researchers. 
Application of AI should be explored wherever benefits may be realised, and disciplinary implications actively considered. 
Creative
Subject to adherence to other principles, there is open license and scope to explore new ways of doing things. ‘Not sure’ need not be a barrier. Aston should be at the forefront in making use of AI. 
Ethical
Involving active consideration of all risks of harm including, where relevant, completion of formal processes of approval. 
Aston will maintain robust approaches to the assurance of academic integrity.




Appendix 2 – Guidance notes for students (from Sept 2024)
Aston recognises the value of assistive technologies and encourages all students to embrace the constructive use of technology in study. 
This includes the application and use of Artificial Intelligence (AI) tools.  
Check with your tutors if you are not sure whether you are allowed to use generative AI to support your work on an assessment. How to approach your learning and assessment will always be clearly outlined in your programme and module handbooks, and assessment briefs. 
From planning in study to support for translation or summary of research articles, AI tools can be positively applied in increasingly sophisticated ways. 
When permitted to use AI in an assessment, use it as a starting point to assist and/or structure your thinking rather than a solution to replace your thinking. For example, ‘Write me a 5-point plan for how to develop a literature review for a university engineering degree’ can be an extremely helpful prompt at the start of a learning activity, whereas ‘write a 2000-word literature review about ‘X’ could actively undermine your learning.
If you are permitted to use AI in an assessment, be mindful of the known limitations of AI tools and approach their application and use critically and in conjunction with information and support from other sources.
As with all scholarship and research, it is extremely important to reference sources of information and content including the use of AI. E.g., (OpenAI's ChatGPT AI [Large Language Model], personal communication, 31 March 2023). 
Ensure that work submitted for assessment purposes is your own work and that you are aware of the University’s Assessment Regulations including the Student Code of Conduct (Assessment). Note particularly the Student Declaration for assessments which includes the following: 
“I declare that I have personally prepared this assignment. The work is my own, carried out personally by me unless otherwise stated and has not been generated using Artificial Intelligence tools unless specified as a clearly stated approved component of the assessment brief.” 
Note that Aston uses a variety of approaches to ensure the integrity of academic awards including tools that can reveal the use of AI. You will always be safe to make mistakes in your studies/assessments if you fully acknowledge your working practices and information sources and engage with available support. 
Approach the use of AI responsibly and constructively. Positive application has the potential to greatly enrich learning. Deliberate misuse such as submitting unacknowledged AI generated content as your own for an assessment is a serious breach of Aston’s regulations and could lead to significant penalties being applied."
42,Aberystwyth University,42_Aberystwyth.rtf,https://www.aber.ac.uk/en/is/regulations/guidance-on-ai/,"General Guidance on the Safe use of AI
1.0 Introduction and scope
AU recognises the importance of using generative AI in education and is committed to its responsible, ethical and appropriate use in teaching and learning, research, and administration.
The ethical use of AI tools can provide significant benefits and their use will undoubtedly become more commonplace in the next few years. However, there are some clear risks and security concerns in employing generative AI.  The following guidance highlights these threats and is intended as a high-level guide to best practice when using, primarily, generative AI tools across a range of activities, such as academic research and administration within a higher education environment.
 It should also be noted that existing policies and procedures will apply to some of the situations described below. All AU IT systems users should familiarise themselves with this document and recognise that they are ultimately responsible for:
The output of any AI tool they seek to make use of;
Ensuring the quality of their own work in relation to AI use;
Educating themselves about how that AI tool is trained and the appropriateness of their choice of AI tool.
 
2.0 Teaching and learning
For use of AI specifically in teaching and learning contexts, see:
Guide to best practice(""https://libguides.aber.ac.uk/c.php?g=676952&p=5126956"")
Utilising AI in the Library(""https://libguides.aber.ac.uk/artificial-intelligence"")
Where use of AI constitutes Unacceptable Academic Practice(""https://www.aber.ac.uk/en/academic-registry/handbook/regulations/uap/"")
LTEU Blog(""https://wordpress.aber.ac.uk/e-learning/"") including AI updates
 
3.0 Risks to confidentiality
AI tools are trained on, and capture, vast amounts of pre-existing data and any data which you may have provided when using the tool. If you share any personal or sensitive (‘special category’) data with any generative AI platform, it may be accessible by the service provider, its partners and sub-contractors and also has the potential to become publicly available.  You may well be breaching data protection legislation in this or other ways. Do not share such data with AI tools, particularly when third party AI generative services are being used.  See 5.6 below for further details.
The University’s policies and procedures on data protection(""https://www.aber.ac.uk/en/about-us/corporate-information/information-governance/data-protection/policy/"") will apply in these cases
 
4.0 Copyright / Intellectual Property / confidential business data
The University holds and processes a great deal of information which is business critical, commercially valuable, and highly sensitive.  In some cases, it comprises the intellectual property of the University, and such categories of data or documentation should not be supplied to generative AI tools.  Similarly, textual works may be copyright of the university or of its staff and similarly should not be input into third party generative AI tools.  You should also respect the copyright of third parties, such as authors whose works are held by the library or are part of online subscriptions available to AU staff and students.  Legal responsibility for copyright infringement is likely to lie with the user, not the generative AI tool.
The following policies apply here:
Copyright (""https://www.aber.ac.uk/en/is/regulations/copyright/"")
Intellectual Property Policy(""https://www.aber.ac.uk/en/media/departmental/rbi/documents/IP-Policy.pdf"")
 
5.0 Good practice when using AI
5.1 Use of Copilot and  ‘third party’  tools
AU has access to Microsoft’s Copilot which is safe and fully licensed for use.  This should be the primary option for those wishing to use AI for University business. 
Other third-party AI tools need to be approved for AU use using the established security clearance procedures set out in the Cloud Service Security Policy(""https://www.aber.ac.uk/en/is/regulations/saas/"")
 
5.2 Transparency and responsibility
Where at all possible, the use of AI should be transparent and explainable. Be clear when you have used AI and the reasons for its use whether in developing teaching and assessment activities, research or administration. This can help to promote academic integrity and prevent any misunderstandings or ethical issues.
Individuals and groups using AI technologies are responsible for their actions and must use AI in a responsible and ethical manner.
 
5.3 Read the ‘Terms and Conditions’
Always familiarise yourself with the Terms and Conditions of any AI tool in order to understand what it does with submitted data, conditions of usage and ownership, the limitations of the tool, potential biases, and any options which are offered to you (such as disallowing the retention of data).
 
5.4 Reporting
Be prepared to report(""https://www.aber.ac.uk/en/is/regulations/offence/"") any misuse of AI technology or any results from AI tools which might breach University rules or UK legislation.
 
5.5 Broader ethical issues
Be aware that there may be wider ethical implications of using certain AI tools.  Some are highlighted below.
Potential inherent biases due to the training data/models used, including biases on gender, race, religion, sexuality, disability, and geo-politics, among others. 
AI which is trained on copyrighted images, texts, music and code, which are then remixed/reproduced without compensation to the original creator.
Use of AI trained on non-profit resources used for commercial output.
Data labelling in poorer countries done by underpaid workers.
Environmental impact of AI data centres using significant amounts of power, based in areas where there is little green energy.
 
5.6 Avoid using certain data
Some organisations prohibit the use of the following data categories in any AI processes:
Passwords and usernames.
Personally identifiable information (PII) or other sensitive or confidential material, irrespective of any perceived lawful basis, including explicit consent. PII is any information that can be used to confirm or corroborate a person’s identity.
Any data that hasn't been properly anonymised to ensure it is non-identifiable.
Any data that is not fully consistent with the University’s policies on Data Protection, Data Processing, GDPR/DPA2018, Academic Integrity, Attribution and Ethics.
Any data related to University Intellectual Property.
Any data that is protected by copyright, unless it aligns with principles like fair use, educational exceptions, or if explicit permission has been granted.
Any prompts or data, whose responses might result in reputational damage to Aberystwyth University
Any non-PII data from third parties where the individual has not explicitly consented for their data to be used with AI, with the exception of data that is clearly already in the public domain.
 
Should you wish to use any of the above data in conjunction with AI, you must contact Information Services(""https://www.aber.ac.uk/en/is/help/contactus/"") for advice beforehand.
 
Approved Aug 2024.  Due for review Sept 2025
About Us(""https://www.aber.ac.uk/en/is/about/"")
AU Service Status(""https://status.aber.ac.uk/"")
News & Events(""https://www.aber.ac.uk/en/is/news/"")
Opening Hours(""https://www.aber.ac.uk/en/is/about/opening-hours/"")
Primo - the library catalogue(""https://primo.aber.ac.uk/primo-explore/search?vid=44WHELF_ABW_VU1&lang=en_GB"")
Library Services(""https://www.aber.ac.uk/en/is/library-services/"")
IT Services(""https://www.aber.ac.uk/en/is/it-services/"")
Help and Support(""https://www.aber.ac.uk/en/is/help/"")
FAQs(""https://www.aber.ac.uk/en/is/faq/"")
Feedback and Actions(""https://www.aber.ac.uk/en/is/feedback/"")
Services for Researchers(""https://libguides.aber.ac.uk/researchers"")
AberSkills(""https://www.aber.ac.uk/en/aberskills/"")
Library Floor Map(""https://wagnerguide.com/c/aberystwyth/map"")
Services for Visitors(""https://www.aber.ac.uk/en/is/visitors/"")
Staff Profiles(""https://www.aber.ac.uk/en/is/staff-profiles/"")
Contact Us(""https://www.aber.ac.uk/en/is/help/contactus/"")
Contact for this page:
Information Services, Aberystwyth University, Hugh Owen Library, Penglais, Aberystwyth, SY23 3DZ
Tel: 01970 62 2400 Email: is@aber.ac.uk(""mailto:is@aber.ac.uk"")"
43,Keele University,43_keele.pdf,https://www.keele.ac.uk/media/keeleuniversity/policyzone20/studentandacademicservices/AI-in-Education-Framework-2025-1.pdf,"Page 1 of 6 
  
GENERATIVE AI IN  EDUCATION  FRAMEWORK  
Introduction  
 
Generative Artificial Intelligence ( GAI) refers to AI systems capable of generating new 
content in response to input data . Generative AI is a sub -set of AI; where AI focuses on 
problem -solving, data analysis and predictions, Generative AI uses algorithms to generate 
content based on vast datasets, generating text, images, music and code from prompts.  
 AI Tools are transforming not just education but the workplace  and will form a key 
component of both going forward; our graduates will be entering a world where Generative 
AI is the norm.  AI is already embedded into everyday tools and services such as 
spreadsheets, email, and web search  which can make it difficult to distinguish when Gen AI 
is used part of academic work.  
 
However, w hilst it is important to recognise that  AI can pose  risks  in areas such as academic 
misconduct, it also has the potential to provide  significant benefits .  As an institution our 
approach t o AI is to be  risk-aware not risk averse , and  to educate ourselves about the 
opportunities and risks that Gen AI presents to discover how we can deliver future -facing 
real- world learning experiences , enhance student employability skills  and support  
inclusivity,  widening access and participation.  
 
Whil st we need to  explor e the opportunities AI brings, we  also need to  ensure that staff and 
students are supported to  use it responsibly and safely.  This framework sets the expectation 
that w e embed appropriate use of generative AI into our teaching , learning and assessment 
practices , to enable pedagogic innovation and to support inclusive education. In doing so, 
we should always  prioritise human -centred creativity to support ethical use  and maintain 
academic integrity . This means moving beyond using AI to provide access to information 
and summarising responses  and towards  developing  inquiry -based  learning , reflective 
practice and critical thinking skills.  
 
1. Purpose  
 1.1 This framework  is intended to ensure  that AI  in education is used responsibly, ethically, 
and equitably within Keele.  It aims to support the integration of Generative AI in education 
and development and embedding of foundational AI literacies across staﬀ and students , 
ensuring that both staff and students are AI -literate  and able to use AI in an ethically 
responsibl e way.  
 

Page 2 of 6 
 Based on the Generative AI principles , the framework outlines  approaches to the use of 
Generative  AI in Education and aims to ensure a more consistent approach  of AI 
implementation  in teaching, learning and assessment . By promoting AI literacy, upholding 
academic integrity, we aim to foster a learning environment that leverages the full potential 
of AI while maintaining fairness and academic standards.   
1.2 The framework should be used in conjunction with other relevant guidance  including the 
Assessment and Feedback Code of Practice , the Keele Learning Principles  and the Inclusive 
Education Framework . Use of Generative AI in teaching , learning and assessment must 
comply with associated University Codes of Practice , Guidance, Policies  and Procedures , a 
list of which are provided at the end of this document.    
1.3 This framework will evolve as the use of AI in education develops. Keele is committed to regular review and updates to keep pace with technological advancements and ensure best 
practices are followed.  
 
2. Scope  
 
This framework is based on six  high -level  principles  that guide  Keele’s approach to 
Generative AI . These principles have been informed by the five principles agreed by the 
Russell Group  in 2023 to enable  universities ensure students and staff are ‘AI literate’.  
The six  principles are :  
• Staﬀ and Students will be supported to become more AI Literate  
• Students will be supported to use Gen AI tools ethically and appropriately in their 
learning  
• Staff will be supported to adapt their teaching learning and assessment methods to 
incorporate ethical use of Gen AI  
• Staff and students will have fair access to Gen AI tools and resources needed for teaching and learning  
• Academic integrity will be upheld in all assessments and associated policies will be 
reviewed regularly as generative AI tools develop  
• Best practice will be shared across and beyond the institution as technology  and the 
application of technology  in education develops.   
 
3. Framework  
 
3.1 Staff and Students will be supported to  become more AI Literate 
3.1.1 Generative AI literacy is essential for students and staff to fully engage with and 
understand the benefits and challenges of generative AI tools . Being AI -literate means 
having the requisite knowledge, skills  and capabilities to explore and critically evaluate AI -
Page 3 of 6 
 generated outputs. Staff are expected to have the necessary foundational level knowledge 
and skills to use generative AI tools effectively and responsibly as appropriate for their 
discipline , including understanding what AI technology is and how AI models are trained. The  AI 
Competency Framework  sets out expectations on  foundational skills and knowledge  for staﬀ . 
3.1.2 It is important to understand the diﬀerence between AI and Generative AI. Prompting 
skills are very important in Generative AI (GenAI); that is the  ability to craft eﬀective inputs 
(prompts) that guide GenAI models to produce desired outputs  and ultimately  determine 
the quality and relevance of the AI's output.  As a minimum, the expectation of all staﬀ  
responsible for delivery of teaching and learning is to  ensure they are proﬁcient in critical 
prompting skills and to test the pedagogical implications of prompts prior to  any use in  
teaching delivery  or assessment design.  Provision should be made to support students in 
crafting eﬀective prompts and reﬁning AI content to improve their ﬁnal output.  The 
Assessment and Feedback Code of Practice  sets out expectations for use of AI  in 
Assessment.  
3.1.3 Use of AI in education should always be underpinned by a human- centred approach 
highlighting the importance of human agency  and focused on strengthening human 
capabilities , for example developing human employability skills (creativity, decision -making, 
empathy, problem -solving, communication and collaboration ) when interacting with 
Generative AI and through exploration of real- world AI applications.  The AI enhanced ABC 
Learning Design framework  is intended to support staff  when designing AI enhanced 
learning activities.  
3.2 Students will be supported to use AI tools ethically and appropriate in their learning  
3.2.1 Staff have a responsibility to ensure that students  are supported to  use generative AI 
tools ethically and responsibly, with an understanding of academic integrity  as outlined in 
the Academic Misconduct Code of Practice  and the implications of AI -generated content  
particularly regarding  their discipline.  
3.2.2 Staff should encourage exploration of ethical issues related to AI, such as bias, 
deepfakes, copyright infringement, data security and privacy, with a focus on AI -augmented 
human creativity. Students should be supported to understand the ethical use of generative 
AI tools, that enhance the learning experience, not replace their own work.  
3.2.3 Staff should ensure students are provided with guidance on the ethical use of 
generative AI  through signposting  students  to the Gen AI academic skills guidance  . It is 
recommended to undertake a specific  learning activity on ethics in module delivery, for 
example covering the responsible use of AI tools, awareness of biases, and the potential for 
misuse.   
 3.2.4 Staff should remind students that they must disclose when AI tools have been used in 
their work , that they  require proper citation  and refer them to the Academic Misconduct 
Code of Practice  
3.2.5 Staﬀ  should be careful to manage “cognitive oﬄoading”  through a balance of AI and 
non-AI activities. Cognitive oﬄoading is this context is  where studies show that students 
Page 4 of 6 
 using AI assistants may perform better than those with traditional assistance (such as paper -
based handouts) while they rely on AI, but that they learn less and perform less well when 
the AI is removed.  
3.3 Staff will be supported to adapt their teaching learning and assessment methods to 
incorporate ethical use of Gen AI  
3.3.1 Active Learning is one of our Curriculum Expectations  and we should explore how AI 
can support active learning and collaboration either during  synchronous sessions , in person 
or online or as part of asynchronous activities, for example to support group work, inquiry -
based learning, discussion or formative feedback.    
3.3.2Integration of AI tools should involve appropriate scaffolding , providing students with 
activities and resources that help them understand the capabilities and limitations of AI and ensuring students can practice necessary skills. Identify key opportunities to introduce or discuss AI concepts and applications, using case studies and examples to illustrate them.  
3.3.3 Assessment methods should be revi ewed to ensure that they remain  fair, transparent, 
and resistant to the misuse of AI. Staﬀ  should consider how AI can provide  opportunities for 
more authentic assessment types, to enable personalisation and to potentially reduce over -
assessing. AI tools and outputs must be tested before assessment design to understand their 
capabilities  and limitations .  
3.3 .4 AI provides a signiﬁcant opportunity to develop and enhance critical evaluation skills in 
students, for example , evaluating AI -generated output(s) based on accuracy, relevance, 
credibility, and potential bias.  AI models are only as good as the data they are trained on; if 
the training data is biased, the output will likely reﬂect that bias; the output may not be relevant to the prompt, may contain errors and may draw on unreliable or out of date sources. Respon sible use means critically evaluating AI in this way and ensures AI outputs 
are managed eﬀectively and responsibly.  A starting point would be to identify ke y skills 
required relating to the use of AI in a subject speciﬁc context and to foster critical evaluation of AI outputs.  
3.3.5 Students must be advised on how AI can be  used in assessmen ts, and this must be 
clearly stated, as outlined in the Assessment and Feedback Code of Practice   
3.3.6 AI can enhance and diversify learning and teaching to make it more inclusive. We 
should consider how appropriate use of AI supports the expectations set out in the Inclusive 
Education Framework  in the design of teaching and learning activities and learning 
resources . We should ensure that assessments using AI remain inclusive and do not alienate 
students who have legitimate concerns, whether they are philosophical, ethical, environmental or cultural. Where AI is used it must be to support learning, not as a replacement  for it.   
3.3.7 AI resources can be used to enhance and demonstrate the value of formative 
approaches to assessment, the process of learning as well as outcomes. When developing assessments, staﬀ are encouraged to c onsider activities that explore opportunities and 
challenges of AI, e.g. discussions on ethical implications, societal and environmental impact; 
Page 5 of 6 
 activities encouraging students to identify potential biases in AI  outputs and assess the 
credibility  and reliability of online sources  and the role of intellectual property ( IP).  
3.4 Staff and students will have fair access to Gen AI tools and resources needed for 
teaching and learning   
3.4.1 Staff should  ensu re equitable access to generative AI tools and resources for all 
students regardless of background, location, or personal financial situation ; ensuring all staff 
and students have the necessary resources for teaching and learning  and removing  potential 
barriers such as  economic disadvantage or digital accessibility, to ensure inclusivity in AI 
adoption.  For this reason, it is recommended that s taff use institutional  Gen AI tools , for 
example Microsoft Copilot,  that comply with GDPR and relevant privacy regulations.  
3.4.2 Staff must communicate to students the AI tools and platforms that are available to 
them and e nsure that inclusive approaches are followed , such as students with diverse 
needs (e.g., disabilities or those from low -income backgrounds) have access to AI tools and 
assistive technologies.   
3.4.3 Staﬀ should make students aware that AI is already integrated into the key tools used 
by the university; for example, Microsoft Oﬃce 365 deploys AI in email and PowerPoint and 
AI is embedded into the KLE along with other third -party tools that the university uses for 
teaching and learning.  M icrosoft Copilot is the  institutional tool available free to staﬀ and 
students as part of the MS Oﬃce 365 suite. Use of other AI tools must consider accessibility 
and equitable access along with GDPR and data privacy.   
 3.5 Academic integrity will be upheld in all assessments and associated policies will be 
reviewed regularly as generative AI tools develop  
3.5.1 Assessment methods should be reviewed regularly to ensure that they continue to 
adapt to the growing presence and capabilities of generative AI tools , to reduce 
vulnerabilities to AI misuse while promoting authentic learning.  
3.5.2 AI-driven content must be treated with transparency, ensuring that students are not 
penalised for using AI responsibly.  
3.6 Best practice will be shared across and beyond the institution as technology  and the 
application of technology  in education develops.   
3.6.1 Our ethos is to support a culture of collaboration and innovation and to develop 
scholarship in AI.  We will communicate  best practice in AI in teaching and learning  across 
the institution, disseminating  internal case studies via the intranet and through workshops 
and guidance.   Staff will be supported through the launch of a new self -enrol AI for 
Educators  course on Blackboard Ultra, AI Exploration days and workshops on Critical AI 
Literacy including assessment, active learning and ethical use.  
3.6.2 Staff should ensure there are regular feedback loops from students to inform ongoing 
improvements in AI adoption  in teaching and learning and assessment.  
Page 6 of 6 
 3.6.3 Through engaging with sector wide  institutions and academic networks we will learn 
from others’ experience in order to  stay ahead of AI trends in education and update our 
resources and academic development training accordingly.  
 
4. Related Policies and Procedures  
 4.1 Related Policies   
Captured Content  
IT Acceptable Use   
Data Classification and Handling Policy   
Information Security Policy   
  
4.2 Relevant Codes of Practice  
Assessment and Feedback Code of Practice   
Inclusive Education Framework   
  
4.3 Relevant Guidance  
Keele AI Principles in Education   
Use of Gen AI in Higher Education  
Keele Learning Principles   
Student Guidance on Academic Integrity   
Gen AI Guidance for Students   
  
5. Support and Resources  (KIITE)  
  
AI for Educators course on Blackboard Ultra   
AI (Learning Innovation Technology) Teams Channel  
AI Resource Hub (Sharepoint)"
44,University of Essex,44_Essex.rtf,https://www.essex.ac.uk/student/academic-offences/artificial-intelligence,"Artificial intelligence guidance
Artificial Intelligence, or AI, is a term used to describe machine-implemented abilities to reason, plan, solve problems, think abstractly, comprehend complex ideas, learn quickly or learn from experience.
Generative AI
Generative AI is a type of AI that creates new content or data. Recent developments mean that Generative AI is very easy to access and use without specialist training for example through applications such as ChatGPT, Bard, Claude and Bing. For example, ChatGPT could be asked to explain how a combustion engine works and it will return a well-written coherent written answer. Applications like DALL-E can even create images based on a written description provided by the user. For example, you could request a water-painting of a sailing boat on calm waters with snow-capped mountains in the background and it will create a new image fitting that description.
The University's position on AI
Generative AI technology will certainly be something that you encounter in your personal and professional lives long after you have graduated. At Essex, we want you to explore generative AI tools responsibly. But when you use these tools, remember to think about things like keeping your data safe, respecting copyrights, and being honest in your academic work. We hope that by the time you graduate, you will have developed the knowledge and skills to be able to use AI effectively and ethically to support your learning and help you succeed in the future.
Limitations of AI
Text-based responses that generative AI produces are well-written and can appear convincing. However, generative AI learns from historic internet-based material which can be out of date or unreliable. Sometimes this means generative AI presents information that is not correct. Other known limitations of generative AI are that it can create fictitious citations, make up facts, express biased views, give weak responses about nuanced, contextual, or contemporary matters for which there is often little or no accurate web-based information for it to draw upon. These errors are often difficult to spot and therefore never assume that the content created by generative AI is accurate, up to date or true unless you know it to be so or have verified it through another reliable source. You are always responsible for determining the accuracy of what you write.
Using AI with your learning
It is important to realise that AI’s most useful application is to augment rather than replace human intellectual and creative thinking. There are many legitimate ways in which you can use AI to help you study and learn. We encourage you to use AI tools to develop an understanding of its strengths and limitations, and the skills to use AI ethically and effectively.
Here are a few examples of how AI could be used to help with your learning:
creating an essay plan to help you develop and improve the structure of your assignment
using AI to help you improve your grammar or your writing style by looking at how it constructs answers to questions
asking AI to explain a concept, theory, or text that you have had trouble understanding. Providing the explanation is used to help you understand and is not copied into your assignment, you will not be committing any academic offence. however…
never assume the information generated by AI is accurate or true. Check it.
AI can't be used to write assessments
Writing your own assignments is the only way in which you will develop the skill of communicating effectively in written form. It is also a key pathway for developing your skills more broadly, including the key abilities of developing, formulating, expressing, and testing your own ideas. You will be cheating yourself if you don’t use your time at university to develop those skills by writing your own assignments – whether with or without assistance from digital tools including AI.
What would be cheating?
Providing you do not attempt to pass off AI generated material off as your own work, you will not be cheating and will not have committed any academic offences. Under 1.2c of our current Academic Offences Procedures the following would constitute an academic offence:
“…false authorship or contract cheating, including the soliciting of a third party or the use of artificial intelligence, machine learning or other automated technology, to produce material that is then submitted for assessment and presented as one’s own original work.”
How to avoid an academic offence
Always cite and reference material included in your assignments that is not your own work.
Never present AI generated work as your own in an assignment. That would be cheating. Your lecturers and teachers will give you more specific instructions but in general you will be expected to include information about how you have used AI as part of your assignment submissions.
Never ask AI to generate experimental data which you then submit having purported to have collected it yourself as primary data, either in raw form or after analysis. This is fabrication and counts as serious misconduct.
When you are preparing an assignment, it is a good idea to keep notes that you make along the way and try to keep different versions saved as separate files as your work develops. Should you be suspected of committing an academic offence you will be able to use such notes and archived files to demonstrate how you have constructed the assignment.
Be transparent about which tools you use and how you have used them to create your academic work.
Find help on academic skills(""https://www.essex.ac.uk/student/academic-skills""), including referencing.
Read the guidance on academic offences and academic integrity(""https://www.essex.ac.uk/student/exams-and-coursework#academic-offences"")."
45,University of Sussex,45_Sussex.rtf,https://www.sussex.ac.uk/skills-hub/writing-and-assessments/ai,"Using generative AI in your assessments
What is generative AI?
Generative AI includes a range of tools which can generate human like responses to questions and prompts (this guide will focus on text-based tools). Tools like ChatGPT and Microsoft Copilot are large language models (LLMs), which are trained using large amounts of text to predict the next most likely word. Large Language models learn to understand the statistical relationships between common sequences of characters (tokens), and can then produce the next character in a sequence. This means that the writing they produce is based on probability not understanding i.e. which word is most likely to follow another. Models are trained on data from webpages, social media and other online content.
Generative AI’s are very good at creating new content quickly, however, it's important to be aware that AI models frequently produce responses that look plausible but contain factual errors. In the case of an assessment this would result in you receiving a poor mark or potentially failing an assignment. Outputs should always be critically evaluated.
Some examples of Generative AI tools for text creation are:
ChatGPT
Gemini
Claude
CoPilot

How do I access Microsoft CoPilot?
Microsoft CoPilot(""https://copilot.microsoft.com/"") is now available for University of Sussex students. To access go to the Microsoft Copilot website and then follow the steps below to sign in:
		Select the Sign in option in the top right-hand corner of the page
		Within the submenu that appears select Sign in with a work or school account
		Sign in when prompted with your Sussex account details
The University’s subscription doesn’t retain prompts and responses, aren’t used as part of the models training and the data is encrypted. Please note that Copilot is currently only supported within Chrome or Edge browsers.
 

What are the limitations of AI?
Reliability: AI models produce plausible and well-written responses, however, frequently make factual errors (referred to as “hallucinations”), make up quotes and citations, only present one side of an argument. This means that they are not suitable for unmediated use in academic work. Remember that increasingly generative AIs are being used to create content for the web including fake new and deep fakes.
Currency: Generative AI’s knowledge isn’t necessarily up-to-date, so wouldn’t always be able to give you reliable information about current events.
Specialist areas: They perform better in subjects that are widely written about, and less well in niche or specialist areas.
Bias: Generative AIs are not free from bias. Models will preference Western viewpoints and can perpetuate harmful stereotypes and biases. Tools like ChatGPT, Google Gemini, MS Copilot are trained on data created by humans and primarily in English data scraped from the internet. There are also concerns that as AIs generate more and more content for the internet this same content will be used to train models and lead to degeneration and a loss of diversity.
Ethics: In some cases AI tools have been trained on unlicensed information without the consent of the author. Models will also use your data to train themselves unless you opt out. AIs outputs are often checked by human reviewers (known as Reinforcement Learning from Human Feedback) to ensure responses are accurate and appropriate. This has raised some ethical concerns around the working conditions of content moderators.
Access/Equity: The full functionality of AI tools are usually only available via subscription, which we would discourage anyone from doing on an individual basis.
Privacy: It’s important not to share personal/private information with AI tools. Some tools allow you to opt out of using your conversations to train the algorithm.
It’s important to remember that anyone can put anything on the internet, therefore, it’s likely that Generative AI models have been trained on incorrect, biased and copyrighted information. You always need to be critical of sources. There are lots of resources available on Skills Hub on Critical Thinking. One approach to evaluating sources is the CRAAP test(""https://www.sussex.ac.uk/skills-hub/critical-thinking#Critically"").
 

Can I use generative AI to edit or proofread my assessments?
If you ask someone to proofread your work, they can only make minor suggestions about grammar, vocabulary, expression, and word order. They cannot make changes directly to your work as the general principle of any contributory (summative) assessment is that the structure, argumentation, content, analysis and conclusions are wholly your own, unless properly cited and acknowledged to the original source.
The same rules apply to using AI tools like ChatGPT or advanced features in Grammarly. The use of a proofreader or AI tool to generate an assignment (or part of an assignment) and submit this as if it is all your own work will be regarded as academic misconduct.
A proofreader (person or AI) may not:
rewrite sections where argumentation or logic is unclear,
rewrite sections to improve paraphrasing,
rearrange paragraphs and sentences with the intention of improving structure,
rearrange paragraphs and sentences with the intention of improving the argument,
correct calculations, data, or factual errors etc,
make substantial changes or correction to the references and bibliography.
A proofreader (person or AI) may:
identify errors in grammar, vocabulary, expression and word order, only making specific minor suggestions where the communication is clear,
highlight areas where communication is unclear or where there is inconsistent use of a referencing system.
A proofreader may not be used for assessments where the use of language and the formal accuracy of the work form part of the mark.
Any suggestions made by a person or an AI proofreading your work should be retained in case of any concerns about academic misconduct. We recommend saving and writing your assignments using your University of Sussex OneDrive(""https://www.sussex.ac.uk/its/onedrive"") account as this will automatically keep version history.
Students registered with the Disability Advice team and in receipt of reasonable adjustments are still permitted to use other assistive technology as recommended by the University in their Learning Support Plan.
Support and guidance available:
Skills Hub for more guidance on proofreading(""https://www.sussex.ac.uk/skills-hub/writing-and-assessments/academic-writing-style#proofreading"")
Academic Misconduct guidance(""https://student.sussex.ac.uk/complaints/against-you/misconduct"")
 

Can I use Grammarly?
It's fine to use Grammarly to improve basic grammar, spelling and punctuation errors. However, you should not use Grammarly's generative AI features to meaningfully change your work. The same restrictions apply to Grammarly as they do to a proofreader, and you should think carefully about which changes you accept, as it remains your responsibility to ensure the accuracy of your work.

Can I use generative AI tools to translate my work?
Using AI to translate your work into English, or another language will be regarded as academic misconduct. It is important to note that minor (single word) translation is permitted, however, translating substantial sections of text is not.
All work submitted for assessment should be your own work and prepared in the language required by the assessment and must not be translated by a third party (person or AI).
If a translation service is required for an assessment, you will be required to confirm the section/s of the assessment that have been translated and whether they were translated by yourself or someone/something else. More
If you need support with writing, there is additional support available:
English Language for Academic Study (ELAS) offers workshops and 1-2-1 support(""https://direct.sussex.ac.uk/page.php?realm=study&page=scls"") for students working in English as an additional language.
Writing Support is available through:
Academic Skills Workshops and Webinars(""https://www.sussex.ac.uk/skills-hub/starting-at-sussex/workshops#skills"")
One-to-one writing Support with the Royal Literary Fund’s Fellows(""https://www.sussex.ac.uk/skills-hub/starting-at-sussex/workshops#rlf"")
There may also be writing support available through your School/Department.
 

Can I use generative AI to write my assessments?
If the use of AI has been permitted by your school in a particular module or assessment task then this will be stated clearly in your assessment guidance. Currently, in most modules, it is not permitted. See the following section for more guidance.
It’s important to remember that in written submissions if a person or AI other than yourself prepares the work, part of the work, or provides substantial assistance with work submitted this would be considered academic misconduct.
This includes but is not limited to:
AI generated text or responses
Purchasing essays from essay banks
Commissioning someone else to write an assessment
Writing an assessment for someone else (including where no benefit is gained by the student producing the assessment)
It’s important to remember that all work submitted for assessment should be your own work and all sources of information used in preparing must be fully acknowledged.
Remember, any action that gives you an unfair advantage in an assessment or exam is considered academic misconduct. See Skills Hub for more guidance on referencing and academic integrity(""https://www.sussex.ac.uk/skills-hub/referencing-and-academic-integrity/"").

Can I use AI tools to find references for my essays?
Large Language Models (LLMs), like ChatGPT, are not databases and do not have direct access to academic sources. Because they generate text based on patterns in their training data, they often ""hallucinate"" sources and citations. This is a serious issue in academic work, as fabrication (the creation of false quotations or citations) is a breach of academic integrity policies(""https://www.sussex.ac.uk/skills-hub/referencing-and-academic-integrity/#academic"").
This is different to using AI tools to assist searching. For example, platforms like Elicit or Consensus, are designed to retrieve real, verifiable sources and support with identifying relevant research.
Remember, in academic writing, you should always be led by the literature — read and engage with sources first, then build your argument — rather than writing your essay and trying to find evidence to support it afterwards. Academia is a conversation, and your essay should show how your ideas respond to, build on, or challenge existing scholarship.

How do I know if the use of AI is permitted on my module?
If the use of AI has been permitted by your school in a particular module or assessment task then this will be stated clearly in your assessment guidance. If AI is not permitted on your module it will be because its use would mean you miss out on the knowledge and skills the module is designed to teach.
If in any doubt about what is permissible, you should check with the module convenor. The statements should appear as below:
Generative AI tools must not be used to generate any materials or content for this assessment: The purpose and format of this assessment makes it inappropriate or impractical for AI tools to be used.
Students registered with the Disability Advice team and in receipt of reasonable adjustments are still permitted to use other assistive technology as recommended by the University in their Learning Support Plan.
Generative AI tools can be used in an assistive role: You are permitted to use generative AI tools for specific defined processes within this assessment.
OR
Generative AI has an integral role: AI can be used as a primary tool throughout the assessment process.
It’s important to note that such permissions are for specific assessments and in the particular module only. You should not assume they apply in other modules.
If you are permitted to use generative AI tools then you will need to keep a record of your prompts, the outputs and how you used them to inform/develop your final submission.
 

Can I use AI tools to support my learning?
In limited ways you can use AI tools to assist with your learning.
Providing explanations and definitions of difficult concepts or theories.
Summarising texts, transcripts and notes or re-presenting in a way that helps you to understand/remember theories and ideas. For example, as a song or a play.
Help with planning. For example, suggesting a structure for a piece of work.
Improving your grammar and writing style.
Help finding academic literature
Debating to develop ideas
It’s important to note that AIs can be used to support your understanding, but shouldn’t be copied into your assignments as this would constitute academic misconduct. It's best practice to keep a record of all your prompts and outputs.

How do I reference the use of AI in my work?
If you have been given explicit permission by your tutor then current guidance on a suggested format is:
I acknowledge the use of [1. insert AI system(s) and link] on [date] to [2.specific use of generative artificial intelligence]. The prompts used include [3. list of prompts]. The output from these prompts was used to [4. explain use].
AI tools cannot be cited as you would the author of a book because it is not possible to refer your reader to an original source and nor are AI tools considered authors (AI tools generate content based on the training dataset).
 

What information should I avoid sharing with AI tools?
Before using AI tools, we recommend you read the terms of use. Many AI tools collect and retain the data you provide for training and improving their systems. Also, personal information you share could be stored, shared, or even made public.
If you’re working with University of Sussex data, always use Microsoft Copilot via your Sussex account(""https://copilot.microsoft.com/""). This version is licensed and keeps your data protected. If you use any other AI tool, make sure to opt out of data collection whenever possible.
Even when using Copilot, don’t share sensitive information (e.g. names, addresses, health data, research results or passwords) with AI tools.

Alternative tools to generative AI
It’s important to understand that there is an ever increasing range of AI tools available and the quality of responses will vary depending on a number of factors including the quality of the prompts, whether you are using the free or subscribed version and if it’s the right tool for the job.
Activity|Generative AI|Relevant tool|
Referencing|Generative AI tools often create fictional citations and in most cases won’t provide citations at all. There are tools available which reference all sources of information, however, may not accurately format the citation as required by you school/department.
It’s important to be aware that using a source without acknowledging it would amount to plagiarism. Find out how to avoid plagiarism(""https://www.sussex.ac.uk/skills-hub/referencing-and-academic-integrity#main"") on Skills Hub.|Your school will have specific guidance on which referencing style you should be using. The below tools will help you with your citations and bibliographies. More importantly, they will help you to stay organised and avoid accidental plagiarism.
Zotero,
Endnote,
Zoterobib.
Find the Referencing and academic integrity guidance on Skills Hub(""https://www.sussex.ac.uk/skills-hub/referencing-and-academic-integrity"").|
Finding academic sources|It’s important to remember that LLM are not databases.
Not all AI tools will:
provide citations.
find current, high-quality, peer reviewed articles.
find the most relevant resource for answering a research question.
find genuine sources.
There are tools like Research Rabbit which provide lists of sources based on an article, which can help with unstructured searching. However, in order to undertake systematic searches you’ll need to use tools like Library search, Web of Science and Scopus.
Publication research tools include:
Research Rabbit (Free): a visual citation literature mapping tool similar features in Scopus and Web of Science.
Elicit (Subscription): finds scientific literature from the Semantic Scholar corpus and automates parts of the research process including finding keywords, summarising and extracting key information.
Scite (Subscription): finds scientific articles, categorises citations based on context and provides supporting or contrasting evidence for the source reference.
The University of Sussex does not recommend any of these tools for assessment.|Through Library Search and your Subject Resource Guides(""https://guides.lib.sussex.ac.uk/resources"") you can access high quality, academic, peer reviewed research quickly and easily.
Scopus and Web of Science allow you to visualise connection between articles and filter effectively by subject areas. If you’re writing a literature review then structured searching will be essential.
When undertaking your research remember that tools like Google Scholar search all subject areas. You’re more likely to find subject specific materials by using subject databases. Examples of some of the resources available through the library include:
Literature Online (LION)(""https://sussex.idm.oclc.org/login?url=https://search.proquest.com/lion"") is ideal for English students and let you find criticism easily
Reaxys(""https://sussex.idm.oclc.org/login?url=http://www.reaxys.com"") is perfectly design for Chemistry students look for chemical compound properties, structures and reactions.
Nexis(""https://advance.lexis.com/nexis?federationidp=4HKXSX59158"") allows you to search for news across the range of newspapers and countries.
Also if you're searching for archival/primary/statistical sources then AI searches won't discover these resources. Examples available throught the library include:
Independent Voices(""https://www.jstor.org/site/reveal-digital/independent-voices/?so=item_title_str_asc&searchkey=1714660095286"") a collection of alternative press newspapers, magazines and journals.
Slavery, Abolition and Social Justice(""https://sussex.idm.oclc.org/login?url=http://www.slavery.amdigital.co.uk"") brings together primary source documents from archives and libraries acros the US and UK.
Orbis(""https://guides.lib.sussex.ac.uk/orbis"") provides access to finacial data for public and private companies worldwide.
The library regularly runs workshops on search skills and offers 1-2-1 support(""https://www.sussex.ac.uk/library/using-the-library/training"").|
Checking Facts|Generative AI tools like ChatGPT are trained on large datasets at a certain point in time, which means they may not have up-to-date information. For example, GPT-5 is trained on data up until June 2024. The paid for version of ChatGPT and Perplexity incorporate live web searches, which can provide more current information, but general internet searches may not always find subject-relevant or academic sources, so the paid-for version is not necessarily any better. For academic research, specialised tools like subject databases or encyclopedias are more reliable.
It’s also important to remember that LLMs generate responses using probabilistic methods, introducing an element of randomness. This means you may receive different answers to the same question, depending on the model's settings and how the query is phrased. Additionally, AI models can sometimes produce inaccurate or fabricated information—commonly referred to as ""hallucinations""—especially when responding to complex or specialist queries. It’s always a good idea to verify critical information from reliable sources.|Like Wikipedia, AI generated summaries can be a good starting point, however, the best place to check facts or find introductory materials for a topic is by using your reading list (which you'll find on your module Canvas site), subject encyclopaedias and textbooks, which will also provide a bibliography of sources used and be relevant to your specific discipline.
You can access dictionaries and encyclopaedia resources via Library Search and Subject Guides(""https://guides.lib.sussex.ac.uk/resources"").|
Summarising articles and book chapters|AI generated summaries of texts are not replacements for critically engaging with sources for your research.
An AI generated summary may help you get a general sense of text, but may miss out the nuances or misrepresent arguments.
Critically engaging with your sources will help improve your understanding of the topic and will also help you to bring your own voice and informed perspective to a debate. When writing your assignment it may be more engaging for yourself (and your reader) if you’re identifying novel and unique connections rather than relying on a general overview produced by AI which everyone will have seen.|When researching for your assignment you need to read critically and keep your research question in mind to identify information relevant to your argument. General summaries won’t be tailored to your research question.
Resources available via Skills Hub on:
Critical thinking(""https://www.sussex.ac.uk/skills-hub/critical-thinking/""),
Effective reading(""https://www.sussex.ac.uk/skills-hub/reading-and-research/""),
Note-making(""https://www.sussex.ac.uk/skills-hub/note-making"").|
Please note that given the rapid development of AI tools, this information may at times become out of date. This page was last updated on September 26 2025."
46,Nottingham Trent University,46_NottTrent.rtf,https://www.ntu.ac.uk/studenthub/news/2023/12/artificial-intelligence-%40-ntu,"As technology continues to evolve, so does our approach to education. One of the most exciting advancements is Generative Artificial Intelligence (GenAI), a tool that can enhance your academic journey.
We have put together Generative AI Guidance for students, which can be found on the Digital Skills Now learning room.(""https://now.ntu.ac.uk/d2l/le/content/986783/viewContent/13413951/View"") This guidance helps you use GenAI effectively and ethically, ensuring you get the most out of your studies.
What is Generative AI?
Generative AI refers to the use of artificial intelligence to create new and original content, such as text, images, music and video. These tools use algorithms and machine learning techniques, to predict and generate outputs that simulate human-like responses.
Using GenAI at NTU
Microsoft Copilot(""https://www.microsoft365.com/?auth=2&home=1"") is our preferred use of generative AI, because unlike other tools, our data and IP will not be shared with all users of the platform, just those at NTU.
As an NTU student, you get free access to Microsoft 365, which includes Microsoft Copilot.
You can easily access Copilot by signing into Microsoft 365 online. Select the Copilot logo in the top left-hand corner in the app launcher.
GenAI guidance
The Generative AI guidance not only covers important considerations like dos and don’ts, but also prompts on ways to use AI ethically and effectively to support your studies.
Generative AI is a powerful tool that can significantly enhance your learning experience at NTU.

Artificial Intelligence @ NTU
Published: 11/12/2023
Generative Artificial Intelligence (GenAI or AI) is the use of technology to create content such as text, images, music, video and computer code. These tools are generating a lot of headlines at the moment, so it's important to know how to use it effectively.

Dos and don'ts for using AI
AI is far from perfect
On the surface, GenAI tools can look very clever. However, don’t be fooled!
These tools are very good at pretending to be as smart as a human. For example: when ChatGPT is writing a line of text, it does so by predicting the next likely word in the sentence based on patterns from anything that it can find online. This means the information it creates may seem legit, but can actually be factually incorrect, out of date, biased or just nonsensical.
We’ve put together a helpful list of dos and don’ts to help you feel more confident about using AI tools at NTU.
Dos
Do make it clear where and how you have used GenAI tools in your work.
Do check and confirm any information GenAI outputs for you by using reliable sources such as Library OneSearch.
Do familiarise yourself with how these tools work(""https://nationalcentreforai.jiscinvolve.org/wp/2023/10/16/generative-ai-primer/#2"") so you can better understand their strengths and limits.
Do follow any School guidance about using AI in your subject.
Do remember that you are at university to develop your own knowledge and skills.
Don’ts
Don’t submit work which has been produced by GenAI as if it were your own. This is academic misconduct according to the NTU Academic Integrity Policy.(""https://www.ntu.ac.uk/__data/assets/pdf_file/0036/921987/17C-Academic-Integrity-Policy-Sept-2023.pdf"")
Don’t give GenAI tools access to personal data, research data, copyrighted materials or University intellectual property such as lecture slides.
Don’t upload any material of your own, unless you are comfortable with how the GenAI tool will use it in the future.
Don’t use AI bots to attend online classes or meetings or to take notes for you. By doing this, you would be sharing information with an external party. If you have a disability that may require the use of AI to help with notetaking, please contact disability.support@ntu.ac.uk(""mailto:disability.support@ntu.ac.uk"") for support.
Don’t run code generated by AI without fully understanding how it works and the action it will perform. You need to be sure what it will do.
In summary, AI can be used to help you work more productively or creatively but should not be a substitute that you rely on to complete your work.
Most importantly, when using a GenAI tool, remember to always cross reference the information it gives you with known accurate sources.
Help and support
Please refer to any guidance your School has issued on GenAI.
Further help is available from the Library Learning and Teaching team:
Email libinfodirect@ntu.ac.uk(""mailto:libinfodirect@ntu.ac.uk"")
Book an appointment(""https://librarybookings.ntu.ac.uk/"")
If you need to report an AI related data breach, please use the data breach or incident form.(""https://www.ntu.ac.uk/myhub/policies-and-guidance/general-data-protection-regulation/breach-form/_nocache"")"
48,"City St George's, University of London",48_CityStGeorge.rtf,https://studenthub.citystgeorges.ac.uk/academic-resources/learning-and-study-support/online-learning-tools/using-generative-artificial-intelligence-ai-for-learning,"City St George’s is exploring the opportunities and challenges presented by generative AI. We appreciate the importance of students learning to use generative AI appropriately and effectively, but we expect students to use these tools in an ethical and responsible way. This is an important part of learning and academic integrity. Our guidance for students is outlined below.

What is generative AI?
Generative AI refers to tools that create new content such as text, images, video, audio, code or synthetic data.
They use sophisticated machine learning algorithms that learn from vast amounts of data to produce new content that is similar to what they've learned.
Essentially, these algorithms analyse existing content, such as text or images, and then use that information to generate new content in response to requests, known as prompts, from people.
The chatbot style interfaces used by these technologies are designed to simulate a human conversation, with text responses that appear human-like because they were trained on content written by people.
However, this capability can sometimes blur the lines between human and machine interactions, potentially leading to misunderstandings or over-reliance on automated systems. It’s important to remain aware that, despite their sophistication, these tools lack genuine understanding and should be used with care.
Strengths of Generative AI
Providing responses to questions or requests for information in a range of formats.
Supporting the development of ideas or helping with problem-solving.
Effectively performing analytical tasks and providing insights into data.
Summarising information in a more digestible format.
Continuously improving their capabilities through regular updates.
Limitations of Generative AI
Generative AI tools have several limitations due to their lack of understanding of the content they produce which can lead to misinformation, bias and an absence of ethical judgement. The content generated is based on predicting the next plausible word or sentence and they are trained to give responses that people like rather than responses that are necessarily accurate. This can result in:
Inaccuracies: The generated content might not be factually correct. For AI-generated computer code, this could mean security issues, bugs or illegal use of software libraries.
Biased and offensive content: The content may contain biases (e.g. political and cultural) and potentially offensive material.
Fake references: The content may contain plausible, but entirely made-up references or citations.
Dataset limitations: Generative AI tools are limited by the dataset they have been trained on. This may mean it might not include curriculum-relevant information and will not have access to scholarly databases, journals, and publications.
It is important that you understand the limitations and use your developing professional judgement to check the factual accuracy and appropriateness of the content produced. AI-generated content should be used together with the learning resources provided by your module tutor and other trustworthy sources.
Can I use generative AI at City St George’s?
Use of generative AI is generally permitted to support your learning; however, use of generative AI for assessments needs to be different to ensure that you have reached important learning outcomes. For assessments, use of generative AI is only permitted, where you have been instructed by your module tutor or programme director to do so. You can find details of how you can use AI for both your learning and assessments below.
Generative AI to support your learning
Generative AI may be used to support your learning. You may find it useful to use generative AI to clarify key concepts or understanding, or to ask you questions based on your revision notes.
To ensure the outputs from generative AI are useful, you will need to give it sufficient detail to support your request, for example including the level you are studying and the context. You must ensure that you review carefully the response you receive for accuracy, reliability and credibility.
We expect students to use generative AI tools in an ethical and responsible way. One aspect of this is that you must be aware of the limitations of these tools, in terms of reliability and bias, and ensure that you use generative AI to support your learning, rather than do your learning for you.
Do not use generative AI tools as a replacement for the resources supplied by your module tutor. Learning to make effective, critical and ethical use of generative AI tools is an important skill as part of preparing for your career.
Learning to use AI, understanding its strengths and weaknesses, may also become a useful employability skill and you may find some modules will embed the use of AI into assessments and other activities.
You may find using prompts useful for supporting your learning(""https://blogs.city.ac.uk/aiforstudents"").
Generative AI for assessments
When it comes to using AI as part of an assessment, the University’s default position is that you must not use generative AI tools for assessment, unless you have been instructed to do so by your module tutor or programme director.
Guidance about what is permitted will be provided as a clear written statement, which should be found in the assessment details, handbook or on the Virtual Learning Environment. It is important to follow the guidance provided and adhere to the Academic Integrity and Misconduct policy.
If you are permitted to use generative AI for your assessment, you are expected to it responsibly and ethically. This includes being aware of its limitations, acknowledging the use of generative AI in your work, and using it to support your own original work.
Academic integrity and misconduct
The University requires that all work submitted for assessment is your own original work, or in the case of group work, the original work of group members.
If your module leader has given you instructions on the use of AI for a particular assessment, you should follow these. In the absence of any such specific instructions, the key point is that when you hand in work for an assessment, you are stating that it is your own original work.
The purpose of any assessment is to measure what you have learnt and understood from the course being assessed. It is not possible to assess your understanding if you plagiarise, copy and paste text, use AI, paraphrasing software or essay mills.
The University sees academic integrity as very important and takes academic misconduct very seriously, seeking at all times to rigorously protect its academic standards.
Under the Academic Integrity and Misconduct Policy, unauthorised use of generative AI tools could be considered:
Plagiarism – where text used in the assessment is the direct output from an AI tool. Plagiarised text which has been amended using further AI tools (e.g., paraphrasing) remains plagiarised. The sources at the end of this message give guidance on appropriate citation of external material.
Falsification or fabrication – where the outputs from using generative AI tools have produced sources or data that do not exist.
Contract-cheating – where generative AI tools have been used to produce the whole assessment.
Any students suspected of committing academic misconduct will be actively investigated and if the misconduct is confirmed the full sanctions outlined within our Academic Integrity and Misconduct Policy will apply.
Acknowledging the use of generative AI in your work
Students should consult CiteThemRight(""http://www.citethemrightonline.com/"") for citing and referencing resources correctly. If the output of the AI produced material is available online, you can cite this as you normally would.
If not, then you are advised to cite this as ‘personal communication’. Refer to the guidance on citing generative AI from Cite Them Right Online(""https://www.citethemrightonline.com/sourcetype?docid=b-9781350927964&tocid=b-9781350927964-217&st=AI"") (your University login is required).
Where you have been permitted to use generative AI in your assessment task, you may be asked to acknowledge how you have used generative AI, what you have used it for and to include a copy of the output generated, including relevant prompts.
Please refer to any guidance from your module tutor or programme director about requirements for acknowledging use of AI.
It is your responsibility to ensure that the reader of your work can clearly distinguish between original content created by you and content generated or inspired by generative AI and other sources. If you use generative AI in your assessment in any way that breaches our Academic Integrity and Misconduct Policy, this may be considered to be academic misconduct.
Academic misconduct is taken very seriously, and all suspected cases will be thoroughly investigated.
As part of an academic misconduct investigation, you may be asked to disclose what generative AI tools you have used, how you have used them (including specific prompts), and you may be required to provide draft copies of your work or other relevant evidence. It is therefore recommended that you store your work on OneDrive where version history will be available.
It is important to understand these Guidelines and use generative AI responsibly to avoid any violations of academic integrity.
What generative AI tools are available?
City St George’s provides Microsoft Copilot Chat free for all students and you are recommended to use this tool:
About Copilot: Copilot uses the latest AI models, including GPT-5, so offers similar capabilities to ChatGPT-5. It can generate text and images based on prompts that use text, files or images. It retains your conversation history, and it is recommended that you keep these conversations where AI has been used to support assessment as you may be asked to produce them as part of your submission.
Accessing Copilot: You can access Microsoft Copilot at m365copilot.com, through the iOS or Android app(""https://play.google.com/store/apps/details?id=com.microsoft.copilot&hl=en&gl=US&pli=1""), or in the Microsoft Edge sidebar and Windows 11 . Ensure you log in with your University credentials to keep your data secure.
Copilot privacy and security: Microsoft’s enterprise data protection(""https://learn.microsoft.com/en-us/copilot/microsoft-365/enterprise-data-protection#what-is-enterprise-data-protection-in-microsoft-365-copilot-and-microsoft-copilot"") is applied when you log in to Copilot with your University credentials, which means that data entered is kept private and is not used to train the underlying dataset. As with all generative AI tools, you should not enter personal, sensitive or confidential information nor submit copyrighted materials into the tool.
Other generative AI tools
There are a range of other generative AI tools available. The most well-known is ChatGPT by OpenAI(""https://openai.com/blog/chatgpt"") which uses a chatbot interface for users to engage with the system; however, there are other tools available, including those embedded in search engines, existing software (such as Grammarly or Office 365) and computer coding editors.
Most tools require you to create an account which may be free or come at a cost. Free accounts are usually limited in terms of functionality or the number of times you can use the tool.
Some tools use the data you enter to train the generative AI large language model. It is therefore important that you familiarise yourself with the privacy policy for any tools you use and do not enter any personal, sensitive or confidential information.
In addition, ensure that you do not submit any copyrighted materials into the tools.
How to use prompts for generative AI
To use generative AI, you need to provide a set of instructions, known as a prompt, for what you would like it to do. The prompt should describe what you want the tool to perform, details of the task and any specific requirements for the output, For example:
“I am a first year Economics student in a UK university and I need to understand the concept of supply and demand, can you help me learn more about this and find useful study resources?”
Having reviewed the output, you may need to provide follow-up questions or information to help refine the information received. You can access further information about prompting and suggested prompts for specific tasks via the AI prompts for students blog(""https://blogs.city.ac.uk/aiforstudents"").
Note: It is important to use your professional judgement to check the factual accuracy and appropriateness of the content produced and to use AI content in conjunction with the learning resources provided by your module tutor and other trustworthy sources, such as the Library(""https://libraryservices.city.ac.uk/"").
Support and guidance
Support is available to assist you with academic skills and writing:
Refer to the Academic Integrity and Misconduct policy(""https://studenthub.citystgeorges.ac.uk/student-support-services/student-concerns-and-rights/academic-misconduct"").
Contact the Academic Skills team(""https://studenthub.citystgeorges.ac.uk/academic-resources/learning-and-study-support"") who provide support for referencing, critical thinking and writing, academic reading, time management, revision techniques, exam performance.
Refer to the Library Services guidance on citing and referencing(""https://libraryservices.city.ac.uk/support/citing-and-referencing"").
Make the most of Library resources by speaking with your Subject Librarian(""https://libguides.city.ac.uk/c.php?g=218899&p=1446680"").
Contact the Student Union Advice team(""https://csgsu.co.uk/advice-and-support"") if you would like advice on responding to an Academic Misconduct allegation"
49,Ulster University,49_ulster.rtf,https://www.ulster.ac.uk/learningenhancement/cqe/strategies/ai/guidance-for-students,"Guidance on use of AI for students
Guidance for students on responsible use of AI tools
Generative AI tools can be prompted in conversational ways to create new content including text, images, audio, video and computer code. As the tools develop, they are becoming integrated into existing business and personal applications such as web browsers, the Microsoft Office suite and Google Docs.  New plugin architectures are evolving allowing other businesses to integrate their services within the tools.
Generative AI Tools such as ChatGPT, Google Bard, DALLE-2 and CoPilot can be helpful for generating content. This has obvious implications for assessment and some institutions have banned their use. Here at Ulster, we believe that these tools will be a part of our personal and professional lives and we wish to explore their use with students in ethical, transparent and reasonable ways.  Our position is to:
		Develop an understanding of Generative AI and promote AI literacy across the staff and student body
		Provide guidance on the appropriate use of GenAI tools
		Encourage critical dialogue when AI tools are used within the curriculum.
		Encourage a University culture that upholds the value of integrity(""https://www.ulster.ac.uk/peopleandculture/values/integrity"")
		Reinforce the expectation that work submitted for assessment is students own original work.
		Remain open to the benefits of the use of AI whilst highlighting the dangers of relying on the outputs as accurate sources of information.
		Encourage learning, teaching and assessment design that encourages creativity and innovation
Limitations
Whilst these tools can generate content that appears reasonable, they should not be relied upon to be wholly accurate, and students should know how to evaluate the information critically using other reliable sources.
Some of the current limitations of Large Language Model (LLM) AI tools are as follows:
		The tools do not understand the meaning of the words they produce.
		The tools will often generate arguments that are factually wrong.
		The tools will often generate false references and quotations.
		Content generated is not checked for accuracy.
		The tools can distort the truth and emphasise the strength of an opposing argument.
		The tools may struggle to maintain contextual understanding over extended conversations however,  there are current developments in this area.
		The tools may struggle to generate responses based on visual and auditory input.
		Generated content can include harmful bias and reinforce stereotypes. These biases can be reinforced through further human interaction with the model.
		The tools rely heavily on data access to generate responses. This has led to concerns about data privacy
		The models are trained on a data set from a Western English-speaking perspective again reinforcing particular perspectives. Developing skills to prompt AI tools is likely to be a useful digital skill but users should also understand the limitations, remain open, curious, and critical when making judgements about the accuracy of the content generated.
Over reliance on these tools will limit the development of your writing and evaluation skills which are skills that you will use in future careers. You should therefore approach the use of these tools with a critical lens by understanding the their limitations.
Developing skills to prompt AI tools is likely to be a useful skill but students should remain open, curious, and critical when making judgements about the accuracy of the content generated.
Using AI Reasonably
You should not feel under and pressure to make use of the tools and you will not be disadvantaged if you decide not to use them. However, Ulster University recognises that these tools may be used in reasonable ways and that they will evolve to become embedded in many of our workflows.
In their current state, reasonable use of the tools might be for:
		Planning the structure of written work.
		Developing creative ideas and inspiration.
		Answering questions of web-based material.
		Helping to improve writing skills.
		Asking for an explanation of a topic.
Importantly, unless you are specifically asked to do so, you should avoid using GenAI to create content for assessed coursework and research.  The use of AI tools must not substitute your critical thinking, problem-solving skills and thought processes. Your work must be original and reflect your own informed perspective and understanding.
When using GenAI technology, you are expected to exercise responsible and ethical practices. This includes:
		critically evaluating the outputs of AI generated content,
		understanding the limitations and potential biases of AI algorithms
		maintaining academic integrity by appropriately citing and acknowledging all sources
Data Security
As Generative AI learns from data drawn from a wide range of digital platforms, all users must be particularly cautious when inputting data.
While  writing prompts for Chatbots for example, you are at risk of sharing personal, proprietary and confidential data and sharing intellectual property.
This data will be stored and potentially misused by service providers and re-used for other generated responses. For this reason:
Never input:
		personal information,
		sensitive or confidential data
		copyright protected information.
Acknowledging the use of Generative AI tools
As an Ulster student, you are expected to understand and appreciate the value of academic integrity and familiarise yourself with and meet the University’s standards of academic integrity, including the use of AI.
The Student Academic Misconduct Procedure(""https://www.ulster.ac.uk/__data/assets/pdf_file/0004/1535971/Academic-Misconduct-Procedure.pdf"") explicitly discusses the use of AI, and the student declaration for coursework submission states that:
“I declare that this is all my own work. Any material I have referred to has been accurately referenced and any contribution of Artificial Intelligence technology has been fully acknowledged.
I understand the importance of academic integrity and have read and understood the University’s General Regulation: Student Academic Integrity and the Academic Misconduct Procedure. I understand that I must not upload my work before, during or after submission to any unapproved plagiarism detectors or answer sharing platforms, or equivalent, and that only University-approved platforms should be used.”
It is therefore not appropriate to misrepresent AI generated content as your own original work. Where content is used without being acknowledged, it will be considered  as a form of academic misconduct.
Where generative artificial intelligence (AI) tools have been used for academic purposes, they must be acknowledged appropriately to ensure that any output is not misconstrued as the author’s own work. Before students begin any piece of assessed work, they should be clear that the use of AI tools is authorised and appropriate as this practice may differ across modules and programmes of study.
The below links provide more information about citing and referencing AI in the Harvard style and the Library Subject Team
 (opens in new window)
 can provide more guidance if other referencing styles are used.
		Citing AI Generative Tools in the Ulster Harvard Referencing style for LHS (opens in new window)(""https://guides.library.ulster.ac.uk/lhsharvard/ALGenerativeTools"")
		Citing AI Generative Tools in the Ulster Harvard Referencing style for CEBE, AHSS and UUBS (opens in new window)(""https://guides.library.ulster.ac.uk/harvardref/AIGenerativeTool"")"
50,Robert Gordon University,50_RobertGorden.rtf,https://library.rgu.ac.uk/apa-referencing/ai,"APA Referencing
Generative AI

 
The use of generative AI within assignments must comply with RGU guidance(""https://campusmoodle.rgu.ac.uk/course/view.php?id=104016""). It is your responsiblity to check your assignment brief and ensure that the use of AI tools is permitted within an assignment

Any use of AI tools, including idea and content generation or helping you to plan or develop an assignment, must be acknowledged as a source. Instructions are given below on how to reference the legitimate use of AI within assignments but given how fast the AI landscape is changing these instructions may be subject to change in the coming months.

This guidance is based on advice produced by the APA Style Team(""https://apastyle.apa.org/blog/how-to-cite-chatgpt""). They are responsible for updating the APA style and may issue further guidance in the future.
 
Template
Author. (Year). Title of Generative AI tool (Version number) [Large Language Model]. Source.
 
Reference
Open AI. (2023). ChatGPT. (July 20 version) [Large Language Model]. https://chat.openai.com/chat
Citation
(OpenAI, 2023)

If you have used the author's name in your sentence then only the year of publication is placed after it in brackets. e.g.
A response generated by Open AI (2023) suggested that.....

Other Examples and Questions
 
The AI is not text based (e.g. images, code, videos)
We advise that you follow the template above for any content that you have generated from an AI tool."
51,Edinburgh Napier University,51_napier.rtf,https://my.napier.ac.uk/your-studies/improve-your-academic-and-study-skills/artificial-intelligence-tools,"Generative Artificial Intelligence tools and your learning
Using generative Artificial Intelligence (Gen AI) content generation or writing assistance tools such as ChatGPT and Grammarly, may have a positive or negative impact on your learning and skills. The guidance on this page is intended to help you to understand these tools so that you can make informed decisions about whether or not to use them.
If you use an AI content generation tool as part of your academic work, you need to be very careful that you do not commit Academic Misconduct by submitting work that is not your own. You should always first check with your module leader or tutor about what – if any – use of Gen AI is allowed in your work.
 
 
Generative artificial intelligence and your studies
When it comes to generative artificial intelligence, there are many apps and tools which can often provide quick answers, feedback and ideas. However, if you're thinking of using artificial intelligence tools when it comes to your studies, there are some important things to think about that could impact your studies and your professional career.
Watch our short guide to artificial intelligence to find out more.


Generative artificial intelligence and your studies
01:38


Video transcript: Artificial intelligence and your studies 
 
 
What is an Gen AI?
Generative artificial intelligence (Gen AI) tools can generate content across many subjects and skills e.g., writing, art / design, computer coding. They generate content based on questions that the user inputs to the tool.
Gen AI writing tools work by simulating natural conversation on a given topic. They have been trained on an immense quantity of data and generate content by predicting the next most likely word. They can develop well-structured paragraphs or longer work. These tools continue to learn from user responses and are regularly updated with recent data from the internet.
Image generation is also possible through tools such as ChatGPT, or specialised tools like Midjourney and Adobe Firefly. They work in a similar way but based on image/shape recognition combined with natural language processing.
Before using any free tool you should read the terms and conditions carefully. It is rare for a tool or app to be completely free and make money in other ways e.g. advertising, taking your personal data and using or selling it. Think carefully and critically about the risks, benefits and ethics before you make use of any technology, including AI content generation tools.
Please read the following FAQ section carefully to understand what it means for you as a student to use these tools, particularly around the context of assessments and exams.

 
 
Edinburgh Napier University student guide to artificial intelligence tools
Are there any risks with using Gen AI content generation tools? |Are there any ethical issues with using Gen AI content generation tools? |Can I use Gen AI content generation tools in my assessments? 
Your assessments are required to be solely your own work, or in the case of group work, solely the work of your group. They are a means for you to demonstrate what you have learned. Submitting work which is not your own is plagiarism and falsification i.e. cheating.
The Edinburgh Napier University Academic Regulations clearly state that submitting work which is not your own is academic misconduct and a form of cheating. The penalties imposed for academic misconduct reflect the seriousness of this conduct. Being found to have committed academic misconduct has potentially severe consequences for your studies and future employment.
If you do plan to use an Gen AI content generation tool to develop your assessment, you should contact your module leader to find out what, if any, evidence of this use should be submitted with your assignment use is allowed. Most online assessments now require you to submit a declaration which allows you to acknowledge and detail any use of GenAI tools. You should seek the guidance of your module leader for all assessment submissions, including online exams and coursework. You must make sure that you comply with the guidance from your module leader and keep a record of the guidance you receive.
Contact your module leader if you are unsure whether you are permitted to use any Gen AI tools in your submission.
If you are under pressure with an assessment and are thinking about using an Gen AI tool to do it for you, there are other means of support including:
Your Module Leader, Module tutors or Programme Leader
Your Personal Development Tutor(""https://my.napier.ac.uk/your-studies/your-personal-development-tutor"")
Academic Skills team(""https://my.napier.ac.uk/your-studies/improve-your-academic-and-study-skills/one-to-ones"")
Wellbeing and Inclusion Team(""https://my.napier.ac.uk/wellbeing-support-and-inclusion"")
ENSA Academic Misconduct Advice(""https://www.napierstudents.com/advice/education/academicmisconduct/"")
They can discuss your circumstances and advise you on how best to move forward with your studies without reverting to academic misconduct that may impact on your future studies and employability.
|||Can I use Gen AI to support my learning? 
There is potential for Gen AI to support your learning. For example, you might use them:
As a starting point for research or helping understanding in the same way that you might use a search engine (although bear in mind that, as with other information found on the internet, the answers provided by Gen AI tool may be untrue).
To develop your questions about a topic, refining your questions to focus more on the topic and developing your critical thinking in the process.
If you choose to use such a tool:
Remember to check that you are comfortable with the terms and conditions before you do so (e.g., are you happy that your personal data might be shared or sold to others?).
Be aware that the tool may give you answers which are incorrect, illogical and / or biased. You will need to use other sources and your own understanding of a topic to confirm the accuracy of any information provided.
Follow the correct citation and referencing for your school(""https://my.napier.ac.uk/your-studies/improve-your-academic-and-study-skills/referencing-and-academic-integrity/referencing"") to acknowledge non-Gen AI sources of information which you use in your submission.
Ensure that you clearly identify any work in an assessment which is not your own work e.g. if you ask questions of a Gen AI tool and use the answers, then this would not be wholly your own work and should be identified and acknowledged appropriately. Seek advice from your module leader on how this should be done for your assessment. Be prepared to provide a copy of your AI conversation as an appendix.
||||What is Edinburgh Napier’s position on using Gen AI tools? 
We provide students with engaging, real-world learning opportunities to equip you for lives and careers in a global digital world. Gen AI and other forms of artificial intelligence are already a part the workplace. This is why we encourage you to think critically about the implications of digital tools for your studies, your current learning and your future lives.
We also recognise the potential for these tools to empower you in your own learning and, when used responsibility, make learning more inclusive and accessible. We aim to provide every student with the support to engage with a range of learning opportunities during your studies, thereby reducing the likelihood of any student choosing to miss out on the learning involved in creating your own work for assessments and instead submitting the output of Gen AI. We have been actively engaged in gathering students' opinions on Gen AI since 2023, and will continue to do so, using this evidence to inform our guidance.
Edinburgh Napier University’s position statement(""https://documentcentre.napier.ac.uk/-/media/files/university-governance/artificial-intelligence/edinburghnapieruniversityspositionongenerativeartificialintelligence.pdf"") on Gen AI outlines our shared commitment to ethical and responsible use. Student responsibilities are outlined below, but you can read the full document for details on the responsibilities of the University Leadership, academic staff, professional services staff etc.
Our Collective Responsibilities
We all are responsible for understanding the ethical implications of Gen AI, including its impacts on academic integrity, personal and institutional data, misinformation, bias, copyright, equity, and the environment.
Staff and students are expected to declare when they directly use AI-generated content.
DLTE provides support and training in Gen AI for staff and students, and we should all maintain a level of critical awareness to make informed decisions about its use.
Anyone processing personal data on behalf of the University is required to comply with the University Data Protection Policy when using any Gen AI tools.
Students’ Responsibilities (Undergraduate and Taught Postgraduate)
You have a personal responsibility to think critically about the ethical implications of Gen AI as part of your learning, including its environmental impact, bias, misinformation, and data privacy. Engage with MyNapier’s Artificial intelligence tools(""https://my.napier.ac.uk/your-studies/improve-your-academic-and-study-skills/referencing-and-academic-integrity/artificial-intelligence-tools"") pages.
You are responsible for ensuring your work reflects your own thinking, skills, and understanding.
If you use Gen AI tools in your learning or assessments, you must follow university guidance and acknowledge AI-generated content.
Misrepresenting AI-generated work as your own is academic misconduct and may result in an academic integrity investigation. The outcome of such an investigation may have significant implications for your future studies and negatively impact your personal development and future career prospects.
You should be familiar with the Academic Integrity Regulations(""https://my.napier.ac.uk/your-studies/improve-your-academic-and-study-skills/referencing-and-academic-integrity/academic-integrity"") and Student Charter and Student Professional Standards(""https://my.napier.ac.uk/your-studies/regulations-conduct-and-safety/student-charter"")[1](""file:///C:/Users/40000590/Downloads/MyNapier%20Update%20Aug25_LD.docx#_ftn1"").
If you are unsure about permissible use of Gen AI in your assessments, check the Assessment Brief and ask your module leader/tutor.
If you are under pressure trying to complete an assessment and are thinking about inappropriately using an Gen AI tool to do it for you, you should avoid this and seek out other means of support, including your module leader/tutor, your PDT, the Academic Skills team(""https://my.napier.ac.uk/your-studies/improve-your-academic-and-study-skills/one-to-ones""), Wellbeing and Inclusion Team(""https://my.napier.ac.uk/wellbeing-support-and-inclusion""), ENSA(""https://www.napierstudents.com/"").
Students’ Responsibilities (Postgraduate Research)
Postgraduate research is founded on the three pillars of independence, originality and significance. Ensure that any use of Gen AI in your studies does not compromise your ability to undertake research that achieves these three pillars.
Share your research writing with your supervisors regularly during your studies and always discuss any intended use of Gen AI with them first.
You have a personal and professional responsibility as a researcher to think critically about the ethical implications of Gen AI use in research, including its environmental impact, bias, misinformation, and data privacy.
Misrepresenting AI-generated work as your own is academic misconduct and may result in an academic integrity investigation. The outcome of such an investigation may have significant implications for your future studies and negatively impact your personal development and future career prospects.
Any use of Gen AI in the process and writing-up of your research should be clearly acknowledged.
Your final thesis should be your own work, not AI-generated content.


[1](""file:///C:/Users/40000590/Downloads/MyNapier%20Update%20Aug25_LD.docx#_ftnref1"") The Student Charter and Student Professional Standards will be replaced by a new document for 2025/26.
|||||What about Postgraduate Research and Generative AI? 
With Gen AI tools such as Chat-GPT widely available and expected to continue to develop quickly, as will our societal and legal responses to the technology. The below guidance is based on current, available technologies. Many of the points below are prompts to think, not hard and fast rules.
Points of Consideration
Postgraduate research at the University is founded on three golden pillars: independence, originality and significance. When using Gen AI tools, consider:
Can Gen AI produced text ever be considered original?
If an algorithm is producing the text, in what sense could you claim to have produced it independently?
And if the work is not original, how does it contribute significantly to knowledge? 
Gen AI tools, like ChatGPT, work by analysing material to predict and generate content based on prompts. They do not create new ideas, but rely on patterns in pre-existing data.  Therefore their limitations are:
These tools are not designed to generate genuinely new ideas
As postgraduate research requires the development of new ideas, the use of Gen AI models as tools for this purpose is limited. 
The current UK laws governing copyright do not fully address Gen AI, which creates legal uncertainty. As Gen AI models often rely on copyrighted works:

Outputs from Gen AI will constitute plagiarism, even where it is not directly copied.
Use of such content in your thesis may constitute plagiarism.
 
All of our research postgraduate degrees (excluding MRes) are examined by viva voce.

Significant use of Gen AI produced text runs the risk of entering an examination without a solid understanding of the material in your own thesis.
This could lead to a fail, whether or not plagiarism can be demonstrated.
 
Gen AI tools can support research for gathering information and brainstorming, and while the results may look different to those produced by conventional search engines, they are no more ‘intelligent’, original or accurate. Despite the term ‘artificial intelligence’, these technologies are not capable of thought in the sense that we expect it to be demonstrated in your work.  Put simply:
While Gen AI models may be able to help you find potentially relevant information, provide a prompt for thought or guidance,
They cannot do the work of critical thinking for you. 
All RPG students are expected to meet regularly with their supervisors and:
Share their writing throughout their studies.
Discuss any intended use of Gen AI with supervisors early So your supervisors can provide advice and guidance.
Guidance
If you choose to use Generative AI tools to assist in any stage of your research, you must follow the below guidance.
Appropriately cite any text or output generated by AI in your thesis, as you would any other sources.
Clearly indicate where in AI-generated material is included your thesis. Options include a narrative account in your introduction or a detailed appendix.
Gen AI tools have limitations; always use them in conjunction with other sources to ensure the credibility and reliability of the information you present.
Ensure the final product is your own work, and not copied from an Gen AI tool, like Chat GPT. You may use generated text as a prompt for inspiration or guidance, but the final submitted assessment must be your work, your creation, and your own analysis.
Statement of Generative AI Use
In addition to the optional inclusion of a reflective narrative of the use of Gen AI as suggested above, all students are required to make a declaration of their use of Gen AI in their thesis, including in the course of the research reported in the thesis.
Have you utilised any generative AI tools in your thesis, including the research which forms the basis of your thesis?
YES / NO
If yes, please provide a brief account of your use of such Gen AI tools.
(The above guidance is drawn in part from guidance developed by Deakin University, Australia(""https://blogs.deakin.edu.au/deakinlife/2023/02/02/what-you-need-to-know-about-chatgpt-and-other-ai-tools/?mkt_tok=MjA5LUlOUS0zNjcAAAGJszImxhX83bnqIKscuo7USaXJptKPJb_-1iNQAQ1Crnp-_XNaTlHrOA9XEF80q0U-4PfnwnnvDa8CscPmscpjKFVCNGN8K30-uL27lHQNhXcOyw""))

 
 
Where can I find more information?
The Skills hub provides a wide range of support to help you develop key academic skills including:
Academic Integrity(""https://my.napier.ac.uk/your-studies/improve-your-academic-and-study-skills/referencing-and-academic-integrity/academic-integrity"")
Referencing Guidelines(""https://my.napier.ac.uk/your-studies/improve-your-academic-and-study-skills/referencing-and-academic-integrity/referencing"")
ENSA Academic Misconduct Advice(""https://www.napierstudents.com/advice/education/academicmisconduct/"")
Academic Skills team(""https://my.napier.ac.uk/your-studies/improve-your-academic-and-study-skills/one-to-ones"")
Wellbeing and Inclusion Team(""https://my.napier.ac.uk/wellbeing-support-and-inclusion"")
About this guide
The information on this page is adapted from Heriot Watt University’s Introduction to Artificial Intelligence (AI) content creation tools and university study: Student Guide(""https://lta.hw.ac.uk/wp-content/uploads/Student-Guide-Introduction-to-Artificial-Intelligence-content-creation-tools-university-study.pdf""). This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License"
52,University of Portsmouth,52_portsmouth.rtf,https://myport.port.ac.uk/study-skills/digital-skills/using-ai-at-university,"Using AI at university
How to use these new technologies responsibly and transparently

Jump to:
		What is AI?(""https://myport.port.ac.uk/study-skills/digital-skills/using-ai-at-university#explanation"")
		Can I use AI for my studies?(""https://myport.port.ac.uk/study-skills/digital-skills/using-ai-at-university#use"")
		Risks of using AI(""https://myport.port.ac.uk/study-skills/digital-skills/using-ai-at-university#risks"")
		Using Generative AI in assessments(""https://myport.port.ac.uk/study-skills/digital-skills/using-ai-at-university#assessments"")
		How to acknowledge AI sources in your work(""https://myport.port.ac.uk/study-skills/digital-skills/using-ai-at-university#reference"")
		Privacy and Data Protection(""https://myport.port.ac.uk/study-skills/digital-skills/using-ai-at-university#privacy"")
At the University of Portsmouth, our goal is to assist you in developing strong academic practices and a critical understanding of utilising generative AI tools. This guide will support you in the following:
Using generative AI tools creatively, responsibly and ethically:
		Understand the capabilities and limitations of AI tools;
		Use AI to enhance your learning, not replace your efforts;
		Be mindful of potential biases and inaccuracies in AI-generated content.
Maintaining academic integrity and avoiding academic misconduct:
		Know when the use of generative AI is and is not permitted;
		Clearly distinguish between your ideas and those generated by AI;
		Follow university guidelines and policies on the use of AI in assignments;
		Seek guidance from your lecturers if you are unsure about the appropriate use of AI.
What are AI, Generative AI and Large Language Models?
Artificial Intelligence (AI) is a broad term for computer systems designed to perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation. These systems use algorithms and statistical models to process and learn from large amounts of data, enabling them to improve their performance over time.
Generative AI is a subset of AI that focuses on creating new, original content rather than simply analysing or making predictions based on existing data. Generative AI systems use deep learning techniques, such as neural networks, to produce various types of content, including:
		Text: AI models like ChatGPT, Copilot, Claude and Gemini(""https://gemini.google.com/"") can generate human-like text based on input prompts. These models can assist with writing tasks, answering questions, and engaging in conversations;
		Images: Tools like DALL-E (accessible from ChatGPT and Copilot), Midjourney, Davinci, and Stable Diffusion(""https://stability.ai/"") can create original images and artwork based on textual descriptions provided by users. These systems can generate illustrations, photographs, and even abstract art pieces;
		Audio and Video: Generative AI can produce audio and video content, such as music, speech, and short video clips. Examples include Google's AudioLM and OpenAI's Sora;
		Code: AI models like ChatGPT, Copilot, Claude and Gemini can generate code snippets and assist with software development tasks based on natural language inputs.
Large Language Models (LLMs) are an essential part of generative AI for text-based applications. They are trained on vast amounts of text data, learning patterns, grammar, and language semantics. LLMs can generate coherent and relevant text by processing this data, forming the foundation of AI models like ChatGPT, Claude, and Gemini. The term ""large"" refers to the neural networks' extensive size and the enormous datasets used to train them, ranging from billions to trillions of parameters. The terms Generative AI (GAI) and Large Language Model (LLM) are often used interchangeably, but strictly speaking, LLM should only refer to the specific type of AI model that focuses on processing and generating human-like text based on patterns learned from vast amounts of text data. LLMs are a key component of many Generative AI applications, particularly those involving text generation, but Generative AI encompasses a wider range of AI systems that can create various types of content, including images, audio, and video.
These tools can help with idea generation, inspiration, and the creation of various types of media. However, it is crucial to recognise generative AI's limitations and use these tools responsibly. While generative AI can assist with learning and creative tasks, students must develop their skills, critical thinking abilities, and original ideas rather than relying solely on AI-generated content.
Can I use AI for my studies?
Absolutely, you can! It is important that you use these tools to support your learning and to develop the AI skills employers will expect from graduates. Our approach is laid out in our six principles for the use of AI:
Foster AI Fluency: We will support you in becoming literate in AI technologies and developing critical skills to use generative AI tools effectively, responsibly, and ethically in your learning.
Equip and Support Staff: We will ensure our staff are equipped to guide you in using AI tools appropriately and to enhance your learning experience through AI integration.
Adapt Teaching and Assessment for Ethical AI Use: We will continuously adapt our teaching and assessment strategies to incorporate the ethical use of AI tools, promoting equal access and enhancing educational outcomes.
Uphold Academic Integrity and Rigour: We are committed to transparency in guiding the appropriate and ethical use of generative AI, encouraging proper acknowledgement of AI tool usage, and fostering open discussions about AI without fear of penalty. Currently, we will not rely on AI detection tools to assess your work's integrity.
Promote Collaboration and Innovation: We will foster a culture of innovation, collaboration, and openness in using AI in education, encouraging the sharing of best practices and research findings.
Maintain a Dynamic Approach to AI Evolution: We recognise the rapidly evolving nature of AI technologies and maintain a flexible stance towards their integration, committing to ongoing review and adaptation of policies and strategies.
When using AI tools, it's crucial to critically engage with the generated content, take responsibility for the final output, and ensure your use aligns with our academic regulations. The work you submit should authentically showcase your own knowledge, skills, and efforts while adhering to the specific guidelines of each assessment. AI should support your learning journey, not replace your critical thinking, creativity, and originality. By upholding academic integrity, you demonstrate your commitment to your education and our University's values.
Risks and issues to consider when using Generative AI tools
		GenAI output may seem accurate but often contains factual errors (commonly called hallucinations). You must fact-check any information produced by GAI tools.
		Despite appearances, GenAI lacks understanding of the content it generates, potentially leading to misplaced trust;
		GenAI output imitates or summarises existing content, often without the permission of the intellectual property owners, but it can give the appearance of creativity;
		GenAI can generate content that may pose moral and ethical concerns, raising important issues regarding its use;
		Some AI tool developers have outsourced reinforcement learning from human feedback (RLHF) to low-wage workers;
		GenAI can be misused to generate fake news and deep fakes;
		Reliance on vast data and computing power contributes to the digital divide, favouring large tech companies and certain economies. This means that most people, especially those in the Global South, are unable to create and control GenAI;
		GenAI outputs may reinforce dominant values and marginalise diverse perspectives;
		The complexity of GenAI models makes it difficult to understand the reasons behind specific outputs;
		Significant computational resources are required for training and running GenAI models, raising serious questions about their environmental impact;
		The increasing presence of GenAI-generated content online may recursively influence future GPT models, perpetuating biases and errors.  






















Generative AI (GAI) might appear to think and understand complex topics like a super-intelligent person, but this is an illusion. In reality, GAI systems are highly sophisticated language models that predict the most likely next words based on patterns in their training data. While their outputs can be impressively coherent and human-like, GAI does not truly comprehend the meaning behind the words it generates in the same way a human does.
Using Generative AI in assessments
Generative AI can enhance and support your learning, and we encourage you to experiment with the available tools (you’ll find some ideas in this section). However, when it comes to assessments, not everything is permitted, and it's crucial that you understand what is allowed and what isn’t.  
The Golden Rule
We require that most work submitted for assessment is your own original content, demonstrating your knowledge, skills, and critical thinking abilities. To that end, AI-generated content must not be included in your assessment submissions unless specified in the assessment brief and/or approved by your module lecturer.
Think of it this way: Is it acceptable to have someone else entirely or partially do your assignment for you?
Of course, the answer is no! Doing so would breach the University's Academic Regulations, outlined in the Student Conduct Policy(""https://policies.docstore.port.ac.uk/policy-053.pdf""). Therefore, make sure you apply the following guidance  when working on your assessments:  


Ensure your submitted work is genuinely yours, not just copied or edited from AI-generated content (including writing, images, video, audio and code). Simply editing AI-generated content is not enough for it to be considered your own work! Engage with the material, think critically, and express ideas in your own style and voice to maximise learning and maintain academic integrity.






















Detection Tools
We will not rely on AI detection tools to assess the integrity of student work. These tools often exhibit limitations in their accuracy and fail to provide adequate explanations regarding their scoring methodology and the interpretation of the scores they generate. Importantly, academics can usually spot AI-generated content without the need for specialised detection tools. The writing style, lack of original insights, and inconsistencies in the work may be tell-tale signs of AI involvement.
Categories of AI in assessments
At the University of Portsmouth, the use of GAI in assessments falls into two categories:
Category 1 - AI tools can be used. The use of AI tools in the production of these assessments is permitted. Students can use AI tools as directed by the module coordinator/lecturer(s) and necessitated by the assessment. For example, AI could assist you with analysing data, identifying patterns, or producing novel insights when such tasks are specifically assigned and align with the learning objectives. Most of your assessments will fall into this category. 
IMPORTANT: Content directly produced by AI must not be included in your assessment submissions unless specified in the assessment brief and/or approved by your module lecturer (See “The Golden Rule” above).
Your module coordinator/lecturer(s) will provide information on what is and what is not an appropriate use of GAI tools for each assessment. If in doubt, ask for guidance. 
Category 2 - AI tools cannot be used. Using AI tools to produce these assessments is unsuitable due to their specific learning objectives and structure. Typically, these assessments aim to develop essential knowledge, skills, and abilities for students to excel in their studies and future careers. Examples of assessments where AI might not normally be used could include:
		In-person examinations
		Class tests
		Some online tests
		Vivas
		Some laboratories and practicals
		Discussion-based assessments  
Should I use AI in assessments?
The following questions will help inform your approach to using AI for your assessments:  
		Are you following the module guidance on using generative AI tools for assessments?
		Have you cited and acknowledged any use of generative AI according to the University's guidelines?
		Are you aware that using AI in a way inconsistent with policies and guidelines can result in academic misconduct?
You should be given clear guidance on what use of generative AI is appropriate in any assessment.  
		Is your final work your own, not simply copy-pasted from a generative AI tool?
		Is your style and voice evident in the work?
		Have you applied your critical/creative thinking and logical reasoning to write the assignment rather than simply rephrasing AI-generated content?  
		Are you tracking how you have used generative AI throughout your assignment?
		Are you saving copies of each step to create a record that can be shared with lecturers to facilitate conversations about your work?  
		Are you correctly acknowledging and referencing source materials used in your work?
		Have you used sources besides AI, such as the library, to find relevant and high-quality reference materials?  
		Are you exercising critical thinking and disciplinary expertise when considering AI-generated information?
		Are you fact-checking the information you receive from AI?
		Are you aware of generative AI's limitations, such as potentially outdated or inaccurate content and its limited ability to provide reliable sources?  
		Are you aware of potential biases in the generative AI you are using?
		Are you aware that AI tools may align with commercial objectives or reinforce societal prejudices?
		Are you constantly applying critical thinking, analysing and contextualising AI's outputs, and cross-verifying any information it provides?
		Are you forming your own perspective rather than relying solely on AI-generated content?  























If you choose to use GAI to aid in creating an assessment, always consult with your module coordinator/lecturer(s) before doing so.

Examples of how GAI can be used in assessments
This is not an exhaustive list.
Close all
Text editing and proofreading using GAI (e.g., ChatGPT)
AI-assisted search tools (e.g., Microsoft Copilot, Perplexity.ai, Scite.ai)
Bibliography tools
Text-to-speech and speech-to-text tools
Machine translation (e.g., Google Translate, ChatGPT, MS Copilot, ClaudeAI)
Using AI-generated materials as research sources
Non-text generation, including images, video and audio (e.g., ChatGPT, Gemini, MS Copilot, DALL-E, Stable Diffusion)
Data analysis and presentation (e.g., Copilot, ChatGPT)
Programming and Coding Support
How to acknowledge AI sources in your work
If lecturers have made clear that you may use AI sources in your assessed work, then you should acknowledge, describe and reference its use.
The University Library offers guidance on referencing your use of AI tools(""https://library.port.ac.uk/ref/page840.html#t840""). 
Privacy and Data Protection
Artificial Intelligence (AI) tools present significant benefits but also come with inherent privacy risks. Even when these tools are not directly trained on user inputs, caution is necessary. Staff and students should be vigilant about the data they enter into AI systems.
Best Practices for Data Protection
The first step when considering the use of AI tools should be a necessity assessment. Before inputting personal data (e.g., names, ID numbers, contact details, email addresses, etc), users should carefully consider whether it's necessary to include this information and whether the desired outcome can be achieved without personal details. This critical evaluation helps minimise potential privacy risks from the outset.
If personal data must be used, the principle of data minimisation should be applied rigorously. Users should include only the minimum amount of personal information required to achieve their objectives. It's crucial to avoid unnecessary details such as full names, ID numbers, contact information, and email addresses unless they are essential for the task at hand.
Implementing a privacy-by-design approach is also vital. This means carefully structuring inputs to exclude non-essential personal information and, where possible, using anonymisation or pseudonymisation techniques. By incorporating these practices, data protection becomes an integral part of the process rather than an afterthought.
Configuring AI Tools for Privacy
Most generative AI platforms offer privacy-enhancing options that users should take advantage of. For example, in ChatGPT, users can navigate to Settings > Data Controls and find the option ""Improve the model for everyone."" Disabling this option is generally recommended, especially when working with personal data. This simple step can prevent unintended data uploads, reduce the risk of data breaches, and ensure that personal information isn't used for model training without consent.
Transparency with Students
In an educational context, transparency regarding AI use is paramount. Staff should inform students about the use of AI tools in academic processes, including setting, checking, and marking assessments. They should explain potential impacts on coursework or evaluations and clearly communicate how student data might be used with AI tools. The rationale behind this transparency is rooted in fundamental data protection principles. Students should never be surprised by how their personal information is utilised, especially in an educational environment that increasingly incorporates AI technologies."
53,University of the Arts London,53_UAL.rtf,https://www.arts.ac.uk/about-ual/teaching-and-learning-exchange/digital-learning/ai-and-education/student-guide-to-generative-ai,"Student guide to generative AI
What is generative AI?
Generative artificial intelligence (AI) or Large Language Models (LLMs) are tools that use deep learning models to produce new content such as text, visual content (images/moving image), and audio. It does this by analysing large data sets, learning patterns and relationships, and generating new content that aligns with these patterns. It is important to understand its potential while also considering its limitations and potential risks as more tools adopt generative AI. It is also important to remember that generative AI does not understand concepts and meanings as humans do, but it mimics human behaviour based on probability.
Academic misconduct and generative AI
What is academic misconduct?
Academic misconduct(""https://www.arts.ac.uk/study-at-ual/course-regulations/referencing-and-academic-misconduct"") refers to any form of academic cheating. This includes any act which gains, attempts to gain, or helps others in gaining or attempting to gain unfair academic advantage.
Why should I think about academic misconduct?
If using generative AI tools, you should be aware of whether your use of the tool(s) may constitute academic misconduct via plagiarism. Plagiarism is defined as stealing another person's ideas and presenting them as though they were your own. You can use generative AI in the developmental process of your work (see section ‘Keep track of how you use generative AI’).
You may not use it to generate your work unaltered that you submit for assessment as if it was your own work. The only exception to this, is where the course content/assessment brief permits the use of AI generated work. If you have questions, please speak to your tutor.
How can I avoid plagiarism?
Use the tips below in Keep track of how you use generative AI in your work and in particular referencing your work.
Where can I learn more?
Review UAL’s Academic Misconduct webpage(""https://www.arts.ac.uk/study-at-ual/course-regulations/referencing-and-academic-misconduct"") for more information on what academic misconduct is and how to avoid it.
Speak to your course team (course leader, year leader, or unit leader, tutor, etc.)
How you might use generative AI
There is much excitement around this rapidly developing area, and you may find yourself considering how to you might use this in your studies.
Talk to your tutors
If you are considering using generative AI as part of your assessment you should talk to your tutors during crits, tutorials and/or other feedback sessions. They will have the best understanding of the unit you are studying and how generative AI may and may not be used.
Keep track of how you use generative AI
If you do use generative AI, it is important to show how you have used it. You must do this in two ways unless otherwise agreed with your tutor.
Keep a log
Process is one of the marking criteria at UAL. It is about your journey of learning. In assessments this can take the form of a learning log. Keeping a log may also help you to demonstrate how you are addressing the other UAL assessment criteria, for example analysis and evaluation of Enquiry.
Logs can include:
primary and secondary research log;
diary;
drafts;
process log.
You will often show these to your tutors in the development of your assessments during formative assessment points. In some cases, you may even submit your log for summative assessment (work you submit for grading, usually at the end of a unit).
In the case of generative AI, it could be useful for you to demonstrate how you have used it to reach your final outcome by keeping a prompt log that includes:
the questions you are inputting into AI to generate content (often called a prompt);
what content it generated in response;
how you have reflected on the response or used that content in your assessment.
Reference AI in your work
Like any other sources you may consider using in assessments such as a journal, book or database, you must properly reference (cite) AI in your work. The Cite Them Right website(""https://www.citethemrightonline.com/home"") provides guidance on how to reference generative AI in work.
Read: Cite Them Right generative AI (Harvard) referencing guide(""https://www.citethemrightonline.com/sourcetype?docid=b-9781350927964&tocid=b-9781350927964-217&st=generative+AI"")
Consider your course and unit learning outcomes
Each assessment at UAL is different. A good starting point for considering how you might use generative AI in your assessment is to think about the learning outcomes on your unit.
The learning outcomes of the units you study at UAL tell you what you will be expected to demonstrate when you have completed the unit.
You should think about what you are meant to be learning (your goal) and how you achieve it. You may consider how generative AI tools can help you achieve or potentially impact your learning. If you choose to use generative AI, are you bypassing the skills you should be developing in completing your assessment?
After you have reflected on this, speak to your tutor about potential appropriate uses of generative AI and follow the guidance above on how to keep track of how you have used generative AI.
Things to think about if using generative AI
Be curious about content generated by AI
Just with any other research you do, you should be curious and critical, and evaluate the suitability, accuracy, and source of materials in line with guidance from your course.
Generative AI tools provide responses based on the dataset(s) that it is trained on. This could include data that is out of date and/or biased. In some cases, generative AI can provide responses that are factually incorrect.
Specifically with AI generated text, how do you critically reflect on and ensure that the text responses generated are accurate? If you’re unsure of where the source of the response comes from, then how will you know it’s real, simply made up or reproduce biases?
Be curious about where the data you input is going
Be cautious when inputting data into generative AI tools through prompts and uploading of images, etc. This information may be added to datasets, saved by the tool and further distributed by the models. To protect your privacy and the privacy of others, please avoid entering any private or personal information, or research data, into generative AI tools without prior permission of the author or copyright owner and without knowing how data will be stored and re-used.
Acknowledgements
Thanks to the following authors for writing the initial version of this guide:
Sheldon Chow, David Hopwood, Andy Lee, Luis Parada, Mark Robinson & David White.
In addition, thanks to UAL colleagues who participated in the review of the initial version ahead of final approval through various committee structures such as College Academic Committees and Educational Enhancement Committee."
54,University of Chichester,54_Chichester.rtf,https://help.chi.ac.uk/using-ai-your-studies,"Using AI in your studies

What you need to know
AI tools can be a valuable support in your learning journey — helping you to brainstorm ideas, summarise academic texts, generate revision questions, and consolidate your understanding of complex topics. These tools range from everyday AI like grammar checkers and search engines, to more advanced generative AI (GenAI) tools that can create entirely new content, such as essays, code, or images, based on your prompts. While these technologies can enhance your productivity and creativity, they also come with important limitations and responsibilities. GenAI tools, in particular, can produce inaccurate or misleading information (known as “hallucinations”), including fabricated citations, data, or visuals. There are also concerns around data privacy, copyright, and academic integrity.
As such, it’s important that you understand how to use these tools responsibly and in line with university guidance.
 
Which GenAI tools can I use?
University-supported AI tools 
When using university data (such as lecture content, learning resources, research data, special category or personal data), only use Microsoft Copilot 365,(""https://m365.cloud.microsoft/"") logged in with your official university IT account. This should be verified by a visible green shield, which lets you know that your data will be kept safe.  These tools are designed to comply with our data protection policies and offer better security measures.  
 
When using other AI tools (not licensed or supported by the University) 
If you want to use other AI tools, that are not centrally supported by the university, please ensure that you follow these rules: 
Do not sign up using your university account or email.  
Do not input any university data (such as lecture content, learning resources, research data, special category or personal data(""https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/lawful-basis/a-guide-to-lawful-basis/special-category-data/"")) and don’t upload content from academic books and journals – this is against copyright.  
Do not make audio or video recordings of lectures or meetings using unsupported AI tools.  
AI notetakers/meeting assistants (such as Read.ai) are prohibited.  
 
Note: Grammarly is considered an AI tool and falls under these guidelines. 
University guidance
Using GenAI: Key Rules
University's principals for ethical AI use
Protecting your data, and the University's data

Use of Generative AI in Assessment
For assessed work (e.g. essays, assignments) your department/tutor will state the extent to which GenAI tools can be used.
Check with your department to see which level of AI use is permitted for your assignment. 
Unless your tutor states otherwise, the default is (2) ""AI for Planning and Structuring""
If you are permitted to use AI, then you will need to be transparent about its use (see ‘Evidencing the use of AI tools’). 
 
The University of Chichester AI in Assessment Scale
No. |Rule |Student Guidance |
1 |No AI – Independent Knowledge Demonstration | 
You must complete the task without any AI assistance. 
Focus on demonstrating your own understanding and skills. 
Prepare using traditional methods (notes, textbooks, discussions). 
 |
2 |AI for Planning and Structuring | 
You may use AI to generate ideas, outlines, or research questions. 
Your final submission must show how you refined and built on these ideas. 
Keep records of your AI interactions and cite them if required. 
 |
3 |AI for Editing and Refining| 
You may use AI to help edit or refine your work. 
You must critically assess and improve any AI-generated content. 
Clearly indicate where AI was used and how you modified it. 
 |
4 |AI for Task Completion with Human Evaluation | 
You may use AI to complete parts of the task. 
You must demonstrate your understanding by evaluating or extending the AI’s work. 
Include commentary or annotations explaining your decisions. 
 |
 5 | AI Exploration and Co-Design | 
You are encouraged to use AI creatively to solve problems or explore new ideas. 
You may co-design the task with your instructor. 
Document your process and reflect on how AI shaped your work. |
Evidencing the use of generative AI tools

Student declaration of AI use
As a minimum requirement, you are required to include a statement on your assignment describing your use of AI. 
If you have not used AI, please include the following statement: 
 
""No content generated by AI technologies has been presented as my own work and I have not used AI at any stage of the assignment writing process.""
 
To acknowledge AI use, please include the following information:  
The name and version of the GenAI system used (such as Microsoft Copilot (version GPT-4) or ChatGPT-3.5). 
Specify the publisher of the GenAI system (for example, Microsoft or OpenAI). 
Provide the URL of the GenAI system. 
Include a brief description (single sentence) outlining the context in which the tool was utilised. 
For example: 
“I acknowledge the use of Microsoft Copilot (version GPT-5, Microsoft, https://copilot.microsoft.com/(""https://copilot.microsoft.com/"")) to summarise my initial notes and to proofread my final draft” 
 
“I acknowledge the use of Microsoft Copilot (version GPT-5, Microsoft, https://copilot.microsoft.com/(""https://copilot.microsoft.com/"")) for initial research and to suggest a structure for my essay” 
 
Enhanced declaration 
Your department or tutor may require you to provide additional information about your AI usage.  
You may be asked to provide further details in an 'Appendix' section, such as: 
The prompt(s) used to generate a response in the GenAI system, if applicable. 
The date when the output was generated. 
The output obtained (for example, a ‘link to chat’ if ChatGPT was used, or a compilation of all generated outputs in an appendix). 
An explanation of how the output was modified before being incorporated into the work (such as with a tracked-changes document or a descriptive paragraph). 
 
As such keep a record of how you have used it. Retain this information until your work has been assessed. 
 
Citing AI use within assignments
Some referencing guides offer suggestions for how GenAI systems should be cited within an essay and in the reference list. However, there are issues with citing GenAI systems: 
A GenAI tool cannot be classed as an author: it cannot take responsibility for its work, nor does it generate original ideas but reproduces ideas found elsewhere.  
A reference list is designed to enable the reader to refer to the original source, which is not always possible with AI generated content.  
There may be cases where it is appropriate to cite AI generated content within the body of your essay, for example, where the assignment focus is on the topic of GenAI and its output. If in doubt, please check with your department.  
If you do need to reference GenAI in your work, then use your department’s preferred reference style. Referencing guides can be found on the Study Skills help pages(""https://moodle.chi.ac.uk/course/view.php?id=62812&section=5""). 
 
Here is an example of how to reference GenAI in the Harvard style: 
 
In-text citation: 
When prompted to define ‘authenticity’, ChatGPT (OpenAI, 2022) responded… 
Reference list: 
OpenAI (2022) ChatGPT: Optimizing Language Models for Dialogue. Available at https://openai.com/blog/chatgpt/(""https://protect-eu.mimecast.com/s/gAo2CD0z6fBmnV2H5Ijm6?domain=openai.com/""). (Accessed: 30 June 2023) 
Referencing AI generated images
Copyright safe image sources: https://help.chi.ac.uk/copyright-safe-image-sources(""https://help.chi.ac.uk/copyright-safe-image-sources"")  
 
Important: While AI-generated images may appear to be copyright-free, this is not always the case. Some AI tools are trained on copyrighted material without permission, which can raise legal and ethical concerns. Always check the terms of use for the tool you are using, and avoid using AI-generated images in assessments or publications unless you are confident they comply with copyright and academic integrity guidelines.
 
Example of how to reference AI generated images (examples using Harvard style, please consult your department’s referencing guide for advice on other referencing styles): 
 
In-text citation 
Hotpot AI (2024) was used to create a beach scene. 
Reference list 
Hotpot AI (2024) AI generated image by Hotpot AI art generator with prompt ‘Draw a beach with white sand, turquoise sea and blue sky’, 23 May. Available at: URL (Accessed: 31 May  2024)."
55,University of Stirling,55_Stirling.rtf,https://libguides.stir.ac.uk/c.php?g=720419&p=5234850,"Use of Generative AI in Academic Work
You must be honest and transparent about any use of Generative Artificial Intelligence(AI) technologies such as ChatGPT in your academic work. Using AI inappropriately may be considered as plagiarism or cheating and treated under the University's Academic Integrity Policy and Academic Misconduct Procedure(""https://www.stir.ac.uk/about/professional-services/student-academic-and-corporate-services/academic-registry/academic-policy-and-practice/quality-handbook/"").  Please consult your module and course guidelines on appropriate use of AI tool for your assessments. 
Crucially, you must acknowledge your use of any AI in your work by citing it in your text and providing full details in your reference list or bibliography. Some examples are provided below but be aware that guidance might change as this is a developing technology. 
Citing and Referencing AI - Non-recoverable Content
Content from AI is usually produced in response to your questions and prompts and tailored according to what you ask. Unlike other digital material it is not published and does not persist as a resource that can be linked to or retrieved again. This makes it difficult to meet one of the referencing objectives that is to enable the person reading your work to follow up and check the original source.
This is referred to as 'non-recoverable' content. As the content is produced in response to your interaction with the AI, many referencing styles recommend that it is cited as a 'personal communication'.
Some styles recommend crediting the source only in your text or in a note but others require a full reference in the reference list or bibliography.

 Add / Reorder  
Additional Information
As well providing in-text citation and references to your use of AI, you may be asked to provide additional information e.g.:
Appendix: Some referencing style guides e.g. APA , suggest that you copy the text of AI responses in an appendix so that  the reader can see the exact text that was generated. Please check what is required in your assessment and module guidance.
Description: You may be required to describe how the AI information or material was generated e.g. what prompts did you use, how did you use or change the output content or to provide a copy of the output (in an appendix). Please check what is required in your assessment and module guidance.
Further Acknowledgements: You may be required to provide a statement of the extent to which AI content was used in your work e.g. not used, background research only, editing structure and presentation etc. Please check what is required in your assessment and module guidance.
APA
The APA Style team have written the following guidance on citing AI, available here in detail:  
How to cite ChatGPT (apa.org)(""https://apastyle.apa.org/blog/how-to-cite-chatgpt"")  
A summary of the recommendations: 
The results of a ChatGPT “chat” are not retrievable by other readers, and although nonretrievable data or quotations in APA Style papers are usually cited as personal communications(""https://apastyle.apa.org/style-grammar-guidelines/citations/personal-communications""), with ChatGPT-generated text there is no person communicating.  
Quoting ChatGPT’s text from a chat session is therefore more like sharing an algorithm’s output; thus, credit the author of the algorithm with a reference list entry and the corresponding in-text citation. 
Example: 
When prompted with “Is the left brain right brain divide real or a metaphor?” the ChatGPT-generated text indicated that although the two brain hemispheres are somewhat specialized, “the notation that people can be characterized as ‘left-brained’ or ‘right-brained’ is considered to be an oversimplification and a popular myth” (OpenAI, 2023). 
Reference 
OpenAI. (2023). ChatGPT (Mar 14 version) [Large language model]. https://chat.openai.com/chat(""https://chat.openai.com/chat"") 
See the blog post for further information, including adding full text of long responses from ChatGPT in an appendix. 
 
Chicago
You must credit the AI tool (such as ChatGPT) when you reproduce its words within your own work, but unless you include a publicly available URL, that information should be put in the text or in a note—not in a bibliography or reference list.
Create a footnote or endnote, e.g.
¹ Text generated by ChatGPT, OpenAI, March 7, 2023, https://chat.openai.com/chat(""https://chat.openai.com/chat"").

Template for the footnote: Text generated by Name of AI, Publisher/developer, Month day, year, URL.

If the prompt hasn’t been included in the text, it can be included in the note:
¹ ChatGPT, response to “A definition of academic integrity,” OpenAI, March 7, 2023.

Additional information is provided in the Chicago Manual of Style Q & A(""https://www-chicagomanualofstyle-org.ezproxy-s2.stir.ac.uk/qanda/data/faq/topics/Documentation/faq0422.html"").
Harvard
Generative AI
If the generative AI material is available online, you can cite it as an electronic version of a source (such as an artwork or article).
Citation order 
Creator (name of AI)
Year (in round brackets)
Title of Work (in italics)
[Medium]
Available at: DOI or URL (Accessed: date)
For example:
In-text citation
The AI-generated flower (Shutterstock AI, 2023)....
Reference List
Shutterstock AI (2023) Photo of pond with lotus flower [Digital art]. Available at: https://www.shutterstock.com/image-generated-lotus-flower-2252080005 (Accessed: 31 March 2023)
If the AI's end product (for example use of ChatGPT in conversation) is only available to you, cite this as a personal communication and include a description of the AI generated material in your in-text citation.  Consult your tutor in case they require you to provide a copy of the AI work as an appendix to your work. 
Citation Order
Name of AI
Year of communication (in round brackets)
Medium of communication
Receiver of communication
Day/month of communication
For example:
In-text citation
When prompted by the author, ChatGPT responded with a 'definition of academic integrity' (OpenAI ChatGPT, 2023).  A copy of this response is in Appendix 1.
Reference List
OpenAI ChatGPT (2023) ChatGPT response to John Stephens, 2 April.
IEEE
The IEEE has not yet advised on citing AI-generated content. The IEEE Style Manual suggests consulting the Chicago Manual of Style for usage it does not include. The following guidance is therefore adapted from recommendations in the Chicago Manual of Style(""https://www-chicagomanualofstyle-org.ezproxy-s2.stir.ac.uk/qanda/data/faq/topics/Documentation/faq0422.html"").
It is helpful to include details of your question or prompt in your footnote if this is not described in your text.
As there is no link that others may use to access the same content the web address is not essential but may be given as the main URL where the AI tool is located (as in examples below).
As the date that the content was generated is specific to your interaction with the AI, it is not necessary to give date accessed.
Example 1: If the prompt hasn’t been included in the text, it can be included in the reference:
Template: Name of AI response to ""prompt"", Publisher/Developer, Month day, year that content was generated, URL.
1. ChatGPT, response to “A definition of academic integrity,” OpenAI, March 7, 2023, https://chat.openai.com/chat(""https://chat.openai.com/chat"").
Example 2: Question or prompt is described in the document text so is not repeated in the reference:
Template: Text generated by Name of AI, Publisher/Developer, Month day, year that content was generated, URL.
1.Text generated by ChatGPT, OpenAI, March 7, 2023, https://chat.openai.com/chat(""https://chat.openai.com/chat"").
 
 
 
OSCOLA
OSCOLA has not yet  provided specific guidance for citing and referencing AI. This recommendation is adapted from OSCOLA 3.4.11 Personal Communications ,which states:
""When citing personal communications, such as emails and letters, give the author and recipient of the communication, and the date. If you are yourself the author or recipient of the communication, say ‘from author’ or ‘to author’ as appropriate.""
It is helpful to include details of your question or prompt in your footnote if this is not described in your text.
As there is no link that others may use to access the same content give the Web address where the AI is located.
As the date that the content was generated is specific to your interaction with the AI, it is not necessary to give date accessed.
Footnote
Template: Creator and/or name of AI | Form of communication giving prompt or question if not provided in your text | (Date content was generated) 
Example 1: If the prompt hasn’t been included in the text, it can be included in the note:
¹ OpenAI ChatGPT response to prompt 'What are the legal profession's concerns about using ChatGPT to inform student work?' (16  August 2023) <openai.com/chatgpt(""https://openai.com/chatgpt"")>
Example 2: Question or prompt is described in the document text:
¹ OpenAI ChatGPT response to author (16 August 2023) <openai.com/chatgpt(""https://openai.com/chatgpt"")>
Bibliography Entry
As the content cannot be linked to and accessed by others a reference is not essential in the bibliography but may optionally be included:
Template: Creator and title of AI, | medium of communication and receiver of communication | < URL where AI can be accessed > |
Example: OpenAI ChatGPT, Chat GPT response to author (16 August 2023) <openai.com/chatgpt(""https://openai.com/chatgpt"")>
 
 
SLS - Referencing and Avoiding Plagiarism

See the Referencing and avoiding plagiarism module in Canvas for more guidance about plagiarism and help with referencing. This is brought to you by Student Learning Services(""https://www.stir.ac.uk/student-life/support-wellbeing/student-learning-services/"").
All new students should complete the 'Academic Integrity and Writing(""https://canvas.stir.ac.uk/courses/16114"")' module within your first 4 weeks at university. It is also useful to revisit this module if you are struggling with your writing and referencing or have received feedback on plagiarism."
56,University of Kent,56_Kent.rtf,https://student.kent.ac.uk/studies/using-generative-ai-in-your-studies,"Using Generative AI in Your Studies
Your guide to using AI ethically and effectively at Kent.
How this guidance can help you
Generative AI tools are becoming part of how people learn, work, and create across education, industry, and everyday life.
Many students are already using these tools to explore ideas, organise their work, or get feedback, but using AI in your studies comes with responsibilities.
This guidance will help you:
Use AI to support your learning, not replace it.
Prompt more effectively to get useful, reliable responses.
Stay on the right side of Kent’s academic integrity expectations.

Whether you’re just getting started or already experimenting, the links below will help you make informed, ethical choices as a Kent student.  

AI at Kent: Our Approach
Kent’s commitment to responsible and ethical AI use in education.
Kent's Position on AI
The University of Kent recognises the importance of AI literacy for students and staff. Therefore, the University is committed to educating individuals on the ethical and responsible use of generative AI while maintaining academic rigour and integrity.
Generative AI tools, can support your learning when used responsibly. At Kent:
Your work must remain your own. AI can assist you in researching and developing understanding, but it cannot replace your critical thinking or creation of work.
Rules for AI in assessments are set at the module level. Always check your assessment  brief and do not presume use beyond the standard is acceptable . If unsure, ask your convenor.
Transparency matters. When required, you must declare AI use in assessments.


Using AI the Right Way
Your starting point for responsible AI use. Explore the guidance pages(""https://student.kent.ac.uk/studies/using-generative-ai-in-your-studies/ai-use-guidelines"") for more information and advice
Use AI ethically and responsibly.


Follow guidance provided by your module convenor.


Do not submit AI-generated work as your own.


Do not share personal data with AI tools.


AI and Academic Integrity
As a student at the University of Kent, it is important to understand the significant role of generative AI technology and its relationship with academic integrity. While Generative AI tools can be valuable in your learning and preparing for assessments, it is crucial to distinguish between using Generative AI for these purposes and generating content that you cannot claim as your own work.
Academic Integrity
We encourage you to use Generative AI for educational purposes such as:
✅ Brainstorming ideas  ✅ Breaking down course readings to build up to a fuller knowledge ✅ Helping you to build understanding of a concept   
However, the content of your submitted assessments must be your own work. Presenting a Generative AI output or another person’s work as your own is a breach of academic integrity. You are expected to engage in good academic practice that is consistent with the University's six fundamental values of academic integrity: honesty, trust, fairness, respect, responsibility, and courage.
For more comprehensive guidance on using AI in your studies, please click here to visit our Moodle module, ""Generative AI: Developing your AI Literacy"".(""https://moodle.kent.ac.uk/2025/course/view.php?id=22"")
You can also visit our extensive prompt bank to see examples of appropriate use of AI. Click here to access Kent AI Prompt Bank(""https://student.kent.ac.uk/studies/using-generative-ai-in-your-studies/prompt-bank"").
The University recognises the potential for the use of Generative AI to enable academic dishonesty in assessments. The University is updating its regulations on academic misconduct to clarify Policy around the use of Generative AI in your learning and assessment.
View the Academic Misconduct Policy
What You Need to Know
Assessment-level guidance is key
Each assignment or module may have different rules about whether and how AI tools can be used. Always check your assignment brief or ask your Module Convenor if you're unsure.
Academic integrity still applies 
Whether or not AI is used, the final submission must demonstrate your own understanding and academic judgement. Submitting content that misrepresents your contribution, whether written by another person or AI, is a breach of academic integrity. 
What ‘Your Own Work’ Means When Using AI 
In some cases, you may be permitted to incorporate AI-generated content, similar to how you might incorporate ideas from books or websites, with clear attribution and academic judgment.
In others, no AI use may be allowed at all. The key principle is honesty and transparency, guided by your specific assessment requirements.
Unless it is otherwise noted, you should:
Not include materials generated by AI in your submissions.
Not submit materials that you have written but that have been substantially altered by AI (i.e. beyond what could be done by spellchecking or grammar checking software that does not have an AI enabled component).
⚠️ Generative AI Declaration
Some Schools may ask you to include a short declaration in your assessment submissions to confirm whether you have used Generative AI. 
Where required, the wording and expectations for these declarations will be specified in the assignment brief.  
By following this guidance, you can use Generative AI responsibly while maintaining academic integrity and avoiding misconduct.  
Using AI Wisely
AI is a tool, not a shortcut. Stay in control.
Protect Your Learning
Over-Reliance on AI Can Harm Your Skills
University is about developing skills like critical thinking, creativity, and problem-solving. If you rely too much on AI, you lose the chance to develop these skills for yourself.
Whilst future employers may (or may not) expect you to use AI in your work, being unable to use AI tools appropriately (including choosing when not to use them) may result in serious consequences for your career, your prospects, and for others.

Some of the risks
Letting Al Do the Thinking
If you always turn to Al to think for you, you won't develop problem solving skills, harming your future prospects. Developing these skills now will help you for life.

Not Checking Your Understanding
Relying on Al means you stop asking, ""Do I really get this?"". True learning happens when you challenge and test your understanding.

Losing Your Critical Edge
Al can summarise information, but it won't teach you the reasoning skills needed to interpret and evaluate ideas for yourself.

Staying Employable
Employers value graduates who can effectively harness Al while maintaining control, identifying mistakes, thinking critically, and making informed decisions.


AI isn’t always right
Why You Can’t Trust AI Completely
Generative AI sounds confident, but it doesn’t think like a human. It predicts patterns in data, which means:
AI can make mistakes and create fake references.
AI reflects biases in its training data, which can lead to stereotypes.
AI lacks real-world judgment, its answers can sound right but be wrong.
AI is designed to ""understand"" you and provide you with an answer even if your prompt does not make sense.
If you include errors or bias from AI in your work, you are responsible for them.



Stay in control
Make AI Work for You, Not Against You
Use AI to spark ideas, not replace your thinking.
Rewrite AI outputs in your own words and add your perspective.
Verify facts, don’t assume AI is correct.
Limit AI use for summaries, do the hard reading yourself.
Want better results when you use AI? Learn how to write effective prompts on our ""Prompting Tips page"":

Ethics: Responsible AI Use
How to use AI ethically, legally, and sustainably in your studies.
Why Responsible AI Use Matters
Using AI responsibly means more than avoiding plagiarism. It’s about acting ethically, protecting your data, respecting copyright, and understanding the environmental impact of AI. These pages will help you use AI in a way that supports your learning — and avoids risks.

AI Ethics
How to use AI with integrity, fairness, and transparency.
Generative AI tools can support your learning, but only when used ethically. This means using AI in a way that aligns with Kent’s commitment to academic integrity: being honest, transparent, and taking full responsibility for your work.  
Core Ethical Principles
1. Academic Honesty & Transparency
AI use should never be hidden. If your module allows AI use, you must be clear about when and how you’ve used it. This is essential for maintaining trust and integrity in your work.
Follow your module guidance on AI use.
If AI contributes to your work, disclose this clearly and cite it when required.
Never present AI-generated text or ideas as entirely your own.
Learn how to make a correct declaration on our ""AI and Academic Integrity"" page below: 


AI and Academic Integrity
2. Human Oversight  
AI is not a replacement for your own thinking. It can produce incorrect or fabricated content (known as hallucinations), so using AI responsibly means verifying its output.
Always review, fact-check, and evaluate AI outputs.
Use AI for support, not as the creator of your work.
Remember: your critical thinking, not the AI, must guide the final work.
3. Fairness, Bias & Cultural Sensitivity
AI tools are trained on existing data, which can include biases or stereotypes. This means their responses might reflect limited perspectives. Ethical use involves questioning and challenging these patterns.
Evaluate responses for bias and inclusivity to avoid reinforcing stereotypes.
Be mindful of cultural and social implications when interpreting AI-generated content.
Check multiple sources, not just AI outputs, for diverse viewpoints.
David Barnes, a senior lecturer from the School of Computing, talks about how AI tools work and why we must be mindful when using these tools. 


How AI tools work
4. Accountability & Integrity
Even if AI assists you, the responsibility for your work remains yours. Ethical use means owning your decisions and being ready to explain them.
You are responsible for all submitted work.
Be prepared to explain how and why you used AI if asked by your lecturer.
For more on citing AI correctly, visit our ""Academic Integrity and AI"" page below: 


AI and Academic Integrity
When AI Use Becomes Misuse
Using AI can cross into unethical territory when it replaces your own work or violates academic integrity. These behaviours put you at risk of academic misconduct:
Generating and submitting content produced by AI instead of completing the work yourself.
Copying and pasting AI content, leading to errors, false references, or plagiarism.
Ignoring module-specific rules on AI use such as failing to declare AI assistance when required.
Always check your module’s guidance and use our AI Declaration page(""https://student.kent.ac.uk/studies/using-generative-ai-in-your-studies/ai-use-guidelines/ai-and-academic-integrity"") to disclose AI use correctly.
Quick Ethical Check
Before submitting work, ask yourself the following questions:
“Could I explain how and why I used AI in this work if asked?”
""Is all material I am submitting my own?""
""Have a double checked all AI generated materials before using them to guide my own research?""
If the answer to any of these questions is ""no"", you need to rethink your approach.

Copyright and AI
Understand the copyright rules when using AI in your studies.
When using Generative AI, you must follow copyright law and the University’s licence agreements with publishers.
University of Kent Library resources, including databases and their contents (such as abstracts and indexing), journal articles, eBooks, images, charts, videos, audio recordings, artworks, and musical works, are usually protected by copyright and subject to licence agreements. These agreements often restrict how you can use them.
Do not paste or upload these materials into AI tools even for study or research purposes.
What You Should Do
Use library resources only for their intended purpose, your own study and research within the University’s terms of use.
Summarise ideas in your own words before entering them into an AI tool (never copy large sections).
When creating original work with AI, check for potential copyright issues, especially if you plan to share or publish it.
Note AI-generated content appropriately where required (see Academic Integrity guidance(""https://student.kent.ac.uk/studies/using-generative-ai-in-your-studies/responsible-ai-use/copyright-and-ai"")).
Help
The Copyright team provide advice, training and specific guidance on copyright law to support you in your work and study. If you have any questions about copyright, email:


Copyright team
Click the button below to return to the AI home page.

Data Privacy
Generative AI tools process everything you type, and many use this data to train their systems. This means anything you enter may not stay private. Understanding these risks will help you keep your personal and academic information safe.
Are you a member of staff?
If so, please access SharePoint for guidance relevant to you.
Please access Data Protection's guidance on AI use by clicking here to ensure any use is compliant.(""https://livekentac.sharepoint.com/sites/Assurance-DP/SitePages/Artificial-Intelligence-and-Data-Protection.aspx?xsdata=MDV8MDJ8Ty5QZXJyb3R0LVdlYmJAa2VudC5hYy51a3wwMjU3Y2NkZTc2YmM0NTE1YmFkMTA4ZGUwMThjM2E1YXw1MWE5ZmE1NjNmMzI0NDlhYTcyMTNlM2Y0OWFhNWU5YXwwfDB8NjM4OTQ5ODk4OTU0NjUzMzE0fFVua25vd258VFdGcGJHWnNiM2Q4ZXlKRmJYQjBlVTFoY0draU9uUnlkV1VzSWxZaU9pSXdMakF1TURBd01DSXNJbEFpT2lKWGFXNHpNaUlzSWtGT0lqb2lUV0ZwYkNJc0lsZFVJam95ZlE9PXwwfHx8&sdata=bzdTd3J0c3JBRk8weXE5eTBhUXNUUVplbW5RWkp4akJpeU5weXdlMTBxYz0%3d&clickparams=eyAiWC1BcHBOYW1lIiA6ICJNaWNyb3NvZnQgT3V0bG9vayIsICJYLUFwcFZlcnNpb24iIDogIjE2LjAuMTkxMjcuMjAyNjQiLCAiT1MiIDogIldpbmRvd3MiIH0%3D"")
Guidance for students
Many commonly used AI tools can store, share, or be trained on the data that you input. This means if you input personal information, such as names, email addresses, opinions about people, confidential information, or other people’s work into an AI model, that data will no longer be in your control and could be used in ways you did not expect, including forming part of the output generated for other people.
For these reasons, you should not enter personal information, confidential information or other people’s work into an AI tool.
It is important to be aware that free AI tools don’t have the safety considerations in place that approved tools do.  Where possible, you should use the University’s licenced AI products as these offer greater security in terms of how the input can be used by the technology provider through stronger contractual agreements.
Understanding these risks will help you keep your personal and academic information safe.
Why This Matters
Generative AI works by analysing huge amounts of data, including your inputs. If you enter personal or sensitive information, you risk:
Personal data exposure – Your personal information could become public.
Breach of confidentiality – Sharing sensitive third-party data or research participant data without consent could present a serious breach of data protection law and/or confidentiality.
Loss of control over intellectual property – Unpublished or proprietary material could be stored and reused by AI providers.
Your data being reused – Many AI tools use your content to improve their models in ways you may not expect.
Example: If you enter your full name and contact details when asking a question in an AI tool, that information could later appear in a response given to someone else.
If you are doing a research project that involves human participants and you would like to use AI, please contact the Data Protection Office and visit our SharePoint page(""https://livekentac.sharepoint.com/sites/Assurance-DP/SitePages/Data-Protection-and-Ethics-process-integration.aspx?e=4%3A812155fa890e4d1c84a9143a38725938&web=1&sharingv2=true&fromShare=true&at=9&clickparams=eyAiWC1BcHBOYW1lIiA6ICJNaWNyb3NvZnQgT3V0bG9vayIsICJYLUFwcFZlcnNpb24iIDogIjE2LjAuMTg5MjUuMjAxODQiLCAiT1MiIDogIldpbmRvd3MiIH0%3D&CID=87c2b7a1-2003-d000-6cd9-3dd23a951ef0&cidOR=SPO"") for guidance at the start of your project.
Important take-away points
Keep personal and sensitive data out of AI tools. Do not input information that can identify you or other people, or confidential information such as health data, passwords and bank details.
Protect intellectual property. Do not enter unpublished research, or the work of other people without their permission.
Check the tool’s terms and privacy settings. Understand how your data will be stored or used before entering any content.
✅ Where possible, turn off data collection.
For example:
ChatGPT allows you to disable chat history(""https://openai.com/index/new-ways-to-manage-your-data-in-chatgpt/"") so your conversations won’t be used to train the model. Other models have similar features too.
Choose trusted tools. The University of Kent’s Microsoft Copilot Chat includes enterprise-level protections against data collection.


Copilot Guidance
Tip for Safer Use
If you’re unsure whether something is safe to share, don’t share it. Treat AI tools like social media. Always ask yourself:
“Would I be happy if this appeared online?”
If the answer is no, keep it out of AI tools.
Click the button below to return to the AI home page."
57,University of the West of England,57_UWE.rtf,"https://www.uwe.ac.uk/study/academic-information/artificial-intelligence-principles#:~:text=Students%20will%20be%20advised%20when,AI%20tools%20without%20appropriate%20acknowledgement.","Principles for using generative artificial intelligence (AI)
Providing guidance for AI use in learning, teaching and assessment.
Generative artificial intelligence (AI) algorithms like ChatGPT create original content including text, images, audio and video. This technology allows computers to generate new information and creative artifacts, not just analyse data.
UWE Bristol is committed to harnessing the transformative potential of generative AI to enhance learning, teaching and assessment. We aim to support students and staff to become AI-literate, equipped to drive progress and innovation through the ethical use of these powerful technologies.
Aligned with our Strategy 2030(""https://www.uwe.ac.uk/about/values-vision-strategy/strategy-2030""), these principles provide guidance on utilising generative AI across educational provision at UWE Bristol while upholding our values of being ambitious, innovative, inclusive, collaborative, and enterprising.
We will collaborate to share knowledge, contribute to best practices, and foster inclusive AI ecosystems that enhance personalised, accessible learning and empower diverse communities.
These principles will continue to develop, as we continue to support all students to succeed.
1. Enhancing the student experience
1.1.|We will be ambitious and use generative AI to enrich personalised learning and sharpen critical thinking.|
1.2.|We will leverage generative AI to make inclusive learning environments more accessible, creating opportunities for diverse communities to co-create.|
1.3.|We will empower students and staff to use AI in enterprising yet ethical ways, encouraging creativity and collaboration.|
1.4.|Recognising potential disparities in AI literacy, we will proactively address unequal access and skills gaps.|
1.5.|All students will have opportunities to meaningfully engage with generative AI during their studies.|
2. Developing assessment and curricula
2.1.|Students will be advised when and how it is permissible to use generative AI in assignments and assessments.|
2.2.|It is an academic offence to download material from the web and submit it as your own work or submit work created by using AI tools without appropriate acknowledgement.|
2.3.|Students guided to use AI should consult our referencing guide and study skills resources(""https://www.uwe.ac.uk/study/study-support/study-skills#ai-guides"").|
2.4.|We recognise there will be diverse approaches to AI across our communities and at the level of specific assessments. Teams will be supported to agree an approach at programme level.|
2.5.|Teaching teams are empowered to develop innovative curricula and assessments that authentically integrate AI skills for their subject.|
2.6.|To uphold ethical principles, protect privacy and respect intellectual property rights, we will not submit student work to platforms unapproved by the University without the student's consent.|
2.7.|Policies, guidelines and detection tools will be regularly reviewed, considering generative AI's impact on teaching, learning and assessment.|
3. Developing AI literacies
3.1.|We are committed to upskilling our community to develop confidence and AI literacy through tailored training and resources focused on ethical use.|
3.2.|We will facilitate collaborative projects enabling staff and students to engage with AI, share best practices, and co-create literacy resources.|
3.3.|We acknowledge that outputs from generative AI can be of poor quality, contain false information and faulty citations. We will equip staff and students to critically analyse content and understand limitations.|
3.4.|We will provide development opportunities for staff to effectively evaluate and integrate AI tools into their work.|
3.5.|We will empower staff and students to recognise AI risks, biases against groups and challenge unethical usage.|
3.6.|We will collaborate with partners to exchange ideas and develop best practices around emerging AI technologies within teaching and learning.|"
58,University of Plymouth,58_plymouth.rtf,https://plymouth.libguides.com/Ailibraryskills/usingAI,"What is Generative AI?

Generative AI is a type of artificial intelligence that can create new content, such as text, images, videos, audio, and even software code, based on the data it has been trained on. 
Generative AI models are trained on large datasets, learning the patterns and structures within the data. Once trained, these models can generate new content by predicting the next element in a sequence(""https://www.ibm.com/topics/generative-ai%22%20/t%20%22_blank""), such as the next word in a sentence or the next pixel in an image. 
As the number of embedded AI technologies increases within the software packages we commonly use, there is an increasing need to develop your awareness, digital skills and critical thinking to ensure that you approach these tools effectively and ethically, and without negatively impacting on the development of your own skills and knowledge.

Using Copilot securely

Microsoft Copilot is available for both University of Plymouth staff and students through the Edge Browser    
Go to the search bar within the Edge browser
log in with your UoP email to access the secure version
Once logged in, a green tick in the shield indicates that it is secure and confidential

When logging in this way Copilot offers commercial data protection, safeguarding searches and data
When visiting a website, you can use Copilot to analyse it. This uses Bing data, and anything produced is not secure. This is fine for public websites, but we need to be mindful not to use this on anything secure.
The ""attach file"" option is recent, allowing us to upload files and ask Copilot to analyse them.The requests need to be detailed enough for Copilot to analyse them. To do this, go to the Copilot icon on the top right of the page.

Using AI
Key things to remember if you are using AI
Ethical use|AI should be used ethically and in guidance with university student regulations(""https://www.plymouth.ac.uk/student-life/your-studies/essential-information/regulations""). If you are unsure, then it is important that you follow instructions from your lecturers.|
Sustainability|Consider the environmental impact(""https://news.mit.edu/2025/explained-generative-ai-environmental-impact-0117"") of using AI.|
Copyright|Consider the Intellectual Property and Copyright(""http://plymouth.libguides.com/copyright/studying"") implications of using AI.|
Think critically|Approach any information the AI tool produces cautiously, be a critical reader and fact check responses.|
Supplemental material|AI tools should only be used as a supplement to your research, not as a replacement.|
Use good prompts|Check your prompts(""https://plymouth.libguides.com/c.php?g=708948&p=5283372""). The information you get out is only as good as the requests you put in.|
Potential negative impact to academic developement|By using AI in a way which might undermine your skills as a university student, you will not be achieving your learning outcomes, so it may affect your academic development.|
Reference AI
You should reference use of AI tools 

As the content recalled from AI tools cannot be replicated by another person and cannot be linked to, we recommend that you reference the outputs from generative AI, in the same way that you would a personal communication or correspondence.  
There is Harvard guidance on referencing generative AI on Cite them Right.(""https://www-citethemrightonline-com.uoelibrary.idm.oclc.org/sourcetype?docid=b-9781350927964&tocid=b-9781350927964-217&st=generative+ai"") 
Cite them right also has some background information on AI tools and academic work.(""https://www-citethemrightonline-com.plymouth.idm.oclc.org/search-results?any=Generative%20AI"")
Limitations of Using AI
Risks with using information from Generative AI Tools
Not primary sources|Information obtained from Generative AI tools should not be considered a primary source and should be used in conjunction with other sources.|
Potential inaccuracies|AI models can sometimes produce incorrect or biased information, it's crucial to verify information with other sources before including it in your work. |
No critical thinking|Understand that Large Language Models are designed only to summarise, predict and generate texts. They won’t do the thinking for you.|
Potential breach of academic conduct|Never submit chunks of text produced by AI as your own work. You may be in breach of the academic conduct regulations.|
Warning about Personal Information
Large Language models use large amounts of data to generate its responses. This raises concerns about data privacy and security. With the new voice and image capabilities this is a further data privacy concern.
Ensure you do not give away personal details and/or confidential information.
		

Prompting
In the context of GenAI, a 'prompt' is the input or query provided to the AI model to generate a response. It can be a question, a statement, or any text that guides the AI on what kind of output is expected. The quality and clarity of the prompt can significantly influence the relevance and accuracy of the AI’s response.
Prompt engineering is the practice of designing and refining prompts to effectively guide GenAI models to produce accurate and relevant outputs.
Prompt engineering requires critical thinking skills and some technical knowledge of how GenAI works, but developing even basic skills in effective prompting can help you get the most out of using GenAI.
Tools to help with critical evaluation
There are various tools easily found online that are there to help you learn how to evaluation information that you find effectively. Watch the slideshow below to find out more....
Beware of pitfalls!
It is easy to fall into the trap of making assumptions about information you find based on appearance, official-looking banners etc. This section explains why you need to be careful and learn to question what you are looking at!
Reading and Summarising
Scholarcy(""http://www.scholarcy.com/"") An AI summarising tool that can read through books, research papers, journal articles PDF's and Word documents and break them down into bite sized sections (or 'flashcards'), to help you quickly assess the information within, such as themes, findings limitations and data. 
Audemic (""https://audemic.io/"")- This tool creates short written summaries or audio files from academic articles. It aims to breakdown research articles to make them more accessible to a wider audience. 
Verify and fact check your reference
Most AI is currently unable to distinguish between fake and real information and could generate false citations and statistics, affecting the quality of work produced. This could be more obvious when asking the Chatbot to explain a complex or niche topic. Or even something that is not widely available. 
Chat GPT Advises:
Check your facts
While we have safeguards, ChatGPT may give you inaccurate information. It’s not intended to give advice.
 
Example of a Book Reference

Ritchie, D. A. (2003). Doing Oral History (2nd ed.). Oxford University Press. 
Book references contain author, (year of publication). Title of Book. Publisher and Place of Publication. To check if this is a real title do a title search in;
PRIMO
Pubmed
Scopus
Web of Science
Google Scholar
 
Example of a Peer Reviewed Journal Article Reference
Article: ""Hidden Histories of Oppression: Exploring the Interplay between Social Disadvantage and Historical Silencing"" Author: Smith, J. M. Journal: Journal of Historical Sociology Volume: 30 Issue: 3 Pages: 304-321 Publication year: 2017
 
Bodnar, J. (1992). Making sense of oral history. The Journal of American History, 78(3), 887-891.
 

Critical Thinking in the Context of Al
﻿﻿Asking clear, purposeful questions
﻿﻿Analysing the reliability of information
﻿﻿Recognising bias or assumptions
Comparing and evaluating different perspectives
Al generates content based on patterns in data - not truth."
59,Bangor University,59_bagnor.rtf,https://www.bangor.ac.uk/regulations/documents/artificial-intelligence-software-assessment-en.docx,"Generative Artificial Intelligence Software and Academic Integrity
Guidance Document
 
Effective from: 1st September 2025
Review Date: January 2026
Review frequency: annual
 
Contents
Introduction
What is gen-AI technology?
The University’s position on the use of Gen-AI
Assessment at Bangor
Gen-AI and Assessment
Guidance on assessment and assessment categories
Gen-AI use for marking
Gen-AI use for feedback
Gen-AI Detection tools
Programme development and Gen-AI
Reference
Appendix 1: Gen-AI Coversheet
 
Introduction
Continued developments in generative artificial intelligence (gen-AI) software have seen significant growth in free and subscription services as well as significant developments in capability.
 
In response, this document is an update of previously produced guidance that aims to:
1.     Provide the University’s overall position on the use of Gen-AI technology in teaching, learning and assessment.
2.     Provide framework guidance regarding Gen-AI, assessment and assessment design.
3.     Provide colleagues with agency to apply the guidance within their teaching. 
 
It is important to note that this document will not be able to provide specific guidance for every particular circumstance or assessment. It provides a guidance framework which staff should adopt within their teaching, appropriate to the context of the module, programme or subject.
What is gen-AI technology? 
The basics of Gen-AI technology are now well-known and the technology has progressed substantially since its release via free and subscription applications. If needed, an introductory primer on Gen-AI can be found here and a collection of resources regarding the ethical considerations in relation to Gen-AI and education can be found here(""https://www.qaa.ac.uk/sector-resources/generative-artificial-intelligence/ethical-considerations-for-using-generative-ai-in-higher-education"").
 
With respect to teaching, learning and assessment, the latest applications offer significant capability, for example:
·       OpenAi’s Operator tool can, when prompted, log into a Virtual Leaning Environment and autonomously complete, for example, an online test.
·       The Cluely application can operate ‘behind’ your desktop providing prompts and information based on what is occurring ‘on screen’.  For example, it can provide prompts and answers to questions being asked in an online interview or viva.  The application will operate, undetected, within ‘lock-down’ browsers.
·       In addition, Gen-AI is now embedded as standard within operating software such as Microsoft Windows
These examples help to identify that we must continue to review our learning, teaching and assessment approaches.  Importantly however, in doing so, we need to work with the possibilities offered by Gen-AI and be aware of its capabilities.
The University’s position on the use of Gen-AI
The University’s position remains that use of Gen-AI technology in learning, teaching and assessment is not banned, rather students will be guided towards ethical use as part of their education. 
 
The European University Association (EUA) position from 2023 remains relevant: “it is clear that banning the use of AI tools and other new technologies would be futile. Consequently, the higher education sector must adapt its learning, teaching and assessment approaches in such a way that AI is used effectively and appropriately”.  
 
Education at Bangor needs to embrace Gen-AI tools and ensure that our graduates are equipped to move into a workplace where the technology will be integral.  However, the University also needs to reassure itself of the integrity of its assessment processes, and that graduates have met their programme learning outcomes and that they have the knowledge, skills and competencies required by their degree programme, in addition where relevant, to meeting the requirements of any Professional Regulatory and Statutory Bodies. 
 
In addition, given the fast-moving nature of Gen-AI technology, it is important that the University is forward-looking and does not seek to implement rules or policies that will be out of date or redundant within a matter of months.  The University will continually review this guidance document to ensure that it remains relevant and effective.
 
Assessment at Bangor
Broadly, assessment approaches can be seen as being one of either: Assessment of Learning or Assessment for Learning.  The former represents summative assessment through which the student’s submissions provide evidence of achievement against learning outcomes and standards.  The latter represents a process where the engagement with the assessment provides feedback to students to further develop learning; it may be a formative assessment process or culminate in a summative assessment.  Degree programmes should contain an appropriate mix of the two approaches.   Assessments should be planned to provide a coherent structure and sequence of activities that support students in developing the knowledge, skills, and understanding required to meet the module and programme learning outcomes.
Gen-AI and Assessment
Reflecting the advances in Gen-AI technology, the University is seeking to utilize an approach that balances the following:
·       Embraces the ethical use of Gen-AI within education,
·       Maintains the academic standards of its programmes, 
·       Encourages openness around the use of Gen-AI, 
·       Emphasises communication around assessment requirements, and
·       Provides clarity to staff and students.
For the 2025/26 academic year, and within an overall position that the use of Gen-AI technology in learning, teaching and assessment is not banned, the University will adopt a categorization approach for assessments in relation to Gen-AI.  This approach is shown in Table 1.
Table 1: Gen-AI categories for assessment
Category|Category 1 assessments|Category 2 assessments|Category 3 assessments|
Definition|Whilst Gen-AI may be used to prepare for the assessment, the type and logistics of the assessment mean it is not possible for students to be able to use Gen-AI technology during the assessment itself.|Students may use Gen-AI to help them complete the assessment, but must adhere to the guiding principle (see below) and declare if and how they have used it using the Gen-AI coversheet (Appendix 1).  |These are designed so that students must use Gen-AI as part of the assessment requirements so as to support Gen-AI skills development. Students must declare how they have used it using the Gen-AI coversheet (Appendix 1).  |
Nature of assessment|Assessment of Learning|Assessment of Learning and/or Assessment for Learning.|Assessment of Learning and/or Assessment for Learning.|
Use of Gen-AI|Not banned but not feasible to use during the assessment|Not banned but ethical use during assessment completion.|Not banned and necessary to use.|
Examples|In-person presentation, assessed interview or viva voce, in-person examination, practical assessment, field or laboratory notebook (depending when submitted), Objective Structured Clinical Examination (OSCE), contemporaneous in-class assessment.|Written coursework, coursework involving creative outputs, coursework based upon experiential activities, take-home/online examinations.|Critique of Gen-AI produced content, coursework requiring Gen-AI use e.g. production of an artefact. |
Guiding Principle
 |Gen-AI may be used in preparation for the assessment, but the assessment arrangements mean its use in the assessment itself will not be possible. |Gen-AI may be used to help complete the assessment, however, the fundamental content of the submission (e.g., the basic written expression, arguments, interpretations, conclusions etc.) of work submitted for assessment should be a student’s own.  |The assessment design must ensure equity of access of Gen-AI with assessment criteria focusing on effectiveness of use.|
Guidance on assessment and assessment categories
1.     For each assessment, staff must communicate the assessment category to students via the Assessment Brief along with relevant position and guiding principle on Gen-AI use. 
                                  i.         The requirements for specific, professionally accredited programmes may include a restriction on the use of Gen-AI technology in (some) assessment.  Where this is the case, this must be clearly communicated to students with clear guidance on expectations.  
2.     For Category 1 assessments, consider employing forms of assessment that enable students to demonstrate their knowledge and subject skills in an in-person/in-class format.
                                  i.         Its seen as good practice not to simply default to in-person examinations.
                                ii.         In-person examinations can be used as part of a suite of assessment approaches. However, consider in-person examination approaches that go beyond closed-book formats.
3.     For Category 2 and 3 assessments, students should be informed that they must complete the Gen-AI coversheet to provide an open and honest declaration of its use. A copy of this must be made available in the assessment documentation on Blackboard.
                                  i.         Failure to submit the Gen-AI coversheet should not be penalized. This will be reviewed for subsequent academic years.
                                ii.         If a student fails to submit the Gen-AI coversheet, they should be reminded of the need to do so for future assessments in their assessment feedback.
4.     For Category 2 assessments, in designing or reviewing an assessment, staff should run a draft of the instructions through a Gen-AI tool to gauge the ease with which the assessment could be completed solely using Gen-AI.  Based on the outcomes, staff should modify the assessment design appropriately.
                                  i.         There are numerous guides on Gen-AI and assessment design, this(""https://www.kcl.ac.uk/about/strategy/learning-and-teaching/ai-guidance/approaches-to-assessment"") resource is one example.
5.     Whilst the University does not ban the use of Gen-AI, for Category 2 assessments, there is the potential for its use to contravene Bangor’s Academic Integrity Procedure(""https://my.bangor.ac.uk/regulations/procs/documents/BUProc05-2019v3.3.pdf"") through breaching requirements for honesty and through representing an action that falls “…within the general definition of academic misconduct”.  For example, through use beyond that declared on the Gen-AI coversheet. It may in addition exemplify instances of plagiarism, contract cheating and/or use of an essay mill.
6.     School Directors of Teaching and Learning, working with their respective Assessment Officers and/or Academic Integrity Officer, should provide appropriate oversight within their school so as to ensure consistency and clarity of information.
Gen-AI use for marking
Where marking requires the application of active academic judgements of assessment content (e.g.  marking of extended written work, presentations, creative outputs), Gen-AI should not be used.  
Use of Gen-AI, as found embedded within Bangor University-hosted software (e.g. Blackboard), may be appropriate for multiple choice assessment. However, staff must only use or upload such assessment to software hosted by the University for this purpose.  This is to ensure compliance with the UK General Data Protection Regulation.
Gen-AI use for feedback
The above position is differentiated from the use of Gen-AI to collate and/or refine assessment feedback (e.g. voice to text or group feedback), including use as an assistive technology for this purpose.  This may be appropriate and is permitted. Where this activity needs a student’s work to be uploaded to Gen-AI software, staff must only use Bangor University-hosted software for this purpose (e.g. Blackboard, Turnitin, Co-Pilot/Microsoft 365). In all cases, any Gen-AI supported feedback must be reviewed and confirmed by the member of staff responsible for the assessment.
If you are unsure regarding the use of Gen-AI for marking and feedback, please contact your School Director of Teaching and Learning.
The University will monitor the development of Gen-AI tools for marking and feedback and will keep the above positions under review.
 
Gen-AI Detection tools
Gen-AI detection and surveillance tools are available, however, their accuracy and validity cannot be guaranteed (exemplar resources on this topic can be found here and here(""https://citl.news.niu.edu/2024/12/12/ai-detectors-an-ethical-minefield/"")).  Furthermore, use of such tools, particularly through uploading student work to them, may breach the UK General Data Protection Regulation. Therefore, staff should not seek to use these as part of the assessment and marking process.  In addition, Gen-AI detection and surveillance tools will not normally be used in the operation of the University’s Academic Integrity Procedure.
 
The University will monitor the development of Gen-AI detection tools and will keep this position under review.
 
Programme development and Gen-AI 
Within the context and framework of the University’s Curriculum Transformation Project and as part of the annual Quality Assurance and Enhancement process, Schools should reflect on how their programmes embrace Gen-AI, how Gen-AI skills are developed and scaffolded within their curricula and the suite of assessments (and Gen-AI category of assessments) within their programmes.
 
This should be done according to the framework and timelines for module changes that are set out in the Code of Practice for Programme Approval, Monitoring and Review(""https://my.bangor.ac.uk/regulations/regulations/documents/BUReg01-2023v1.1-2.pdf"").  School Directors of Teaching and Learning, working (as appropriate) with their respective Assessment Officers and Programme Leads, should provide appropriate oversight of this process within their school.
 
Reference
 
·        European Universities Association (2023), Artificial intelligence tools and their responsible use in higher education learning and teaching, https://eua.eu/downloads/publications/position_ai%20in%20lt.pdf(""https://eua.eu/downloads/publications/position_ai%20in%20lt.pdf"") 
 
 
 
 
 
Appendix 1: Gen-AI Coversheet
Completion and submission of this coversheet is mandatory for Category 2 and Category 3 assessments. Additional cover-sheets/declarations relating to Academic Integrity may also be used.
Gen-AI in assessment declaration
Student 500 number:________________
Module Code:______________________
Assessment:_______________________
Assessment’s Gen-AI Category (see the Assessment Brief): 2 or 3
 
The following statement reflects my use of Gen-AI within this assessment (select all that apply):
Description of use|Select (X)|
Gen-AI has not been used at all in producing this assessment.| |
Gen-AI was used in an assistive role to research topics and provide explanations.| |
Gen-AI was used in an assistive role to suggest sources of information, e.g. publications to read.| |
Gen-AI was used in an assistive role to summarize the content of publications or other sources.| |
Gen-AI was used in an assistive role to produce an outline or draft structure of my assessment.
 
Note: for Category 2 assessments, the fundamental content of the submission (e.g., the arguments, interpretations, conclusions etc) must be your own.| |
Gen-AI was used in an assistive role to improve spelling, grammar, sentence structure and/or clarity of expression of my assessment.
 
Note: for Category 2 assessments, the basic written expression must be your own. Therefore whilst Gen-AI may correct mistakes it must not produce the actual content.| |
Gen-AI was used in an assistive role to translate text during the production of the work.| |
Gen-AI was used in an assistive role to analyse data and/or produce visualizations of data.| |
Gen-AI was used in an assistive role to help produce creative outputs e.g. art, imagery, movie, music, creative writing.| |
Gen-AI was used in an assistive role to refine computer code and/or other output.| |
Gen-AI was used in another assistive role (please describe):
 | |
Gen-AI was fully used to complete a Category 3 assessment and use complied with the assessment instructions provided.| |
By using this cover sheet and entering my student ID above, I declare that I have provided honest and accurate details regarding my use of Gen-AI within this assessment."
60,University of Hull,60_Hull.pdf,https://www.hull.ac.uk/asset-library/docs/student-use-of-ai-policy-march-2025.pdf,"Student Use of AI  
Classification  Policy  
Version number:  1 00 
Status  Approved  
Approved by:  Senate  
Approval date:  12 March 2025  
Effective from:  12 March 2025  
Next review date:  25 February 2028  
Document author:  Head of the Teaching Excellence Academy  
Document owner:  PVC Education  
Contact:  
Report exemptions to:  Head of the Teaching Excellence Academy  
Education Committee  
Collaborative provision:  Not mandatory  
 
Related documents:  - 
University document:  Yes  
 
Published location:  https://www.hull.ac.uk/choose -hull/university -and -region/key -
documents/quality  
 
- The University has adopted the principles of Designing for Diverse Learners , and all policy 
documents should be written with reference to these principles. Further information is 
available at  the Designing for diverse learners website . 
- An Equality Impact Assessment  (EIA)  must be considered for all new and amended policies. 
Further information is available from the  EIA section of SharePoint . 
- This document is available in alternative formats from policy@hull.ac.uk . 
- All printed or downloaded versions of this document are classified as uncontrolled
 
Version 1 00  of this document was approved  by Senate  on 12 March 2025   
Page 2 
Student Use of AI  
Table of Contents  
1 Introduction  ................................ ................................ ................................ ..................  3 
2 AI Guidance  ................................ ................................ ................................ ..................  3 
3 AI in Assessment  ................................ ................................ ................................ ..........  3 
4 How to Acknowledge the Use of AI  ................................ ................................ .................  4 
5 Version control  ................................ ................................ ................................ .............  4 
 
 
 
 
Version 1 00  of this document was approved  by Senate  on 12 March 2025   
Page 3 
Student Use of AI  
1 Introduction  
1.1 This policy explains how to use Artificial Intelligence (AI) responsibly in your 
assessments at the University of Hull, including tools like ChatGPT that can generate 
text, images, and more. For more details on AI, check out our SkillsGuide. The main goal 
of this policy is to ensure that AI is used ethically, transparently, and fairly, so you can 
benefit from it while still upholding academic standards.  
University assessments require you to develop your own answers, resources, products, 
solutions and work. You are the creators of new works and knowledge. Working with 
integrity means that within assessments you acknowledge when the ideas and work of 
others have been used through the use of references and quotation marks and that work 
that is submitted f or assessment is authored by you and has not been completed on 
your behalf.    
This policy document explains how to use AI in a responsible way in your university  work. 
If you fail to follow this guidance there is a risk that your work may be considered an 
instance of academic misconduct. This guidance should be read alongside the 
Academic Misconduct Regulations.  
2 AI Guidance  
2.1 Before you decide to use AI in your academic work, keep the following in mind:  
• Academic Integrity: Using AI is like using any other source —if you don’t 
acknowledge it, it’s plagiarism. All work you submit should be your own.  
• Accuracy: AI can sometimes produce information that seems believable but is 
actually incorrect. Even the references it generates might be fake or wrongly 
interpreted. Always double -check and critically review any factual information 
produced by AI.  
• Ethics: AI can generate content from text or images without the original creator’s 
consent, raising ethical issues about creativity and authorship.  
• Bias: AI tools may reflect biases present in the data they were trained on, and 
they often don’t rely on impartial or peer -reviewed sources.  
• Data Privacy/Security: Information you provide to an AI tool might be stored and 
used by others, so avoid sharing personal or sensitive details with AI.  
3 AI in Assessment  
3.1 If you’re thinking about using AI tools for your assessments, check with your module 
leader and the assessment brief to see if it’s appropriate for that specific task.  
In some cases, you might be asked to use AI directly. These assignments will be clearly 
marked with instructions on what is allowed. For example, if you’re working on a 
research thesis, discuss the use of AI with your supervisor.  
Unless specified otherwise, you can use AI to:  
• Get a general structure for an essay, presentation, or other work as a starting 
point  
 
Version 1 00  of this document was approved  by Senate  on 12 March 2025   
Page 4 
• Suggest corrections for spelling and punctuation  
• Help with research by providing an overview of a topic (just remember to 
reference it if you use it in your work)  
However, unless you have explicit permission, you cannot use AI to:  
• Write or rewrite your work for you  
• Paraphrase someone else’s work without proper citation  
• Create images or code without acknowledging the source  
• Contribute to a viva or exam that is invigilated  
• Perform research tasks, such as generating data or acting as a source of factual 
information, without acknowledging the source  
4 How to Acknowledge the Use of AI  
4.1 If you’ve been given permission to include AI -generated content in your work, the 
University’s AI SkillsGuide provides instructions on how to reference it.  
If you’ve used AI in another way, check your assignment brief or speak to your module 
leader to find out how to acknowledge this. You might need to make a general statement 
about your AI use or include details of the prompts you used.  
5 Version control  
Version  Author  Date approved  Relevant sections  
1 00 Head of Teaching Excellence 
Academy  12 March 2025, 
Senate  New"
